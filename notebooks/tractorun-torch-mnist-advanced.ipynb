{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e8868e68-d930-447e-a460-bb0e964ce4d2",
            "metadata": {
                "cell_id": "e8868e68-d930-447e-a460-bb0e964ce4d2",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "# Tractorun advanced\n\nThis notebook provides an extended demonstration of the advanced capabilities of the `tractorun` library. The focus will be on two key features:\n1. **Checkpoints for PyTorch**: how to save a checkpoint and restore training from a checkpoint.\n2. **Distributed Model Training**: how to run distributed training by `tractorun` on multiple nodes with multiple processes.\n\nFor a basic example, please refer to [tractorun-torch-mnist](./tractorun-torch-mnist.ipynb)."
                }
            },
            "source": "# Tractorun advanced\n\nThis notebook provides an extended demonstration of the advanced capabilities of the `tractorun` library. The focus will be on two key features:\n1. **Checkpoints for PyTorch**: how to save a checkpoint and restore training from a checkpoint.\n2. **Distributed Model Training**: how to run distributed training by `tractorun` on multiple nodes with multiple processes.\n\nFor a basic example, please refer to [tractorun-torch-mnist](./tractorun-torch-mnist.ipynb)."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "b1a47927-d36a-4f54-8f8d-ae110fd975b6",
            "metadata": {
                "cell_id": "b1a47927-d36a-4f54-8f8d-ae110fd975b6",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "import uuid\nimport sys\n\nfrom yt import wrapper as yt\nfrom yt import type_info"
                }
            },
            "outputs": [],
            "source": "import uuid\nimport sys\n\nfrom yt import wrapper as yt\nfrom yt import type_info"
        },
        {
            "cell_type": "markdown",
            "id": "0061a831-66ed-440f-8b8c-383cef32b4cf",
            "metadata": {
                "cell_id": "0061a831-66ed-440f-8b8c-383cef32b4cf",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Create a base directory for examples"
                }
            },
            "source": "## Create a base directory for examples"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "925cef8c-5f37-4644-84a0-3dfa419b5c58",
            "metadata": {
                "cell_id": "925cef8c-5f37-4644-84a0-3dfa419b5c58",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "working_dir = f\"//tmp/examples/tractorun-mnist-advanced_{uuid.uuid4()}\"\nyt.create(\"map_node\", working_dir, recursive=True)\nprint(working_dir)"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "//tmp/examples/tractorun-mnist-advanced_4c0664db-4ea9-4e7a-a121-574082f6d42e\n"
                }
            ],
            "source": "working_dir = f\"//tmp/examples/tractorun-mnist-advanced_{uuid.uuid4()}\"\nyt.create(\"map_node\", working_dir, recursive=True)\nprint(working_dir)"
        },
        {
            "cell_type": "markdown",
            "id": "77500c37-f2af-4fa2-8a31-0c9bcf189dd5",
            "metadata": {
                "cell_id": "77500c37-f2af-4fa2-8a31-0c9bcf189dd5",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Ensure torch and torchvision exist\n\nLet's ensure that the system has installed `torch` and `torchvision`."
                }
            },
            "source": "## Ensure torch and torchvision exist\n\nLet's ensure that the system has installed `torch` and `torchvision`."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "b0156666-97f0-4c83-b715-e8ef2f0b29d1",
            "metadata": {
                "cell_id": "b0156666-97f0-4c83-b715-e8ef2f0b29d1",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "import torch\nimport torchvision "
                }
            },
            "outputs": [],
            "source": "import torch\nimport torchvision "
        },
        {
            "cell_type": "markdown",
            "id": "805ea734-7217-4ef2-94ee-ab862090ac93",
            "metadata": {
                "cell_id": "805ea734-7217-4ef2-94ee-ab862090ac93",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Run distributed training"
                }
            },
            "source": "## Run distributed training"
        },
        {
            "cell_type": "markdown",
            "id": "796d862f-7295-4e6b-8471-61c69e8f43bc",
            "metadata": {
                "cell_id": "796d862f-7295-4e6b-8471-61c69e8f43bc",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Let's use [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). This process of uploading data is described in the [basic tractorun notebook]()"
                }
            },
            "source": "Let's use [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). This process of uploading data is described in the [basic tractorun notebook]()"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "ac74865b-d615-4b1d-8632-e0cecd166267",
            "metadata": {
                "cell_id": "ac74865b-d615-4b1d-8632-e0cecd166267",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "dataset_train_path = \"//home/samples/mnist-torch-train\"\ndataset_test_path = \"//home/samples/mnist-torch-test\""
                }
            },
            "outputs": [],
            "source": "dataset_train_path = \"//home/samples/mnist-torch-train\"\ndataset_test_path = \"//home/samples/mnist-torch-test\""
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "d8ec8d0a-f0e1-4f56-a14a-64525411715b",
            "metadata": {
                "cell_id": "d8ec8d0a-f0e1-4f56-a14a-64525411715b",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "training_dir = f\"{working_dir}/tractorun\"\nyt.create(\"map_node\", training_dir, force=True)\n\nprint(training_dir)"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "//tmp/examples/tractorun-mnist-advanced_4c0664db-4ea9-4e7a-a121-574082f6d42e/tractorun\n"
                }
            ],
            "source": "training_dir = f\"{working_dir}/tractorun\"\nyt.create(\"map_node\", training_dir, force=True)\n\nprint(training_dir)"
        },
        {
            "cell_type": "markdown",
            "id": "c81b855e-415b-4e5b-b6ae-d8d411c50cfb",
            "metadata": {
                "cell_id": "c81b855e-415b-4e5b-b6ae-d8d411c50cfb",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "In order to run tractorun in distributed mode and using checkpoints:\n1. Use `toolbox.checkpoint_manager` to manage checkpoints.\n2. Set distributed training configuration by `tractorun.mesh.Mesh`\n\n<details>\n  <summary>Show the full diff</summary>\n\n```diff\n@@ -6,7 +6,15 @@\n from torchvision import datasets, transforms\n from torch.optim.lr_scheduler import StepLR\n\n+from tractorun.backend.tractorch import YtTensorDataset, Tractorch\n+from tractorun.toolbox import Toolbox\n+from tractorun.run import run\n+from tractorun.mesh import Mesh\n+from tractorun.resources import Resources\n+from tractorun.stderr_reader import StderrMode\n+from tractorun.backend.tractorch.serializer import TensorSerializer\n\n class Net(nn.Module):\n     def __init__(self):\n         super(Net, self).__init__()\n@@ -33,9 +41,12 @@\n         return output\n\n\n-def train(args, model, device, train_loader, optimizer, epoch):\n+def train(args, model, device, train_loader, optimizer, epoch, first_batch_index, checkpoint_manager):\n     model.train()\n+    ts = TensorSerializer()\n     for batch_idx, (data, target) in enumerate(train_loader):\n+        if batch_idx < first_batch_index:\n+            continue\n         data, target = data.to(device), target.to(device)\n         optimizer.zero_grad()\n         output = model(data)\n@@ -45,9 +56,18 @@\n         if batch_idx % args.log_interval == 0:\n             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                 epoch, batch_idx * len(data), len(train_loader.dataset),\n-                100. * batch_idx / len(train_loader), loss.item()))\n+                100. * batch_idx / len(train_loader), loss.item()), file=sys.stderr)\n             if args.dry_run:\n                 break\n+            state_dict = {\n+                \"model\": model.state_dict(),\n+                \"optimizer\": optimizer.state_dict(),\n+            }\n+            metadata_dict = {\n+                \"first_batch_index\": batch_idx + 1,\n+                \"loss\": loss.item(),\n+            }\n+            checkpoint_manager.save_checkpoint(ts.serialize(state_dict), metadata_dict)\n\n\n def test(model, device, test_loader):\n@@ -66,10 +86,10 @@\n\n     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n         test_loss, correct, len(test_loader.dataset),\n-        100. * correct / len(test_loader.dataset)))\n+        100. * correct / len(test_loader.dataset)), file=sys.stderr)\n\n\n-def main():\n+def main(toolbox: Toolbox):\n     # Training settings\n     parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n     parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n@@ -94,7 +114,7 @@\n                         help='how many batches to wait before logging training status')\n     parser.add_argument('--save-model', action='store_true', default=False,\n                         help='For Saving the current Model')\n-    args = parser.parse_args()\n+    args = parser.parse_args([])\n     use_cuda = not args.no_cuda and torch.cuda.is_available()\n     use_mps = not args.no_mps and torch.backends.mps.is_available()\n\n@@ -120,26 +140,48 @@\n         transforms.ToTensor(),\n         transforms.Normalize((0.1307,), (0.3081,))\n         ])\n-    dataset1 = datasets.MNIST('../data', train=True, download=True,\n-                       transform=transform)\n-    dataset2 = datasets.MNIST('../data', train=False,\n-                       transform=transform)\n+    dataset1 = YtTensorDataset(toolbox=toolbox, path=dataset_train_path, columns=['data', 'labels'])\n+    dataset2 = YtTensorDataset(toolbox=toolbox, path=dataset_test_path, columns=['data', 'labels'])\n+\n     train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n     test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n\n     model = Net().to(device)\n     optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n\n+    ts = TensorSerializer()\n+    first_batch_index = 0\n+    checkpoint = toolbox.checkpoint_manager.get_last_checkpoint()\n+    if checkpoint is not None:\n+        first_batch_index = checkpoint.metadata[\"first_batch_index\"]\n+        print(\n+            \"Found checkpoint with index\",\n+            checkpoint.index,\n+            \"and first batch index\",\n+            first_batch_index,\n+            file=sys.stderr,\n+        )\n+\n     scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n     for epoch in range(1, args.epochs + 1):\n-        train(args, model, device, train_loader, optimizer, epoch)\n+        train(args, model, device, train_loader, optimizer, epoch, first_batch_index, toolbox.checkpoint_manager)\n         test(model, device, test_loader)\n         scheduler.step()\n\n     if args.save_model:\n-        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n+        toolbox.save_model(ts.serialize(model.state_dict()), dataset_train_path, metadata={})\n\n\n-if __name__ == '__main__':\n-    main()\n+run(\n+    main,\n+    backend=Tractorch(),\n+    yt_path=training_dir,\n+    mesh=Mesh(node_count=2, process_per_node=2, gpu_per_process=0),\n+    resources=Resources(\n+        cpu_limit=8,\n+        memory_limit=105899345920,\n+    ),\n+    proxy_stderr_mode=StderrMode.primary,\n+)\n```\n</details>"
                }
            },
            "source": "In order to run tractorun in distributed mode and using checkpoints:\n1. Use `toolbox.checkpoint_manager` to manage checkpoints.\n2. Set distributed training configuration by `tractorun.mesh.Mesh`\n\n<details>\n  <summary>Show the full diff</summary>\n\n```diff\n@@ -6,7 +6,15 @@\n from torchvision import datasets, transforms\n from torch.optim.lr_scheduler import StepLR\n\n+from tractorun.backend.tractorch import YtTensorDataset, Tractorch\n+from tractorun.toolbox import Toolbox\n+from tractorun.run import run\n+from tractorun.mesh import Mesh\n+from tractorun.resources import Resources\n+from tractorun.stderr_reader import StderrMode\n+from tractorun.backend.tractorch.serializer import TensorSerializer\n\n class Net(nn.Module):\n     def __init__(self):\n         super(Net, self).__init__()\n@@ -33,9 +41,12 @@\n         return output\n\n\n-def train(args, model, device, train_loader, optimizer, epoch):\n+def train(args, model, device, train_loader, optimizer, epoch, first_batch_index, checkpoint_manager):\n     model.train()\n+    ts = TensorSerializer()\n     for batch_idx, (data, target) in enumerate(train_loader):\n+        if batch_idx < first_batch_index:\n+            continue\n         data, target = data.to(device), target.to(device)\n         optimizer.zero_grad()\n         output = model(data)\n@@ -45,9 +56,18 @@\n         if batch_idx % args.log_interval == 0:\n             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                 epoch, batch_idx * len(data), len(train_loader.dataset),\n-                100. * batch_idx / len(train_loader), loss.item()))\n+                100. * batch_idx / len(train_loader), loss.item()), file=sys.stderr)\n             if args.dry_run:\n                 break\n+            state_dict = {\n+                \"model\": model.state_dict(),\n+                \"optimizer\": optimizer.state_dict(),\n+            }\n+            metadata_dict = {\n+                \"first_batch_index\": batch_idx + 1,\n+                \"loss\": loss.item(),\n+            }\n+            checkpoint_manager.save_checkpoint(ts.serialize(state_dict), metadata_dict)\n\n\n def test(model, device, test_loader):\n@@ -66,10 +86,10 @@\n\n     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n         test_loss, correct, len(test_loader.dataset),\n-        100. * correct / len(test_loader.dataset)))\n+        100. * correct / len(test_loader.dataset)), file=sys.stderr)\n\n\n-def main():\n+def main(toolbox: Toolbox):\n     # Training settings\n     parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n     parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n@@ -94,7 +114,7 @@\n                         help='how many batches to wait before logging training status')\n     parser.add_argument('--save-model', action='store_true', default=False,\n                         help='For Saving the current Model')\n-    args = parser.parse_args()\n+    args = parser.parse_args([])\n     use_cuda = not args.no_cuda and torch.cuda.is_available()\n     use_mps = not args.no_mps and torch.backends.mps.is_available()\n\n@@ -120,26 +140,48 @@\n         transforms.ToTensor(),\n         transforms.Normalize((0.1307,), (0.3081,))\n         ])\n-    dataset1 = datasets.MNIST('../data', train=True, download=True,\n-                       transform=transform)\n-    dataset2 = datasets.MNIST('../data', train=False,\n-                       transform=transform)\n+    dataset1 = YtTensorDataset(toolbox=toolbox, path=dataset_train_path, columns=['data', 'labels'])\n+    dataset2 = YtTensorDataset(toolbox=toolbox, path=dataset_test_path, columns=['data', 'labels'])\n+\n     train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n     test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n\n     model = Net().to(device)\n     optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n\n+    ts = TensorSerializer()\n+    first_batch_index = 0\n+    checkpoint = toolbox.checkpoint_manager.get_last_checkpoint()\n+    if checkpoint is not None:\n+        first_batch_index = checkpoint.metadata[\"first_batch_index\"]\n+        print(\n+            \"Found checkpoint with index\",\n+            checkpoint.index,\n+            \"and first batch index\",\n+            first_batch_index,\n+            file=sys.stderr,\n+        )\n+\n     scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n     for epoch in range(1, args.epochs + 1):\n-        train(args, model, device, train_loader, optimizer, epoch)\n+        train(args, model, device, train_loader, optimizer, epoch, first_batch_index, toolbox.checkpoint_manager)\n         test(model, device, test_loader)\n         scheduler.step()\n\n     if args.save_model:\n-        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n+        toolbox.save_model(ts.serialize(model.state_dict()), dataset_train_path, metadata={})\n\n\n-if __name__ == '__main__':\n-    main()\n+run(\n+    main,\n+    backend=Tractorch(),\n+    yt_path=training_dir,\n+    mesh=Mesh(node_count=2, process_per_node=2, gpu_per_process=0),\n+    resources=Resources(\n+        cpu_limit=8,\n+        memory_limit=105899345920,\n+    ),\n+    proxy_stderr_mode=StderrMode.primary,\n+)\n```\n</details>"
        },
        {
            "cell_type": "markdown",
            "id": "6091654b-d25c-4b04-be6f-07725095c5f2",
            "metadata": {
                "cell_id": "6091654b-d25c-4b04-be6f-07725095c5f2",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "<font color=\"red\">IMPORTANT NOTE</font> In this example we are running tractorun directly from Jupyter notebook.\n\nThis is a convenient method for experiments and demonstrations, as tractorun uses [pickle](https://docs.python.org/3/library/pickle.html) for easy serialization of the entire notebook state and transferring it to the cluster. This means that all variables will be available in the model training function, and tractorun will attempt to transfer all Python modules from the local environment to the cluster.\n\nHowever, this method does not ensure reproducibility of the run of model's training. For production processes, use the execution via the tractorun CLI, which is described in [basic notebook](./tractorun-mnis.ipynb)."
                }
            },
            "source": "<font color=\"red\">IMPORTANT NOTE</font> In this example we are running tractorun directly from Jupyter notebook.\n\nThis is a convenient method for experiments and demonstrations, as tractorun uses [pickle](https://docs.python.org/3/library/pickle.html) for easy serialization of the entire notebook state and transferring it to the cluster. This means that all variables will be available in the model training function, and tractorun will attempt to transfer all Python modules from the local environment to the cluster.\n\nHowever, this method does not ensure reproducibility of the run of model's training. For production processes, use the execution via the tractorun CLI, which is described in [basic notebook](./tractorun-mnis.ipynb)."
        },
        {
            "cell_type": "markdown",
            "id": "0a75419c-2d61-479d-9895-384843459b0a",
            "metadata": {
                "cell_id": "0a75419c-2d61-479d-9895-384843459b0a",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Let's run training on 2 hosts with 2 processes. This is not the most optimal configuration, but it demonstrates the tractor's capabilities in a simple way."
                }
            },
            "source": "Let's run training on 2 hosts with 2 processes. This is not the most optimal configuration, but it demonstrates the tractor's capabilities in a simple way."
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "2ad67093-9e8e-4ecd-9790-62af82ff4206",
            "metadata": {
                "cell_id": "2ad67093-9e8e-4ecd-9790-62af82ff4206",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "import argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom tractorun.backend.tractorch import YtTensorDataset, Tractorch\nfrom tractorun.toolbox import Toolbox\nfrom tractorun.run import run\nfrom tractorun.mesh import Mesh\nfrom tractorun.resources import Resources\nfrom tractorun.stderr_reader import StderrMode\nfrom tractorun.backend.tractorch.serializer import TensorSerializer\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\n\ndef train(args, model, device, train_loader, optimizer, epoch, first_batch_index, checkpoint_manager):\n    model.train()\n    ts = TensorSerializer()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if batch_idx < first_batch_index:\n            continue\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()), file=sys.stderr)\n            if args.dry_run:\n                break\n            state_dict = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n            }\n            metadata_dict = {\n                \"first_batch_index\": batch_idx + 1,\n                \"loss\": loss.item(),\n            }\n            checkpoint_manager.save_checkpoint(ts.serialize(state_dict), metadata_dict)\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)), file=sys.stderr)\n\n\ndef main(toolbox: Toolbox):\n    # Training settings\n    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                        help='input batch size for training (default: 64)')\n    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                        help='input batch size for testing (default: 1000)')\n    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n                        help='number of epochs to train (default: 14)')\n    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n                        help='learning rate (default: 1.0)')\n    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n                        help='Learning rate step gamma (default: 0.7)')\n    parser.add_argument('--no-cuda', action='store_true', default=False,\n                        help='disables CUDA training')\n    parser.add_argument('--no-mps', action='store_true', default=False,\n                        help='disables macOS GPU training')\n    parser.add_argument('--dry-run', action='store_true', default=False,\n                        help='quickly check a single pass')\n    parser.add_argument('--seed', type=int, default=1, metavar='S',\n                        help='random seed (default: 1)')\n    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                        help='how many batches to wait before logging training status')\n    parser.add_argument('--save-model', action='store_true', default=False,\n                        help='For Saving the current Model')\n    args = parser.parse_args([])\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n    use_mps = not args.no_mps and torch.backends.mps.is_available()\n\n    torch.manual_seed(args.seed)\n\n    if use_cuda:\n        device = torch.device(\"cuda\")\n    elif use_mps:\n        device = torch.device(\"mps\")\n    else:\n        device = torch.device(\"cpu\")\n\n    train_kwargs = {'batch_size': args.batch_size}\n    test_kwargs = {'batch_size': args.test_batch_size}\n    if use_cuda:\n        cuda_kwargs = {'num_workers': 1,\n                       'pin_memory': True,\n                       'shuffle': True}\n        train_kwargs.update(cuda_kwargs)\n        test_kwargs.update(cuda_kwargs)\n\n    transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n        ])\n    dataset1 = YtTensorDataset(toolbox=toolbox, yt_client=toolbox.yt_client, path=dataset_train_path, columns=['data', 'labels'])\n    dataset2 = YtTensorDataset(toolbox=toolbox, yt_client=toolbox.yt_client, path=dataset_test_path, columns=['data', 'labels'])\n\n    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n\n    model = Net().to(device)\n    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n\n    ts = TensorSerializer()\n    first_batch_index = 0\n    checkpoint = toolbox.checkpoint_manager.get_last_checkpoint()\n    if checkpoint is not None:\n        first_batch_index = checkpoint.metadata[\"first_batch_index\"]\n        print(\n            \"Found checkpoint with index\",\n            checkpoint.index,\n            \"and first batch index\",\n            first_batch_index,\n            file=sys.stderr,\n        )\n        checkpoint_dict = serializer.desirialize(checkpoint.value)\n        model.load_state_dict(checkpoint_dict[\"model\"])\n        optimizer.load_state_dict(checkpoint_dict[\"optimizer\"])\n\n    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch, first_batch_index, toolbox.checkpoint_manager)\n        test(model, device, test_loader)\n        scheduler.step()\n\n    if args.save_model:\n        toolbox.save_model(ts.serialize(model.state_dict()), dataset_train_path, metadata={})\n\n\nrun(\n    main,\n    backend=Tractorch(),\n    yt_path=training_dir,\n    mesh=Mesh(node_count=1, process_per_node=1, gpu_per_process=0),\n    resources=Resources(\n        cpu_limit=8,\n        memory_limit=55899345920,\n    ),\n    proxy_stderr_mode=StderrMode.primary,\n)\n"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:11,729\tWARNING\tCannot locate file of the module (__name__: torch.ops, __file__: _ops.py)\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:11,732\tWARNING\tCannot locate file of the module (__name__: torch.classes, __file__: _classes.py)\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:15,222\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/bc3ec92c-8d1dcb56-134403e8-55988bb2/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:15,287\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:15,288\tINFO\t( 0 min) operation bc3ec92c-8d1dcb56-134403e8-55988bb2 materializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:18,456\tINFO\t( 0 min) operation bc3ec92c-8d1dcb56-134403e8-55988bb2: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-22 00:48:20,612\tINFO\t( 0 min) operation bc3ec92c-8d1dcb56-134403e8-55988bb2: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\nold coordinator address: man0-0628.hw.nebius.yt:24595\nnew coordinator address: 127.0.0.1:24595\n/usr/local/lib/python3.12/site-packages/tractorun/backend/tractorch/serializer.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(buffer, map_location=device)\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305400\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.359781\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.830670\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.605967\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.346150\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.449750\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.298427\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.280616\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.566990\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.212487\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.260297\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.337602\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.181873\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.214108\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.281212\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.115761\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.284973\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.103214\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.454207\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.238571\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.211235\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.230551\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.161682\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.388254\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.170093\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.124145\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.163074\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.069960\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.201923\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.186418\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.302840\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.079991\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.030935\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.246017\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.006061\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.075131\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.200864\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.178680\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.015694\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.132049\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.098123\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.085059\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.288829\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.244576\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.151464\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.114122\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.031268\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.196311\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.043951\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.126370\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.197847\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.086704\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.065214\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.021038\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.014852\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.200514\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.177411\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.050361\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.122198\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.157975\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.129585\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.041151\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.022825\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.069116\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.098389\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.097631\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.110371\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.082171\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.168352\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.088162\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.124526\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.170965\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.115097\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.150482\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.113947\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.054285\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.022575\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.047245\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.065953\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.057243\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.292183\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.013264\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.062604\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.145437\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.043913\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.096954\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.039897\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.093554\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.087284\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.092373\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.168433\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.011809\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.013890\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.001240\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nTest set: Average loss: 0.0459, Accuracy: 9854/10000 (99%)\n\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 0.111636\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.024767\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.059515\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.143515\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.061988\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.077941\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.014006\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.088027\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.146471\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.091040\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.233600\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.193643\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.141306\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.021440\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.115944\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.059962\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.087369\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.012917\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.134880\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.057335\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.115357\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.011926\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.014162\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.104110\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.115065\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.139126\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.078291\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.011893\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.062311\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.060214\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.104896\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.133713\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.028132\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.099295\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.005182\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.005963\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.045672\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.045486\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.001559\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.012005\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.055492\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.019866\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.136874\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.039309\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.147047\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.005522\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.066551\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.040743\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.044685\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.098953\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.143796\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.103087\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.054023\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.008250\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.012773\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.071417\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.065895\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.035815\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.033530\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.081068\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.073160\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.001419\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.010620\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.061286\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.059108\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.064861\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.031258\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.124933\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.056308\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.003981\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.081397\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.056891\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.101221\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.122394\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.046409\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.058376\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.029399\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.010278\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.030281\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.061063\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.112632\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.030713\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.006734\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.032074\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.105262\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.017676\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.027966\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.075241\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.018636\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.044391\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.015586\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.006691\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.037831\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.022324\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nTest set: Average loss: 0.0383, Accuracy: 9869/10000 (99%)\n\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.030049\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.019187\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.017713\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.087214\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.055860\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.043705\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.028214\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.034923\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.044398\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.018190\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.096125\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.215992\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.019471\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.029972\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.067644\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.086740\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.165635\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.029024\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.091648\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.032589\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.092993\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.020397\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.015845\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.095842\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.014376\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.020941\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.163863\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.000985\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.021155\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.009519\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.089477\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.075548\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.006048\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.148757\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.008087\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.002194\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.060295\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.030610\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.001488\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.015752\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.054543\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.039640\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.023088\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.087582\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.083670\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.025369\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.006463\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.023205\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.107299\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.072307\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.027280\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.008489\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.019752\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.002141\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.010202\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.070688\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.101460\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.019704\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.057736\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.051821\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.083594\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.002321\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.015739\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.034982\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.029628\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.056978\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.027285\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.032426\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.065632\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.008083\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.055407\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.063949\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.099824\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.051306\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.081524\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.032162\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.023507\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.006915\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.014772\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.027215\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.014356\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.009976\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.001713\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.049863\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.112216\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.029238\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.009107\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.045717\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.016284\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.007336\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.068857\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.004761\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.018981\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.000828\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nTest set: Average loss: 0.0336, Accuracy: 9894/10000 (99%)\n\nTrain Epoch: 4 [0/60000 (0%)]\tLoss: 0.024213\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.007254\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.032177\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.095869\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.021787\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.014750\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.005523\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.061391\n"
                }
            ],
            "source": "import argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom tractorun.backend.tractorch import YtTensorDataset, Tractorch\nfrom tractorun.toolbox import Toolbox\nfrom tractorun.run import run\nfrom tractorun.mesh import Mesh\nfrom tractorun.resources import Resources\nfrom tractorun.stderr_reader import StderrMode\nfrom tractorun.backend.tractorch.serializer import TensorSerializer\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\n\ndef train(args, model, device, train_loader, optimizer, epoch, first_batch_index, checkpoint_manager):\n    model.train()\n    ts = TensorSerializer()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if batch_idx < first_batch_index:\n            continue\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()), file=sys.stderr)\n            if args.dry_run:\n                break\n            state_dict = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n            }\n            metadata_dict = {\n                \"first_batch_index\": batch_idx + 1,\n                \"loss\": loss.item(),\n            }\n            checkpoint_manager.save_checkpoint(ts.serialize(state_dict), metadata_dict)\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)), file=sys.stderr)\n\n\ndef main(toolbox: Toolbox):\n    # Training settings\n    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                        help='input batch size for training (default: 64)')\n    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                        help='input batch size for testing (default: 1000)')\n    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n                        help='number of epochs to train (default: 14)')\n    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n                        help='learning rate (default: 1.0)')\n    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n                        help='Learning rate step gamma (default: 0.7)')\n    parser.add_argument('--no-cuda', action='store_true', default=False,\n                        help='disables CUDA training')\n    parser.add_argument('--no-mps', action='store_true', default=False,\n                        help='disables macOS GPU training')\n    parser.add_argument('--dry-run', action='store_true', default=False,\n                        help='quickly check a single pass')\n    parser.add_argument('--seed', type=int, default=1, metavar='S',\n                        help='random seed (default: 1)')\n    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                        help='how many batches to wait before logging training status')\n    parser.add_argument('--save-model', action='store_true', default=False,\n                        help='For Saving the current Model')\n    args = parser.parse_args([])\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n    use_mps = not args.no_mps and torch.backends.mps.is_available()\n\n    torch.manual_seed(args.seed)\n\n    if use_cuda:\n        device = torch.device(\"cuda\")\n    elif use_mps:\n        device = torch.device(\"mps\")\n    else:\n        device = torch.device(\"cpu\")\n\n    train_kwargs = {'batch_size': args.batch_size}\n    test_kwargs = {'batch_size': args.test_batch_size}\n    if use_cuda:\n        cuda_kwargs = {'num_workers': 1,\n                       'pin_memory': True,\n                       'shuffle': True}\n        train_kwargs.update(cuda_kwargs)\n        test_kwargs.update(cuda_kwargs)\n\n    transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n        ])\n    dataset1 = YtTensorDataset(toolbox=toolbox, yt_client=toolbox.yt_client, path=dataset_train_path, columns=['data', 'labels'])\n    dataset2 = YtTensorDataset(toolbox=toolbox, yt_client=toolbox.yt_client, path=dataset_test_path, columns=['data', 'labels'])\n\n    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n\n    model = Net().to(device)\n    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n\n    ts = TensorSerializer()\n    first_batch_index = 0\n    checkpoint = toolbox.checkpoint_manager.get_last_checkpoint()\n    if checkpoint is not None:\n        first_batch_index = checkpoint.metadata[\"first_batch_index\"]\n        print(\n            \"Found checkpoint with index\",\n            checkpoint.index,\n            \"and first batch index\",\n            first_batch_index,\n            file=sys.stderr,\n        )\n        checkpoint_dict = serializer.desirialize(checkpoint.value)\n        model.load_state_dict(checkpoint_dict[\"model\"])\n        optimizer.load_state_dict(checkpoint_dict[\"optimizer\"])\n\n    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch, first_batch_index, toolbox.checkpoint_manager)\n        test(model, device, test_loader)\n        scheduler.step()\n\n    if args.save_model:\n        toolbox.save_model(ts.serialize(model.state_dict()), dataset_train_path, metadata={})\n\n\nrun(\n    main,\n    backend=Tractorch(),\n    yt_path=training_dir,\n    mesh=Mesh(node_count=1, process_per_node=1, gpu_per_process=0),\n    resources=Resources(\n        cpu_limit=8,\n        memory_limit=55899345920,\n    ),\n    proxy_stderr_mode=StderrMode.primary,\n)\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "chiffa_solutions_torch",
            "name": "chiffa_solutions_torch"
        },
        "tracto": {
            "is_solution_notebook": true,
            "metadata_version": "1",
            "notebook_cypress_id": "13e53a41-d4a7-4e09-8c9a-b021eb86173d"
        },
        "is_solution_notebook": true
    },
    "nbformat": 4,
    "nbformat_minor": 5
}