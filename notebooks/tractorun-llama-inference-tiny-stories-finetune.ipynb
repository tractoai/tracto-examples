{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "id": "5aed4c4d-3591-4eee-9f11-71d9d1047e4e",
            "metadata": {
                "tracto": {
                    "execution_end": 1738867873158,
                    "execution_start": 1738867872988,
                    "metadata_version": "1",
                    "source_hash": "049fdb6b",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [],
            "source": "import yt.wrapper as yt\nimport uuid\nimport os"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "f9095a36-cc37-4d82-8d33-cab9e4eda4a5",
            "metadata": {
                "tracto": {
                    "execution_end": 1738867873164,
                    "execution_start": 1738867873160,
                    "metadata_version": "1",
                    "source_hash": "20bcbce2",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [],
            "source": "yt.config[\"pickling\"][\"dynamic_libraries\"][\"enable_auto_collection\"] = False\nyt.config[\"pickling\"][\"ignore_system_modules\"] = True\nyt.config[\"pickling\"][\"safe_stream_mode\"] = False"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "e3ef4c4f-9636-4d05-a6b4-00c0c3abb15f",
            "metadata": {
                "tracto": {
                    "execution_end": 1738867873228,
                    "execution_start": 1738867873171,
                    "metadata_version": "1",
                    "source_hash": "6880def0",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "//tmp/examples/tractorun-tiny-stories-finetune-875dc7db-a990-4a66-93db-38836f8dfa1b\n"
                }
            ],
            "source": "working_dir = f\"//tmp/examples/tractorun-tiny-stories-finetune-{uuid.uuid4()}\"\nyt.create(\"map_node\", working_dir, recursive=True)\nprint(working_dir)"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "843cb719-e627-4c53-991b-20d11e915998",
            "metadata": {
                "tracto": {
                    "execution_end": 1738867874795,
                    "execution_start": 1738867873239,
                    "metadata_version": "1",
                    "source_hash": "5bc6e2a0",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [],
            "source": "from tractorun.toolbox import Toolbox\nfrom tractorun.run import run\nfrom tractorun.mesh import Mesh\nfrom tractorun.resources import Resources\nfrom tractorun.backend.generic import GenericBackend\nfrom tractorun.backend.tractorch import Tractorch\nfrom tractorun.stderr_reader import StderrMode"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "72cbb116-3314-41c1-9624-2b84d39e2a77",
            "metadata": {
                "tracto": {
                    "execution_end": 1738868086375,
                    "execution_start": 1738867874803,
                    "metadata_version": "1",
                    "source_hash": "7d53f402",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:15,370\tWARNING\tCannot locate file of the module (__name__: torch.ops, __file__: _ops.py)\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:15,372\tWARNING\tCannot locate file of the module (__name__: torch.classes, __file__: _classes.py)\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:18,007\tINFO\tOperation started: https://playground.yt.nebius.yt/playground/operations/cd0e06f6-42ee0531-270703e8-1b2ce6c0/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:18,031\tINFO\t( 0 min) operation cd0e06f6-42ee0531-270703e8-1b2ce6c0 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:18,561\tINFO\t( 0 min) operation cd0e06f6-42ee0531-270703e8-1b2ce6c0 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:19,629\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:19,652\tINFO\t( 0 min) operation cd0e06f6-42ee0531-270703e8-1b2ce6c0: running=0     completed=0     pending=2     failed=0     aborted=0     lost=0     total=2     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:51:21,849\tINFO\t( 0 min) operation cd0e06f6-42ee0531-270703e8-1b2ce6c0: running=2     completed=0     pending=0     failed=0     aborted=0     lost=0     total=2     blocked=0    \n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n/slot/sandbox/_py_runner.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  __tar.extractall(destination)\nFailed to write user statistics\nWaiting for all peers to start\nAll peers started\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "INFO 02-06 18:51:26 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:27 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:27 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:28 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:28 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:28 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:28 __init__.py:183] Automatically detected platform cuda.\nINFO 02-06 18:51:28 __init__.py:183] Automatically detected platform cuda.\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "INFO 02-06 18:51:42 config.py:526] This model supports multiple tasks: {'classify', 'embed', 'reward', 'score', 'generate'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:42 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:42 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:42 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=4, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:42 config.py:526] This model supports multiple tasks: {'reward', 'embed', 'score', 'classify', 'generate'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:42 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:42 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:42 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=5, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:43 config.py:526] This model supports multiple tasks: {'reward', 'generate', 'embed', 'score', 'classify'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:43 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:43 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:43 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=3, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:43 config.py:526] This model supports multiple tasks: {'classify', 'embed', 'generate', 'score', 'reward'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:43 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:43 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:43 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:43 config.py:526] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:43 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:43 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:43 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=2, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:43 config.py:526] This model supports multiple tasks: {'classify', 'reward', 'score', 'embed', 'generate'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:43 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:43 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:43 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=6, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:43 config.py:526] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:43 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:43 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:43 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\nINFO 02-06 18:51:43 config.py:526] This model supports multiple tasks: {'generate', 'score', 'classify', 'embed', 'reward'}. Defaulting to 'generate'.\nWARNING 02-06 18:51:43 arg_utils.py:1119] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\nINFO 02-06 18:51:43 config.py:1538] Chunked prefill is enabled with max_num_batched_tokens=2048.\nINFO 02-06 18:51:43 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=7, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False,\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "INFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:46 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\nINFO 02-06 18:51:47 cuda.py:235] Using Flash Attention backend.\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[rank0]:[W206 18:51:56.990557235 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\n[rank0]:[W206 18:51:56.010453152 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\n[rank0]:[W206 18:51:56.062214225 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n[rank0]:[W206 18:51:56.062276108 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n[rank0]:[W206 18:51:56.062482093 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\n[rank0]:[W206 18:51:56.078555682 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n[rank0]:[W206 18:51:56.082637551 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:56 weight_utils.py:251] Using model weights format ['*.safetensors']\n[rank0]:[W206 18:51:56.586274890 ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\nINFO 02-06 18:51:56 model_runner.py:1111] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\nINFO 02-06 18:51:57 weight_utils.py:251] Using model weights format ['*.safetensors']\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.04it/s]\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.06it/s]\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.68it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.84it/s]\n\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:14,  2.30it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:14,  2.28it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:01<00:12,  2.47it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.63it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]\n\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:14,  2.38it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  3.81it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]\n\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  3.84it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.76it/s]\n\nINFO 02-06 18:53:56 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:56 worker.py:266] Memory profiling takes 0.43 seconds\nINFO 02-06 18:53:56 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:56 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:56 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:56 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:53:59 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.01it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.68it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.84it/s]\n\nINFO 02-06 18:53:56 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:57 worker.py:266] Memory profiling takes 0.43 seconds\nINFO 02-06 18:53:57 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:57 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:57 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:57 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:54:00 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  3.81it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.59it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]\n\nINFO 02-06 18:53:57 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:57 worker.py:266] Memory profiling takes 0.42 seconds\nINFO 02-06 18:53:57 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:57 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:57 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:57 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:54:00 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 02-06 18:53:57 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:57 worker.py:266] Memory profiling takes 0.44 seconds\nINFO 02-06 18:53:57 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:57 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:58 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:58 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:54:00 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  3.69it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.53it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.68it/s]\n\n\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n\nLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  3.64it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.54it/s]\n\nLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.68it/s]\n\nINFO 02-06 18:53:57 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:58 worker.py:266] Memory profiling takes 0.50 seconds\nINFO 02-06 18:53:58 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:58 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:58 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:58 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:53:58 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:58 worker.py:266] Memory profiling takes 0.46 seconds\nINFO 02-06 18:53:58 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:58 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:59 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:59 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:53:58 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:59 worker.py:266] Memory profiling takes 0.56 seconds\nINFO 02-06 18:53:59 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:59 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:59 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:59 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\nINFO 02-06 18:53:59 model_runner.py:1116] Loading model weights took 6.0160 GB\nINFO 02-06 18:53:59 worker.py:266] Memory profiling takes 0.45 seconds\nINFO 02-06 18:53:59 worker.py:266] the current vLLM instance can use total_gpu_memory (139.72GiB) x gpu_memory_utilization (0.90) = 125.75GiB\nINFO 02-06 18:53:59 worker.py:266] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 118.37GiB.\nINFO 02-06 18:53:59 executor_base.py:108] # CUDA blocks: 69264, # CPU blocks: 2340\nINFO 02-06 18:53:59 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 8.46x\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:12,  2.43it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:02<00:12,  2.46it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:02<00:12,  2.39it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:11,  2.47it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:03<00:10,  2.46it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:03<00:10,  2.50it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:04<00:09,  2.57it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:04<00:09,  2.55it/s]\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:04<00:08,  2.57it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:05<00:08,  2.63it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:05<00:08,  2.60it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:05<00:07,  2.59it/s]\n\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:12,  2.64it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:01<00:11,  2.72it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:11,  2.76it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:10,  2.76it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:02<00:10,  2.80it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:09,  2.86it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:09,  2.91it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:03<00:08,  2.93it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:08,  2.93it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:03<00:08,  2.87it/s]\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:04<00:07,  2.88it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:07,  2.79it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:04<00:07,  2.82it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:05<00:07,  2.82it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:06,  2.84it/s]\n\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:13,  2.55it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:11,  2.97it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:00<00:10,  3.18it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:10,  3.03it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:09,  3.18it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:01<00:09,  3.19it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:08,  3.25it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:08,  3.25it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:02<00:08,  3.21it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:07,  3.20it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:03<00:07,  3.16it/s]\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:03<00:07,  3.18it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:06,  3.17it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:04<00:06,  3.14it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:04<00:06,  3.13it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:05,  3.18it/s]\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:13,  2.51it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:12,  2.68it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:01<00:11,  2.73it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:11,  2.81it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:10,  2.88it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:02<00:10,  2.80it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:09,  2.82it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:09,  2.86it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:03<00:09,  2.85it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:08,  2.85it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:03<00:08,  2.83it/s]\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:04<00:08,  2.85it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:07,  2.88it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:04<00:07,  2.90it/s]\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:13,  2.50it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:12,  2.68it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:01<00:11,  2.76it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:10,  2.86it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:10,  2.90it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:02<00:10,  2.84it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:09,  2.85it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:09,  2.89it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:03<00:08,  2.92it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:08,  2.92it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:03<00:08,  2.93it/s]\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:04<00:07,  2.92it/s]\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:14,  2.34it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:12,  2.58it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:01<00:12,  2.66it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:11,  2.77it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:10,  2.85it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:02<00:10,  2.76it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:10,  2.79it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:09,  2.85it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:03<00:08,  2.89it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:08,  2.85it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:03<00:08,  2.84it/s]\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:14,  2.38it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:12,  2.64it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:01<00:11,  2.76it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:11,  2.68it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:11,  2.67it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:02<00:10,  2.73it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:10,  2.67it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:10,  2.68it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:03<00:09,  2.73it/s]\n\nCapturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]\nCapturing CUDA graph shapes:   3%|\u258e         | 1/35 [00:00<00:11,  2.84it/s]\nCapturing CUDA graph shapes:   6%|\u258c         | 2/35 [00:00<00:10,  3.14it/s]\nCapturing CUDA graph shapes:   9%|\u258a         | 3/35 [00:00<00:10,  3.18it/s]\nCapturing CUDA graph shapes:  11%|\u2588\u258f        | 4/35 [00:01<00:09,  3.21it/s]\nCapturing CUDA graph shapes:  14%|\u2588\u258d        | 5/35 [00:01<00:09,  3.26it/s]\nCapturing CUDA graph shapes:  17%|\u2588\u258b        | 6/35 [00:01<00:08,  3.31it/s]\nCapturing CUDA graph shapes:  20%|\u2588\u2588        | 7/35 [00:02<00:08,  3.33it/s]\nCapturing CUDA graph shapes:  23%|\u2588\u2588\u258e       | 8/35 [00:02<00:08,  3.31it/s]\nCapturing CUDA graph shapes:  26%|\u2588\u2588\u258c       | 9/35 [00:02<00:07,  3.34it/s]\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:07,  3.35it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:03<00:07,  3.38it/s]\nINFO 02-06 18:54:01 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 02-06 18:54:01 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 02-06 18:54:02 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 02-06 18:54:02 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:06<00:07,  2.64it/s]\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:06<00:06,  2.68it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:07<00:06,  2.65it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:07<00:06,  2.61it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:07<00:05,  2.61it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:08<00:05,  2.63it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:08<00:04,  2.64it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:08<00:04,  2.63it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:09<00:04,  2.62it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:09<00:03,  2.63it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:10<00:03,  2.67it/s]\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:10<00:03,  2.65it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:10<00:02,  2.61it/s]\n\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:06<00:06,  2.85it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:06<00:05,  2.87it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:06<00:05,  2.88it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:07<00:05,  2.86it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:07<00:04,  2.84it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:07<00:04,  2.86it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:08<00:04,  2.87it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:08<00:03,  2.83it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:08<00:03,  2.83it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:09<00:03,  2.84it/s]\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:09<00:02,  2.80it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:09<00:02,  2.78it/s]\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:10<00:02,  2.71it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:10<00:01,  2.73it/s]\n\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:05<00:05,  3.13it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:05<00:05,  3.14it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:06<00:05,  3.16it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:06<00:04,  3.12it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:06<00:04,  3.09it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:07<00:04,  3.11it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:07<00:03,  3.07it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:07<00:03,  3.01it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:08<00:03,  3.04it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:08<00:02,  3.06it/s]\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:08<00:02,  3.09it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:09<00:02,  3.01it/s]\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:09<00:02,  2.87it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:09<00:01,  2.74it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:10<00:01,  2.69it/s]\n\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:05<00:06,  2.88it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:06,  2.82it/s]\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:06<00:06,  2.84it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:06<00:05,  2.85it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:06<00:05,  2.88it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:07<00:05,  2.91it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:07<00:04,  2.91it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:07<00:04,  2.91it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:08<00:04,  2.92it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:08<00:03,  2.91it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:08<00:03,  2.86it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:09<00:03,  2.72it/s]\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:09<00:02,  2.70it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:09<00:02,  2.73it/s]\n\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:07,  2.90it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:04<00:07,  2.91it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:05<00:06,  2.90it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:06,  2.89it/s]\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:05<00:06,  2.91it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:06<00:05,  2.91it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:06<00:05,  2.91it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:06<00:05,  2.91it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:07<00:04,  2.92it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:07<00:04,  2.90it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:07<00:04,  2.89it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:08<00:03,  2.77it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:08<00:03,  2.71it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:09<00:03,  2.74it/s]\n\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:04<00:08,  2.82it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:07,  2.89it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:04<00:07,  2.91it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:05<00:06,  2.94it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:06,  3.02it/s]\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:05<00:05,  3.05it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:06<00:05,  3.10it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:06<00:05,  3.08it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:06<00:04,  3.09it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:07<00:04,  2.99it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:07<00:04,  2.95it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:07<00:04,  2.88it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:08<00:04,  2.71it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:08<00:03,  2.65it/s]\n\nCapturing CUDA graph shapes:  29%|\u2588\u2588\u258a       | 10/35 [00:03<00:09,  2.71it/s]\nCapturing CUDA graph shapes:  31%|\u2588\u2588\u2588\u258f      | 11/35 [00:04<00:08,  2.70it/s]\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:04<00:08,  2.70it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:08,  2.74it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:05<00:07,  2.76it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:05<00:07,  2.68it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:07,  2.62it/s]\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:06<00:06,  2.57it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:06<00:06,  2.62it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:07<00:05,  2.70it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:07<00:05,  2.77it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:07<00:05,  2.61it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:08<00:05,  2.56it/s]\n\nCapturing CUDA graph shapes:  34%|\u2588\u2588\u2588\u258d      | 12/35 [00:03<00:07,  3.19it/s]\nCapturing CUDA graph shapes:  37%|\u2588\u2588\u2588\u258b      | 13/35 [00:04<00:07,  3.14it/s]\nCapturing CUDA graph shapes:  40%|\u2588\u2588\u2588\u2588      | 14/35 [00:04<00:06,  3.04it/s]\nCapturing CUDA graph shapes:  43%|\u2588\u2588\u2588\u2588\u258e     | 15/35 [00:04<00:06,  2.96it/s]\nCapturing CUDA graph shapes:  46%|\u2588\u2588\u2588\u2588\u258c     | 16/35 [00:05<00:06,  2.99it/s]\nCapturing CUDA graph shapes:  49%|\u2588\u2588\u2588\u2588\u258a     | 17/35 [00:05<00:05,  3.06it/s]\nCapturing CUDA graph shapes:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 18/35 [00:05<00:05,  3.13it/s]\nCapturing CUDA graph shapes:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 19/35 [00:05<00:05,  3.18it/s]\nCapturing CUDA graph shapes:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 20/35 [00:06<00:04,  3.27it/s]\nCapturing CUDA graph shapes:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 21/35 [00:06<00:04,  3.38it/s]\nCapturing CUDA graph shapes:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 22/35 [00:06<00:03,  3.48it/s]\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:07<00:03,  3.58it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:07<00:03,  3.54it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:07<00:03,  3.13it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:08<00:03,  2.96it/s]\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:11<00:02,  2.54it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:11<00:01,  2.56it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:12<00:01,  2.57it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:12<00:01,  2.62it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:12<00:00,  2.66it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:13<00:00,  2.72it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:13<00:00,  2.71it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:13<00:00,  2.59it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:11<00:01,  2.73it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:11<00:01,  2.75it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:11<00:00,  2.76it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:12<00:00,  2.79it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.70it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.80it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:10<00:01,  2.69it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:10<00:00,  2.80it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:11<00:00,  2.88it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:11<00:00,  2.90it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:11<00:00,  3.03it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:10<00:02,  2.68it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:10<00:01,  2.74it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:10<00:01,  2.79it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:11<00:01,  2.83it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:11<00:00,  2.84it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:12<00:00,  2.88it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.81it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.83it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:09<00:02,  2.73it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:09<00:02,  2.74it/s]\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:10<00:02,  2.67it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:10<00:01,  2.61it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:11<00:01,  2.57it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:11<00:01,  2.54it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:11<00:00,  2.50it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:12<00:00,  2.52it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.57it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.77it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:09<00:03,  2.63it/s]\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:09<00:02,  2.73it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:09<00:02,  2.76it/s]\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:10<00:02,  2.76it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:10<00:01,  2.83it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:10<00:01,  3.00it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:11<00:00,  3.08it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:11<00:00,  3.16it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:11<00:00,  3.33it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:11<00:00,  3.34it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:11<00:00,  2.92it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n\nCapturing CUDA graph shapes:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 23/35 [00:08<00:04,  2.57it/s]\nCapturing CUDA graph shapes:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 24/35 [00:09<00:04,  2.63it/s]\nCapturing CUDA graph shapes:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 25/35 [00:09<00:03,  2.70it/s]\nCapturing CUDA graph shapes:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 26/35 [00:09<00:03,  2.69it/s]\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:10<00:02,  2.73it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:10<00:02,  2.64it/s]\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:10<00:02,  2.54it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:11<00:01,  2.65it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:11<00:01,  2.77it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:11<00:01,  2.88it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:12<00:00,  3.04it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:12<00:00,  3.18it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  3.18it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:12<00:00,  2.74it/s]\n\nCapturing CUDA graph shapes:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 27/35 [00:08<00:02,  2.86it/s]\nCapturing CUDA graph shapes:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28/35 [00:08<00:02,  2.83it/s]\nCapturing CUDA graph shapes:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 29/35 [00:09<00:02,  2.83it/s]\nCapturing CUDA graph shapes:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 30/35 [00:09<00:01,  2.88it/s]\nCapturing CUDA graph shapes:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 31/35 [00:09<00:01,  2.99it/s]\nCapturing CUDA graph shapes:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 32/35 [00:10<00:00,  3.11it/s]\nCapturing CUDA graph shapes:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 33/35 [00:10<00:00,  3.10it/s]\nCapturing CUDA graph shapes:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 34/35 [00:10<00:00,  3.12it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:11<00:00,  3.12it/s]\nCapturing CUDA graph shapes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35/35 [00:11<00:00,  3.15it/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\nINFO 02-06 18:54:12 model_runner.py:1563] Graph capturing finished in 12 secs, took 0.29 GiB\nINFO 02-06 18:54:12 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 14.98 seconds\nINFO 02-06 18:54:12 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:12 model_runner.py:1563] Graph capturing finished in 13 secs, took 0.29 GiB\nINFO 02-06 18:54:12 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 15.94 seconds\nINFO 02-06 18:54:13 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:12 model_runner.py:1563] Graph capturing finished in 14 secs, took 0.29 GiB\nINFO 02-06 18:54:12 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 16.91 seconds\nINFO 02-06 18:54:13 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:13 model_runner.py:1563] Graph capturing finished in 12 secs, took 0.29 GiB\nINFO 02-06 18:54:13 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 15.79 seconds\nINFO 02-06 18:54:14 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:13 model_runner.py:1563] Graph capturing finished in 11 secs, took 0.29 GiB\nINFO 02-06 18:54:13 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 14.34 seconds\nINFO 02-06 18:54:14 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:13 model_runner.py:1563] Graph capturing finished in 12 secs, took 0.29 GiB\nINFO 02-06 18:54:13 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 15.47 seconds\nINFO 02-06 18:54:14 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:13 model_runner.py:1563] Graph capturing finished in 13 secs, took 0.29 GiB\nINFO 02-06 18:54:13 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 16.15 seconds\nINFO 02-06 18:54:14 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\nINFO 02-06 18:54:14 model_runner.py:1563] Graph capturing finished in 13 secs, took 0.29 GiB\nINFO 02-06 18:54:14 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 16.16 seconds\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nProcessed prompts:   0%|          | 1/500 [00:04<36:41,  4.41s/it, est. speed input: 24.93 toks/s, output: 45.78 toks/s]\nProcessed prompts:   1%|          | 3/500 [00:04<10:02,  1.21s/it, est. speed input: 71.79 toks/s, output: 136.62 toks/s]\nProcessed prompts:   1%|\u258f         | 7/500 [00:04<03:24,  2.41it/s, est. speed input: 162.28 toks/s, output: 308.33 toks/s]\nProcessed prompts:   3%|\u258e         | 13/500 [00:05<01:44,  4.67it/s, est. speed input: 274.70 toks/s, output: 533.26 toks/s]\nProcessed prompts:   4%|\u258d         | 20/500 [00:05<00:55,  8.65it/s, est. speed input: 413.75 toks/s, output: 814.72 toks/s]\nProcessed prompts:   5%|\u258c         | 26/500 [00:05<00:37, 12.66it/s, est. speed input: 526.75 toks/s, output: 1050.37 toks/s]\nProcessed prompts:   6%|\u258c         | 31/500 [00:05<00:29, 16.14it/s, est. speed input: 614.43 toks/s, output: 1232.28 toks/s]\nProcessed prompts:   8%|\u258a         | 41/500 [00:05<00:17, 26.25it/s, est. speed input: 796.55 toks/s, output: 1626.30 toks/s]\nProcessed prompts:   9%|\u2589         | 47/500 [00:05<00:14, 30.83it/s, est. speed input: 895.66 toks/s, output: 1849.00 toks/s]\nProcessed prompts:  11%|\u2588         | 54/500 [00:05<00:12, 36.75it/s, est. speed input: 1009.09 toks/s, output: 2105.15 toks/s]\nProcessed prompts:  13%|\u2588\u258e        | 66/500 [00:06<00:08, 51.07it/s, est. speed input: 1208.80 toks/s, output: 2559.45 toks/s]\nProcessed prompts:  15%|\u2588\u258c        | 76/500 [00:06<00:07, 60.50it/s, est. speed input: 1367.52 toks/s, output: 2921.67 toks/s]\nProcessed prompts:  18%|\u2588\u258a        | 90/500 [00:06<00:05, 75.79it/s, est. speed input: 1589.01 toks/s, output: 3438.68 toks/s]\nProcessed prompts:  21%|\u2588\u2588        | 104/500 [00:06<00:04, 87.37it/s, est. speed input: 1801.99 toks/s, output: 3949.56 toks/s]\nProcessed prompts:  23%|\u2588\u2588\u258e       | 115/500 [00:06<00:04, 89.09it/s, est. speed input: 1956.34 toks/s, output: 4326.98 toks/s]\nProcessed prompts:  25%|\u2588\u2588\u258c       | 125/500 [00:06<00:04, 89.52it/s, est. speed input: 2090.80 toks/s, output: 4661.49 toks/s]\n\nProcessed prompts:   0%|          | 1/500 [00:04<35:14,  4.24s/it, est. speed input: 25.96 toks/s, output: 46.96 toks/s]\nProcessed prompts:   1%|          | 4/500 [00:04<07:02,  1.17it/s, est. speed input: 99.46 toks/s, output: 179.93 toks/s]\nProcessed prompts:   1%|          | 5/500 [00:04<06:07,  1.35it/s, est. speed input: 112.73 toks/s, output: 207.01 toks/s]\nProcessed prompts:   2%|\u258f         | 8/500 [00:05<03:00,  2.72it/s, est. speed input: 174.51 toks/s, output: 328.19 toks/s]\nProcessed prompts:   3%|\u258e         | 14/500 [00:05<01:15,  6.44it/s, est. speed input: 298.75 toks/s, output: 577.71 toks/s]\nProcessed prompts:   4%|\u258d         | 20/500 [00:05<00:43, 10.97it/s, est. speed input: 418.35 toks/s, output: 821.87 toks/s]\nProcessed prompts:   6%|\u258c         | 28/500 [00:05<00:25, 18.21it/s, est. speed input: 573.47 toks/s, output: 1141.72 toks/s]\nProcessed prompts:   7%|\u258b         | 33/500 [00:05<00:20, 22.31it/s, est. speed input: 663.06 toks/s, output: 1333.60 toks/s]\nProcessed prompts:   8%|\u258a         | 42/500 [00:05<00:14, 32.52it/s, est. speed input: 827.24 toks/s, output: 1685.44 toks/s]\nProcessed prompts:  11%|\u2588         | 53/500 [00:05<00:09, 45.41it/s, est. speed input: 1022.87 toks/s, output: 2110.48 toks/s]\nProcessed prompts:  12%|\u2588\u258f        | 61/500 [00:05<00:08, 50.94it/s, est. speed input: 1154.12 toks/s, output: 2406.28 toks/s]\nProcessed prompts:  16%|\u2588\u258c        | 78/500 [00:05<00:05, 74.00it/s, est. speed input: 1446.23 toks/s, output: 3062.69 toks/s]\nProcessed prompts:  18%|\u2588\u258a        | 88/500 [00:06<00:05, 79.40it/s, est. speed input: 1603.70 toks/s, output: 3426.74 toks/s]\nProcessed prompts:  20%|\u2588\u2589        | 99/500 [00:06<00:04, 84.83it/s, est. speed input: 1771.84 toks/s, output: 3818.96 toks/s]\nProcessed prompts:  22%|\u2588\u2588\u258f       | 109/500 [00:06<00:04, 81.31it/s, est. speed input: 1908.70 toks/s, output: 4145.34 toks/s]\nProcessed prompts:  25%|\u2588\u2588\u258d       | 123/500 [00:06<00:04, 92.74it/s, est. speed input: 2115.41 toks/s, output: 4646.85 toks/s]\nProcessed prompts:  27%|\u2588\u2588\u258b       | 133/500 [00:06<00:03, 91.77it/s, est. speed input: 2248.02 toks/s, output: 4977.75 toks/s]\nProcessed prompts:  29%|\u2588\u2588\u258a       | 143/500 [00:06<00:03, 90.59it/s, est. speed input: 2375.42 toks/s, output: 5303.22 toks/s]\nProcessed prompts:  31%|\u2588\u2588\u2588       | 153/500 [00:06<00:03, 90.10it/s, est. speed input: 2499.07 toks/s, output: 5621.94 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 165/500 [00:06<00:03, 96.42it/s, est. speed input: 2653.08 toks/s, output: 6023.13 toks/s]\nProcessed prompts:  36%|\u2588\u2588\u2588\u258c      | 178/500 [00:06<00:03, 103.05it/s, est. speed input: 2817.18 toks/s, output: 6455.32 toks/s]\nProcessed prompts:  38%|\u2588\u2588\u2588\u258a      | 189/500 [00:07<00:03, 89.79it/s, est. speed input: 2923.47 toks/s, output: 6753.77 toks/s]\n\nProcessed prompts:   0%|          | 1/500 [00:03<33:13,  3.99s/it, est. speed input: 27.54 toks/s, output: 47.82 toks/s]\nProcessed prompts:   0%|          | 2/500 [00:04<15:00,  1.81s/it, est. speed input: 51.50 toks/s, output: 90.82 toks/s]\nProcessed prompts:   1%|          | 5/500 [00:04<04:26,  1.86it/s, est. speed input: 125.75 toks/s, output: 227.95 toks/s]\nProcessed prompts:   2%|\u258f         | 9/500 [00:04<02:01,  4.03it/s, est. speed input: 219.18 toks/s, output: 398.50 toks/s]\nProcessed prompts:   2%|\u258f         | 12/500 [00:04<01:25,  5.72it/s, est. speed input: 281.79 toks/s, output: 518.10 toks/s]\nProcessed prompts:   3%|\u258e         | 16/500 [00:05<01:09,  6.92it/s, est. speed input: 345.38 toks/s, output: 642.68 toks/s]\nProcessed prompts:   5%|\u258d         | 23/500 [00:05<00:38, 12.53it/s, est. speed input: 484.21 toks/s, output: 926.89 toks/s]\nProcessed prompts:   6%|\u258b         | 32/500 [00:05<00:23, 20.33it/s, est. speed input: 654.89 toks/s, output: 1282.06 toks/s]\nProcessed prompts:   8%|\u258a         | 38/500 [00:05<00:18, 24.99it/s, est. speed input: 760.57 toks/s, output: 1509.31 toks/s]\nProcessed prompts:   9%|\u2589         | 44/500 [00:05<00:15, 30.17it/s, est. speed input: 863.73 toks/s, output: 1732.09 toks/s]\nProcessed prompts:  10%|\u2588         | 51/500 [00:05<00:13, 34.44it/s, est. speed input: 975.43 toks/s, output: 1986.14 toks/s]\nProcessed prompts:  13%|\u2588\u258e        | 63/500 [00:05<00:08, 50.49it/s, est. speed input: 1183.31 toks/s, output: 2463.09 toks/s]\nProcessed prompts:  14%|\u2588\u258d        | 71/500 [00:05<00:07, 56.33it/s, est. speed input: 1310.27 toks/s, output: 2756.77 toks/s]\nProcessed prompts:  16%|\u2588\u258c        | 79/500 [00:06<00:06, 61.41it/s, est. speed input: 1433.11 toks/s, output: 3046.80 toks/s]\nProcessed prompts:  17%|\u2588\u258b        | 87/500 [00:06<00:06, 64.22it/s, est. speed input: 1549.78 toks/s, output: 3333.07 toks/s]\nProcessed prompts:  20%|\u2588\u2588        | 102/500 [00:06<00:05, 72.21it/s, est. speed input: 1766.72 toks/s, output: 3857.33 toks/s]\nProcessed prompts:  24%|\u2588\u2588\u258e       | 118/500 [00:06<00:04, 90.28it/s, est. speed input: 2008.41 toks/s, output: 4460.27 toks/s]\nProcessed prompts:  26%|\u2588\u2588\u258c       | 128/500 [00:06<00:04, 85.50it/s, est. speed input: 2134.33 toks/s, output: 4785.86 toks/s]\nProcessed prompts:  28%|\u2588\u2588\u258a       | 140/500 [00:06<00:03, 91.79it/s, est. speed input: 2296.28 toks/s, output: 5205.84 toks/s]\nProcessed prompts:  30%|\u2588\u2588\u2588       | 152/500 [00:06<00:03, 96.77it/s, est. speed input: 2453.24 toks/s, output: 5618.97 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 163/500 [00:06<00:03, 93.40it/s, est. speed input: 2582.31 toks/s, output: 5973.30 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258d      | 173/500 [00:07<00:03, 92.93it/s, est. speed input: 2698.37 toks/s, output: 6295.84 toks/s]\nProcessed prompts:  37%|\u2588\u2588\u2588\u258b      | 183/500 [00:07<00:03, 87.15it/s, est. speed input: 2801.47 toks/s, output: 6593.11 toks/s]\nProcessed prompts:  39%|\u2588\u2588\u2588\u258a      | 193/500 [00:07<00:03, 89.37it/s, est. speed input: 2912.09 toks/s, output: 6910.82 toks/s]\nProcessed prompts:  41%|\u2588\u2588\u2588\u2588      | 203/500 [00:07<00:03, 90.30it/s, est. speed input: 3018.29 toks/s, output: 7220.09 toks/s]\nProcessed prompts:  43%|\u2588\u2588\u2588\u2588\u258e     | 213/500 [00:07<00:03, 76.57it/s, est. speed input: 3092.35 toks/s, output: 7458.71 toks/s]\n\nProcessed prompts:   0%|          | 1/500 [00:04<36:07,  4.34s/it, est. speed input: 25.33 toks/s, output: 47.20 toks/s]\nProcessed prompts:   0%|          | 2/500 [00:04<16:45,  2.02s/it, est. speed input: 46.45 toks/s, output: 86.98 toks/s]\nProcessed prompts:   1%|          | 4/500 [00:04<06:42,  1.23it/s, est. speed input: 89.46 toks/s, output: 171.59 toks/s]\nProcessed prompts:   2%|\u258f         | 11/500 [00:05<01:44,  4.67it/s, est. speed input: 237.84 toks/s, output: 463.09 toks/s]\nProcessed prompts:   3%|\u258e         | 15/500 [00:05<01:09,  7.03it/s, est. speed input: 317.85 toks/s, output: 628.38 toks/s]\nProcessed prompts:   4%|\u258d         | 20/500 [00:05<00:44, 10.69it/s, est. speed input: 414.96 toks/s, output: 828.40 toks/s]\nProcessed prompts:   5%|\u258c         | 26/500 [00:05<00:29, 16.08it/s, est. speed input: 529.20 toks/s, output: 1065.80 toks/s]\nProcessed prompts:   6%|\u258b         | 32/500 [00:05<00:21, 21.98it/s, est. speed input: 639.25 toks/s, output: 1301.56 toks/s]\nProcessed prompts:   9%|\u258a         | 43/500 [00:05<00:12, 35.54it/s, est. speed input: 841.84 toks/s, output: 1741.35 toks/s]\nProcessed prompts:  10%|\u2588         | 50/500 [00:05<00:11, 39.51it/s, est. speed input: 956.26 toks/s, output: 1997.88 toks/s]\nProcessed prompts:  12%|\u2588\u258f        | 59/500 [00:05<00:08, 49.01it/s, est. speed input: 1108.00 toks/s, output: 2343.18 toks/s]\nProcessed prompts:  14%|\u2588\u258d        | 70/500 [00:05<00:07, 60.70it/s, est. speed input: 1289.73 toks/s, output: 2760.68 toks/s]\nProcessed prompts:  17%|\u2588\u258b        | 85/500 [00:06<00:05, 72.08it/s, est. speed input: 1526.12 toks/s, output: 3309.47 toks/s]\nProcessed prompts:  19%|\u2588\u2589        | 95/500 [00:06<00:05, 76.57it/s, est. speed input: 1675.38 toks/s, output: 3667.24 toks/s]\nProcessed prompts:  22%|\u2588\u2588\u258f       | 108/500 [00:06<00:04, 86.54it/s, est. speed input: 1870.47 toks/s, output: 4147.30 toks/s]\nProcessed prompts:  24%|\u2588\u2588\u258d       | 122/500 [00:06<00:03, 96.06it/s, est. speed input: 2075.03 toks/s, output: 4655.82 toks/s]\nProcessed prompts:  27%|\u2588\u2588\u258b       | 133/500 [00:06<00:03, 96.61it/s, est. speed input: 2223.54 toks/s, output: 5030.70 toks/s]\n\nProcessed prompts:   0%|          | 1/500 [00:04<33:23,  4.02s/it, est. speed input: 27.40 toks/s, output: 47.82 toks/s]\nProcessed prompts:   0%|          | 2/500 [00:04<15:22,  1.85s/it, est. speed input: 50.53 toks/s, output: 89.80 toks/s]\nProcessed prompts:   1%|          | 5/500 [00:04<04:49,  1.71it/s, est. speed input: 119.61 toks/s, output: 218.33 toks/s]\nProcessed prompts:   2%|\u258f         | 11/500 [00:05<02:04,  3.91it/s, est. speed input: 234.17 toks/s, output: 448.22 toks/s]\nProcessed prompts:   3%|\u258e         | 16/500 [00:05<01:14,  6.54it/s, est. speed input: 332.65 toks/s, output: 653.00 toks/s]\nProcessed prompts:   5%|\u258d         | 23/500 [00:05<00:42, 11.17it/s, est. speed input: 467.05 toks/s, output: 937.04 toks/s]\nProcessed prompts:   6%|\u258c         | 29/500 [00:05<00:30, 15.44it/s, est. speed input: 574.98 toks/s, output: 1172.49 toks/s]\nProcessed prompts:   7%|\u258b         | 37/500 [00:05<00:20, 22.76it/s, est. speed input: 719.04 toks/s, output: 1490.90 toks/s]\n\nProcessed prompts:   0%|          | 1/500 [00:04<35:57,  4.32s/it, est. speed input: 25.44 toks/s, output: 47.88 toks/s]\nProcessed prompts:   1%|          | 3/500 [00:04<10:08,  1.23s/it, est. speed input: 71.65 toks/s, output: 137.01 toks/s]\nProcessed prompts:   1%|\u258f         | 7/500 [00:04<03:22,  2.44it/s, est. speed input: 163.60 toks/s, output: 316.58 toks/s]\nProcessed prompts:   2%|\u258f         | 10/500 [00:05<02:21,  3.46it/s, est. speed input: 216.83 toks/s, output: 422.61 toks/s]\nProcessed prompts:   3%|\u258e         | 14/500 [00:05<01:23,  5.81it/s, est. speed input: 297.31 toks/s, output: 589.22 toks/s]\nProcessed prompts:   5%|\u258c         | 25/500 [00:05<00:32, 14.50it/s, est. speed input: 519.93 toks/s, output: 1050.63 toks/s]\nProcessed prompts:   6%|\u258c         | 30/500 [00:05<00:26, 17.86it/s, est. speed input: 609.76 toks/s, output: 1240.21 toks/s]\nProcessed prompts:   8%|\u258a         | 39/500 [00:05<00:17, 26.15it/s, est. speed input: 773.85 toks/s, output: 1595.33 toks/s]\nProcessed prompts:  10%|\u2588         | 50/500 [00:05<00:11, 38.27it/s, est. speed input: 972.88 toks/s, output: 2036.49 toks/s]\nProcessed prompts:  12%|\u2588\u258f        | 59/500 [00:05<00:09, 46.85it/s, est. speed input: 1126.86 toks/s, output: 2381.50 toks/s]\nProcessed prompts:  14%|\u2588\u258d        | 71/500 [00:05<00:07, 60.01it/s, est. speed input: 1330.27 toks/s, output: 2840.92 toks/s]\nProcessed prompts:  16%|\u2588\u258c        | 81/500 [00:05<00:06, 67.18it/s, est. speed input: 1489.63 toks/s, output: 3215.15 toks/s]\n\nProcessed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\nProcessed prompts:   0%|          | 1/500 [00:04<34:57,  4.20s/it, est. speed input: 26.17 toks/s, output: 47.10 toks/s]\nProcessed prompts:   0%|          | 2/500 [00:04<15:42,  1.89s/it, est. speed input: 49.11 toks/s, output: 91.75 toks/s]\nProcessed prompts:   1%|          | 4/500 [00:04<06:11,  1.33it/s, est. speed input: 95.29 toks/s, output: 180.83 toks/s]\nProcessed prompts:   1%|\u258f         | 7/500 [00:04<02:50,  2.89it/s, est. speed input: 161.87 toks/s, output: 315.53 toks/s]\n\nProcessed prompts:   0%|          | 1/500 [00:03<33:02,  3.97s/it, est. speed input: 27.69 toks/s, output: 47.07 toks/s]\nProcessed prompts:   0%|          | 2/500 [00:04<16:00,  1.93s/it, est. speed input: 49.20 toks/s, output: 89.23 toks/s]\nProcessed prompts:   1%|          | 5/500 [00:04<04:55,  1.68it/s, est. speed input: 117.65 toks/s, output: 220.76 toks/s]\nProcessed prompts:   2%|\u258f         | 11/500 [00:05<01:58,  4.13it/s, est. speed input: 237.81 toks/s, output: 461.66 toks/s]\nProcessed prompts:   3%|\u258e         | 15/500 [00:05<01:16,  6.34it/s, est. speed input: 317.84 toks/s, output: 624.51 toks/s]\nProcessed prompts:   4%|\u258d         | 21/500 [00:05<00:44, 10.65it/s, est. speed input: 436.16 toks/s, output: 871.18 toks/s]\nProcessed prompts:   5%|\u258c         | 26/500 [00:05<00:32, 14.72it/s, est. speed input: 529.97 toks/s, output: 1071.80 toks/s]\nProcessed prompts:   6%|\u258b         | 32/500 [00:05<00:22, 20.44it/s, est. speed input: 639.89 toks/s, output: 1309.59 toks/s]\nProcessed prompts:   9%|\u258a         | 43/500 [00:05<00:13, 32.75it/s, est. speed input: 839.95 toks/s, output: 1750.21 toks/s]\nProcessed prompts:  11%|\u2588         | 53/500 [00:05<00:10, 43.67it/s, est. speed input: 1015.36 toks/s, output: 2143.39 toks/s]\nProcessed prompts:  12%|\u2588\u258f        | 60/500 [00:05<00:09, 48.12it/s, est. speed input: 1128.31 toks/s, output: 2402.09 toks/s]\nProcessed prompts:  15%|\u2588\u258d        | 74/500 [00:05<00:06, 67.16it/s, est. speed input: 1366.82 toks/s, output: 2952.43 toks/s]\nProcessed prompts:  17%|\u2588\u258b        | 85/500 [00:06<00:05, 75.41it/s, est. speed input: 1541.51 toks/s, output: 3363.12 toks/s]\nProcessed prompts:  19%|\u2588\u2589        | 95/500 [00:06<00:05, 80.09it/s, est. speed input: 1693.00 toks/s, output: 3726.53 toks/s]\nINFO 02-06 18:54:15 chat_utils.py:330] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nProcessed prompts:  27%|\u2588\u2588\u258b       | 137/500 [00:06<00:03, 92.87it/s, est. speed input: 2250.81 toks/s, output: 5062.73 toks/s]\nProcessed prompts:  29%|\u2588\u2588\u2589       | 147/500 [00:06<00:04, 84.43it/s, est. speed input: 2363.33 toks/s, output: 5357.47 toks/s]\nProcessed prompts:  31%|\u2588\u2588\u2588       | 156/500 [00:06<00:04, 76.68it/s, est. speed input: 2455.02 toks/s, output: 5607.47 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 167/500 [00:07<00:04, 81.17it/s, est. speed input: 2584.43 toks/s, output: 5952.62 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258c      | 176/500 [00:07<00:05, 64.28it/s, est. speed input: 2642.16 toks/s, output: 6129.49 toks/s]\nProcessed prompts:  37%|\u2588\u2588\u2588\u258b      | 184/500 [00:07<00:04, 64.94it/s, est. speed input: 2717.92 toks/s, output: 6350.45 toks/s]\nProcessed prompts:  38%|\u2588\u2588\u2588\u258a      | 191/500 [00:07<00:05, 57.63it/s, est. speed input: 2760.35 toks/s, output: 6491.22 toks/s]\nProcessed prompts:  40%|\u2588\u2588\u2588\u2588      | 201/500 [00:07<00:04, 64.83it/s, est. speed input: 2861.61 toks/s, output: 6790.05 toks/s]\nProcessed prompts:  42%|\u2588\u2588\u2588\u2588\u258f     | 208/500 [00:07<00:04, 59.95it/s, est. speed input: 2907.31 toks/s, output: 6942.85 toks/s]\nProcessed prompts:  43%|\u2588\u2588\u2588\u2588\u258e     | 215/500 [00:07<00:04, 58.46it/s, est. speed input: 2957.01 toks/s, output: 7107.69 toks/s]\nProcessed prompts:  44%|\u2588\u2588\u2588\u2588\u258d     | 222/500 [00:08<00:05, 53.07it/s, est. speed input: 2991.78 toks/s, output: 7240.66 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258c     | 229/500 [00:08<00:05, 52.84it/s, est. speed input: 3036.28 toks/s, output: 7399.87 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 239/500 [00:08<00:04, 60.14it/s, est. speed input: 3121.43 toks/s, output: 7685.31 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 246/500 [00:08<00:06, 39.38it/s, est. speed input: 3085.88 toks/s, output: 7654.14 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 251/500 [00:09<00:10, 24.87it/s, est. speed input: 2987.38 toks/s, output: 7457.07 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 255/500 [00:10<00:18, 12.92it/s, est. speed input: 2760.55 toks/s, output: 6936.59 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 258/500 [00:10<00:26,  9.21it/s, est. speed input: 2596.15 toks/s, output: 6505.84 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 261/500 [00:11<00:22, 10.63it/s, est. speed input: 2601.06 toks/s, output: 6507.53 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 264/500 [00:11<00:19, 11.89it/s, est. speed input: 2596.42 toks/s, output: 6504.80 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 267/500 [00:11<00:16, 13.86it/s, est. speed input: 2601.94 toks/s, output: 6505.10 toks/s]\nProcessed prompts:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 273/500 [00:11<00:11, 20.06it/s, est. speed input: 2636.03 toks/s, output: 6577.33 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 278/500 [00:11<00:09, 23.25it/s, est. speed input: 2650.68 toks/s, output: 6596.87 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 282/500 [00:11<00:08, 26.17it/s, est. speed input: 2665.41 toks/s, output: 6621.68 toks/s]\n\nProcessed prompts:  40%|\u2588\u2588\u2588\u2589      | 199/500 [00:07<00:03, 83.93it/s, est. speed input: 3018.79 toks/s, output: 7026.92 toks/s]\nProcessed prompts:  42%|\u2588\u2588\u2588\u2588\u258f     | 208/500 [00:07<00:04, 67.12it/s, est. speed input: 3066.30 toks/s, output: 7190.91 toks/s]\nProcessed prompts:  43%|\u2588\u2588\u2588\u2588\u258e     | 216/500 [00:07<00:04, 61.82it/s, est. speed input: 3117.24 toks/s, output: 7364.35 toks/s]\nProcessed prompts:  45%|\u2588\u2588\u2588\u2588\u258d     | 223/500 [00:07<00:04, 57.12it/s, est. speed input: 3155.09 toks/s, output: 7501.98 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258c     | 230/500 [00:07<00:05, 47.47it/s, est. speed input: 3164.17 toks/s, output: 7575.86 toks/s]\nProcessed prompts:  47%|\u2588\u2588\u2588\u2588\u258b     | 236/500 [00:08<00:05, 47.74it/s, est. speed input: 3197.34 toks/s, output: 7702.56 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 242/500 [00:08<00:07, 34.24it/s, est. speed input: 3153.58 toks/s, output: 7648.44 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 247/500 [00:08<00:10, 24.72it/s, est. speed input: 3076.83 toks/s, output: 7511.66 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 251/500 [00:08<00:10, 24.69it/s, est. speed input: 3070.05 toks/s, output: 7537.46 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 255/500 [00:10<00:26,  9.14it/s, est. speed input: 2708.84 toks/s, output: 6689.12 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 258/500 [00:10<00:25,  9.37it/s, est. speed input: 2666.74 toks/s, output: 6593.27 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 263/500 [00:10<00:19, 12.41it/s, est. speed input: 2686.78 toks/s, output: 6624.24 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 266/500 [00:10<00:18, 12.85it/s, est. speed input: 2667.19 toks/s, output: 6562.77 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 271/500 [00:11<00:14, 16.35it/s, est. speed input: 2682.29 toks/s, output: 6584.51 toks/s]\nProcessed prompts:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 274/500 [00:11<00:12, 18.21it/s, est. speed input: 2687.70 toks/s, output: 6591.36 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 278/500 [00:11<00:15, 14.74it/s, est. speed input: 2634.83 toks/s, output: 6452.56 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 281/500 [00:11<00:13, 16.00it/s, est. speed input: 2632.06 toks/s, output: 6441.33 toks/s]\nProcessed prompts:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 289/500 [00:11<00:08, 25.29it/s, est. speed input: 2680.06 toks/s, output: 6552.94 toks/s]\nProcessed prompts:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 301/500 [00:11<00:04, 41.05it/s, est. speed input: 2764.37 toks/s, output: 6735.93 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 310/500 [00:12<00:03, 49.58it/s, est. speed input: 2820.62 toks/s, output: 6864.78 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 319/500 [00:12<00:03, 57.35it/s, est. speed input: 2876.80 toks/s, output: 6999.42 toks/s]\n\nProcessed prompts:  44%|\u2588\u2588\u2588\u2588\u258d     | 222/500 [00:07<00:04, 65.20it/s, est. speed input: 3143.14 toks/s, output: 7646.24 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258c     | 230/500 [00:07<00:04, 61.47it/s, est. speed input: 3194.10 toks/s, output: 7831.09 toks/s]\nProcessed prompts:  47%|\u2588\u2588\u2588\u2588\u258b     | 237/500 [00:08<00:04, 54.87it/s, est. speed input: 3222.14 toks/s, output: 7952.63 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u258a     | 243/500 [00:08<00:06, 38.11it/s, est. speed input: 3178.51 toks/s, output: 7897.39 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2589     | 248/500 [00:08<00:07, 32.70it/s, est. speed input: 3156.78 toks/s, output: 7890.21 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 252/500 [00:08<00:09, 24.88it/s, est. speed input: 3094.01 toks/s, output: 7776.31 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 256/500 [00:09<00:18, 12.92it/s, est. speed input: 2874.28 toks/s, output: 7254.58 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 259/500 [00:10<00:20, 11.85it/s, est. speed input: 2809.81 toks/s, output: 7095.92 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 261/500 [00:10<00:20, 11.93it/s, est. speed input: 2787.15 toks/s, output: 7029.80 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 263/500 [00:10<00:20, 11.32it/s, est. speed input: 2750.34 toks/s, output: 6926.04 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 266/500 [00:10<00:17, 13.08it/s, est. speed input: 2746.00 toks/s, output: 6904.02 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 270/500 [00:10<00:14, 15.71it/s, est. speed input: 2746.53 toks/s, output: 6892.40 toks/s]\nProcessed prompts:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 274/500 [00:10<00:12, 17.99it/s, est. speed input: 2747.33 toks/s, output: 6877.43 toks/s]\nProcessed prompts:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 277/500 [00:11<00:11, 18.84it/s, est. speed input: 2742.86 toks/s, output: 6863.27 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 282/500 [00:11<00:09, 23.96it/s, est. speed input: 2763.08 toks/s, output: 6899.68 toks/s]\nProcessed prompts:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 287/500 [00:11<00:07, 28.57it/s, est. speed input: 2783.91 toks/s, output: 6936.21 toks/s]\nProcessed prompts:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 296/500 [00:11<00:04, 41.19it/s, est. speed input: 2843.00 toks/s, output: 7065.50 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 312/500 [00:11<00:02, 64.99it/s, est. speed input: 2963.37 toks/s, output: 7331.92 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 320/500 [00:11<00:02, 67.38it/s, est. speed input: 3011.39 toks/s, output: 7432.40 toks/s]\nProcessed prompts:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 328/500 [00:12<00:04, 39.67it/s, est. speed input: 2982.55 toks/s, output: 7354.12 toks/s]\nProcessed prompts:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 342/500 [00:12<00:02, 56.48it/s, est. speed input: 3084.02 toks/s, output: 7603.72 toks/s]\nProcessed prompts:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 355/500 [00:12<00:02, 67.16it/s, est. speed input: 3168.14 toks/s, output: 7804.82 toks/s]\nProcessed prompts:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 364/500 [00:12<00:01, 68.70it/s, est. speed input: 3216.51 toks/s, output: 7926.94 toks/s]\nProcessed prompts:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 384/500 [00:12<00:01, 96.85it/s, est. speed input: 3365.06 toks/s, output: 8290.11 toks/s]\nProcessed prompts:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 399/500 [00:12<00:00, 103.40it/s, est. speed input: 3462.07 toks/s, output: 8542.69 toks/s]\n\nProcessed prompts:  29%|\u2588\u2588\u2589       | 144/500 [00:06<00:04, 79.53it/s, est. speed input: 2336.80 toks/s, output: 5331.83 toks/s]\nProcessed prompts:  31%|\u2588\u2588\u2588       | 156/500 [00:06<00:04, 85.52it/s, est. speed input: 2488.67 toks/s, output: 5734.81 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 166/500 [00:07<00:03, 86.58it/s, est. speed input: 2606.02 toks/s, output: 6052.35 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258c      | 176/500 [00:07<00:03, 84.36it/s, est. speed input: 2714.03 toks/s, output: 6353.98 toks/s]\nProcessed prompts:  37%|\u2588\u2588\u2588\u258b      | 185/500 [00:07<00:03, 80.46it/s, est. speed input: 2803.16 toks/s, output: 6606.91 toks/s]\nProcessed prompts:  39%|\u2588\u2588\u2588\u2589      | 194/500 [00:07<00:03, 81.60it/s, est. speed input: 2897.17 toks/s, output: 6879.20 toks/s]\nProcessed prompts:  41%|\u2588\u2588\u2588\u2588      | 203/500 [00:07<00:03, 74.41it/s, est. speed input: 2971.75 toks/s, output: 7108.51 toks/s]\nProcessed prompts:  42%|\u2588\u2588\u2588\u2588\u258f     | 211/500 [00:07<00:04, 70.78it/s, est. speed input: 3036.95 toks/s, output: 7316.40 toks/s]\nProcessed prompts:  44%|\u2588\u2588\u2588\u2588\u258d     | 219/500 [00:07<00:04, 66.74it/s, est. speed input: 3096.15 toks/s, output: 7513.13 toks/s]\nProcessed prompts:  45%|\u2588\u2588\u2588\u2588\u258c     | 226/500 [00:07<00:05, 54.23it/s, est. speed input: 3115.03 toks/s, output: 7608.37 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258b     | 232/500 [00:08<00:05, 51.63it/s, est. speed input: 3144.91 toks/s, output: 7723.98 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 238/500 [00:08<00:07, 37.14it/s, est. speed input: 3113.01 toks/s, output: 7696.44 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u258a     | 243/500 [00:08<00:07, 34.41it/s, est. speed input: 3111.51 toks/s, output: 7736.74 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 247/500 [00:08<00:08, 28.32it/s, est. speed input: 3078.33 toks/s, output: 7691.64 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 251/500 [00:09<00:16, 14.71it/s, est. speed input: 2895.69 toks/s, output: 7282.10 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 254/500 [00:09<00:20, 11.90it/s, est. speed input: 2798.91 toks/s, output: 7057.87 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 256/500 [00:10<00:23, 10.33it/s, est. speed input: 2731.07 toks/s, output: 6894.67 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 258/500 [00:10<00:22, 10.63it/s, est. speed input: 2709.17 toks/s, output: 6830.77 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 260/500 [00:10<00:21, 10.93it/s, est. speed input: 2688.16 toks/s, output: 6768.99 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 262/500 [00:10<00:20, 11.81it/s, est. speed input: 2677.81 toks/s, output: 6734.00 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 266/500 [00:10<00:14, 16.31it/s, est. speed input: 2692.91 toks/s, output: 6774.59 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 269/500 [00:11<00:14, 16.33it/s, est. speed input: 2678.17 toks/s, output: 6727.00 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 272/500 [00:11<00:12, 18.24it/s, est. speed input: 2679.08 toks/s, output: 6719.54 toks/s]\nProcessed prompts:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 277/500 [00:11<00:14, 15.52it/s, est. speed input: 2636.29 toks/s, output: 6597.98 toks/s]\n\nProcessed prompts:   8%|\u258a         | 42/500 [00:05<00:17, 25.68it/s, est. speed input: 798.38 toks/s, output: 1675.22 toks/s]\nProcessed prompts:  11%|\u2588         | 53/500 [00:05<00:11, 38.51it/s, est. speed input: 987.61 toks/s, output: 2111.24 toks/s]\nProcessed prompts:  13%|\u2588\u258e        | 63/500 [00:06<00:08, 49.13it/s, est. speed input: 1152.67 toks/s, output: 2498.44 toks/s]\nProcessed prompts:  15%|\u2588\u258c        | 75/500 [00:06<00:06, 61.86it/s, est. speed input: 1346.40 toks/s, output: 2964.20 toks/s]\nProcessed prompts:  17%|\u2588\u258b        | 85/500 [00:06<00:05, 69.25it/s, est. speed input: 1499.67 toks/s, output: 3337.45 toks/s]\nProcessed prompts:  20%|\u2588\u2588        | 102/500 [00:06<00:04, 89.56it/s, est. speed input: 1766.32 toks/s, output: 3990.42 toks/s]\nProcessed prompts:  23%|\u2588\u2588\u258e       | 117/500 [00:06<00:03, 100.65it/s, est. speed input: 1989.93 toks/s, output: 4548.52 toks/s]\nProcessed prompts:  26%|\u2588\u2588\u258c       | 129/500 [00:06<00:03, 101.65it/s, est. speed input: 2155.64 toks/s, output: 4965.25 toks/s]\nProcessed prompts:  28%|\u2588\u2588\u258a       | 140/500 [00:06<00:03, 101.49it/s, est. speed input: 2301.40 toks/s, output: 5344.48 toks/s]\nProcessed prompts:  30%|\u2588\u2588\u2588       | 151/500 [00:06<00:03, 94.86it/s, est. speed input: 2433.02 toks/s, output: 5699.37 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 163/500 [00:06<00:03, 98.13it/s, est. speed input: 2583.74 toks/s, output: 6104.42 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258d      | 174/500 [00:07<00:03, 83.00it/s, est. speed input: 2686.96 toks/s, output: 6401.39 toks/s]\nProcessed prompts:  37%|\u2588\u2588\u2588\u258b      | 183/500 [00:07<00:03, 80.25it/s, est. speed input: 2777.87 toks/s, output: 6667.02 toks/s]\nProcessed prompts:  38%|\u2588\u2588\u2588\u258a      | 192/500 [00:07<00:04, 71.91it/s, est. speed input: 2850.91 toks/s, output: 6894.95 toks/s]\nProcessed prompts:  40%|\u2588\u2588\u2588\u2588      | 202/500 [00:07<00:03, 76.70it/s, est. speed input: 2955.67 toks/s, output: 7205.59 toks/s]\nProcessed prompts:  42%|\u2588\u2588\u2588\u2588\u258f     | 211/500 [00:07<00:04, 70.60it/s, est. speed input: 3025.30 toks/s, output: 7433.02 toks/s]\nProcessed prompts:  44%|\u2588\u2588\u2588\u2588\u258d     | 219/500 [00:07<00:04, 68.19it/s, est. speed input: 3088.14 toks/s, output: 7640.73 toks/s]\nProcessed prompts:  45%|\u2588\u2588\u2588\u2588\u258c     | 227/500 [00:08<00:06, 44.64it/s, est. speed input: 3064.72 toks/s, output: 7638.47 toks/s]\nProcessed prompts:  47%|\u2588\u2588\u2588\u2588\u258b     | 234/500 [00:08<00:05, 48.61it/s, est. speed input: 3118.68 toks/s, output: 7827.93 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 240/500 [00:08<00:06, 39.66it/s, est. speed input: 3107.69 toks/s, output: 7847.39 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 245/500 [00:08<00:06, 38.36it/s, est. speed input: 3119.01 toks/s, output: 7920.76 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 250/500 [00:09<00:11, 21.37it/s, est. speed input: 2987.47 toks/s, output: 7639.21 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 254/500 [00:09<00:17, 14.04it/s, est. speed input: 2836.88 toks/s, output: 7303.48 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 257/500 [00:10<00:22, 10.70it/s, est. speed input: 2713.19 toks/s, output: 6990.75 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 259/500 [00:10<00:21, 11.09it/s, est. speed input: 2697.21 toks/s, output: 6938.23 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 262/500 [00:10<00:18, 13.06it/s, est. speed input: 2701.92 toks/s, output: 6955.99 toks/s]\n\nProcessed prompts:  20%|\u2588\u2589        | 99/500 [00:06<00:04, 90.57it/s, est. speed input: 1786.70 toks/s, output: 3910.71 toks/s]\nProcessed prompts:  22%|\u2588\u2588\u258f       | 111/500 [00:06<00:04, 95.56it/s, est. speed input: 1967.96 toks/s, output: 4342.08 toks/s]\nProcessed prompts:  24%|\u2588\u2588\u258d       | 122/500 [00:06<00:04, 80.60it/s, est. speed input: 2098.38 toks/s, output: 4669.43 toks/s]\nProcessed prompts:  27%|\u2588\u2588\u258b       | 136/500 [00:06<00:03, 91.83it/s, est. speed input: 2299.29 toks/s, output: 5172.92 toks/s]\nProcessed prompts:  29%|\u2588\u2588\u2589       | 147/500 [00:06<00:03, 93.89it/s, est. speed input: 2443.85 toks/s, output: 5544.22 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 165/500 [00:06<00:03, 110.54it/s, est. speed input: 2695.04 toks/s, output: 6192.64 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258c      | 177/500 [00:06<00:03, 105.72it/s, est. speed input: 2837.62 toks/s, output: 6577.67 toks/s]\nProcessed prompts:  38%|\u2588\u2588\u2588\u258a      | 189/500 [00:07<00:03, 89.38it/s, est. speed input: 2949.31 toks/s, output: 6900.45 toks/s]\nProcessed prompts:  40%|\u2588\u2588\u2588\u2589      | 199/500 [00:07<00:03, 76.56it/s, est. speed input: 3025.15 toks/s, output: 7135.69 toks/s]\nProcessed prompts:  42%|\u2588\u2588\u2588\u2588\u258f     | 208/500 [00:07<00:04, 72.22it/s, est. speed input: 3099.17 toks/s, output: 7364.31 toks/s]\nProcessed prompts:  43%|\u2588\u2588\u2588\u2588\u258e     | 216/500 [00:07<00:04, 69.17it/s, est. speed input: 3162.06 toks/s, output: 7566.18 toks/s]\nProcessed prompts:  45%|\u2588\u2588\u2588\u2588\u258d     | 224/500 [00:07<00:03, 71.23it/s, est. speed input: 3235.09 toks/s, output: 7794.41 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258b     | 232/500 [00:07<00:04, 62.62it/s, est. speed input: 3277.20 toks/s, output: 7953.24 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 239/500 [00:07<00:04, 56.59it/s, est. speed input: 3308.24 toks/s, output: 8082.61 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 245/500 [00:08<00:05, 43.23it/s, est. speed input: 3289.27 toks/s, output: 8084.28 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 250/500 [00:08<00:07, 31.95it/s, est. speed input: 3236.55 toks/s, output: 8001.09 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 254/500 [00:09<00:16, 15.04it/s, est. speed input: 2994.78 toks/s, output: 7451.79 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 257/500 [00:09<00:21, 11.24it/s, est. speed input: 2851.91 toks/s, output: 7116.25 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 260/500 [00:10<00:27,  8.74it/s, est. speed input: 2708.27 toks/s, output: 6746.24 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 264/500 [00:10<00:21, 10.81it/s, est. speed input: 2713.72 toks/s, output: 6741.20 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 268/500 [00:10<00:19, 12.02it/s, est. speed input: 2694.77 toks/s, output: 6681.16 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 271/500 [00:11<00:16, 13.69it/s, est. speed input: 2695.73 toks/s, output: 6675.93 toks/s]\n\nProcessed prompts:   2%|\u258f         | 9/500 [00:05<02:21,  3.47it/s, est. speed input: 193.31 toks/s, output: 381.55 toks/s]\nProcessed prompts:   2%|\u258f         | 11/500 [00:05<01:41,  4.80it/s, est. speed input: 231.75 toks/s, output: 461.38 toks/s]\nProcessed prompts:   4%|\u258e         | 18/500 [00:05<00:42, 11.21it/s, est. speed input: 370.27 toks/s, output: 750.26 toks/s]\nProcessed prompts:   5%|\u258d         | 23/500 [00:05<00:30, 15.83it/s, est. speed input: 463.37 toks/s, output: 945.97 toks/s]\nProcessed prompts:   6%|\u258c         | 28/500 [00:05<00:23, 20.20it/s, est. speed input: 551.50 toks/s, output: 1135.04 toks/s]\nProcessed prompts:   7%|\u258b         | 35/500 [00:05<00:16, 28.44it/s, est. speed input: 676.57 toks/s, output: 1410.07 toks/s]\nProcessed prompts:   9%|\u2589         | 44/500 [00:05<00:11, 38.38it/s, est. speed input: 831.89 toks/s, output: 1762.26 toks/s]\nProcessed prompts:  11%|\u2588\u258f        | 57/500 [00:05<00:08, 54.70it/s, est. speed input: 1055.05 toks/s, output: 2266.91 toks/s]\nProcessed prompts:  14%|\u2588\u258e        | 68/500 [00:06<00:06, 65.38it/s, est. speed input: 1235.63 toks/s, output: 2685.34 toks/s]\nProcessed prompts:  16%|\u2588\u258b        | 82/500 [00:06<00:05, 76.42it/s, est. speed input: 1457.20 toks/s, output: 3211.65 toks/s]\nProcessed prompts:  20%|\u2588\u2589        | 98/500 [00:06<00:04, 93.09it/s, est. speed input: 1709.99 toks/s, output: 3816.54 toks/s]\nProcessed prompts:  22%|\u2588\u2588\u258f       | 109/500 [00:06<00:04, 94.39it/s, est. speed input: 1868.63 toks/s, output: 4201.68 toks/s]\nProcessed prompts:  24%|\u2588\u2588\u258d       | 120/500 [00:06<00:03, 95.60it/s, est. speed input: 2022.12 toks/s, output: 4587.29 toks/s]\nProcessed prompts:  26%|\u2588\u2588\u258b       | 132/500 [00:06<00:03, 97.55it/s, est. speed input: 2185.04 toks/s, output: 5001.50 toks/s]\nProcessed prompts:  29%|\u2588\u2588\u258a       | 143/500 [00:06<00:03, 97.92it/s, est. speed input: 2328.13 toks/s, output: 5371.87 toks/s]\nProcessed prompts:  31%|\u2588\u2588\u2588       | 154/500 [00:06<00:03, 99.04it/s, est. speed input: 2467.78 toks/s, output: 5742.91 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 165/500 [00:07<00:03, 92.74it/s, est. speed input: 2592.41 toks/s, output: 6077.10 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258c      | 175/500 [00:07<00:04, 81.12it/s, est. speed input: 2686.67 toks/s, output: 6345.12 toks/s]\nProcessed prompts:  37%|\u2588\u2588\u2588\u258b      | 184/500 [00:07<00:03, 81.73it/s, est. speed input: 2782.98 toks/s, output: 6620.84 toks/s]\nProcessed prompts:  39%|\u2588\u2588\u2588\u258a      | 193/500 [00:07<00:04, 73.44it/s, est. speed input: 2857.88 toks/s, output: 6851.24 toks/s]\nProcessed prompts:  40%|\u2588\u2588\u2588\u2588      | 201/500 [00:07<00:04, 74.28it/s, est. speed input: 2935.19 toks/s, output: 7081.09 toks/s]\nProcessed prompts:  42%|\u2588\u2588\u2588\u2588\u258f     | 209/500 [00:07<00:03, 74.35it/s, est. speed input: 3009.14 toks/s, output: 7305.71 toks/s]\nProcessed prompts:  43%|\u2588\u2588\u2588\u2588\u258e     | 217/500 [00:07<00:03, 75.29it/s, est. speed input: 3082.87 toks/s, output: 7537.08 toks/s]\nProcessed prompts:  45%|\u2588\u2588\u2588\u2588\u258c     | 225/500 [00:08<00:05, 51.76it/s, est. speed input: 3086.30 toks/s, output: 7596.52 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258b     | 232/500 [00:08<00:06, 39.83it/s, est. speed input: 3071.27 toks/s, output: 7615.22 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 238/500 [00:08<00:08, 32.28it/s, est. speed input: 3042.38 toks/s, output: 7596.05 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u258a     | 243/500 [00:08<00:09, 26.39it/s, est. speed input: 2998.60 toks/s, output: 7535.19 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 247/500 [00:09<00:09, 25.38it/s, est. speed input: 2987.25 toks/s, output: 7550.46 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 251/500 [00:09<00:13, 17.91it/s, est. speed input: 2892.87 toks/s, output: 7356.12 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 254/500 [00:09<00:13, 17.96it/s, est. speed input: 2877.68 toks/s, output: 7355.38 toks/s]\n\nProcessed prompts:  21%|\u2588\u2588        | 105/500 [00:06<00:04, 84.10it/s, est. speed input: 1839.88 toks/s, output: 4078.15 toks/s]\nProcessed prompts:  24%|\u2588\u2588\u258d       | 121/500 [00:06<00:03, 100.88it/s, est. speed input: 2082.85 toks/s, output: 4676.77 toks/s]\nProcessed prompts:  26%|\u2588\u2588\u258b       | 132/500 [00:06<00:03, 95.80it/s, est. speed input: 2227.15 toks/s, output: 5045.28 toks/s]\nProcessed prompts:  29%|\u2588\u2588\u258a       | 143/500 [00:06<00:03, 92.27it/s, est. speed input: 2365.58 toks/s, output: 5403.99 toks/s]\nProcessed prompts:  31%|\u2588\u2588\u2588       | 153/500 [00:06<00:03, 87.97it/s, est. speed input: 2483.32 toks/s, output: 5715.01 toks/s]\nProcessed prompts:  33%|\u2588\u2588\u2588\u258e      | 164/500 [00:06<00:03, 91.98it/s, est. speed input: 2620.51 toks/s, output: 6077.85 toks/s]\nProcessed prompts:  35%|\u2588\u2588\u2588\u258d      | 174/500 [00:07<00:03, 82.64it/s, est. speed input: 2720.05 toks/s, output: 6363.40 toks/s]\nProcessed prompts:  37%|\u2588\u2588\u2588\u258b      | 183/500 [00:07<00:03, 79.53it/s, est. speed input: 2810.83 toks/s, output: 6623.82 toks/s]\nProcessed prompts:  39%|\u2588\u2588\u2588\u258a      | 193/500 [00:07<00:03, 84.18it/s, est. speed input: 2922.68 toks/s, output: 6941.99 toks/s]\nProcessed prompts:  41%|\u2588\u2588\u2588\u2588      | 204/500 [00:07<00:03, 89.15it/s, est. speed input: 3044.10 toks/s, output: 7293.61 toks/s]\nProcessed prompts:  43%|\u2588\u2588\u2588\u2588\u258e     | 214/500 [00:07<00:03, 80.63it/s, est. speed input: 3128.49 toks/s, output: 7557.26 toks/s]\nProcessed prompts:  45%|\u2588\u2588\u2588\u2588\u258d     | 223/500 [00:07<00:04, 69.00it/s, est. speed input: 3183.67 toks/s, output: 7750.73 toks/s]\nProcessed prompts:  46%|\u2588\u2588\u2588\u2588\u258c     | 231/500 [00:07<00:03, 71.31it/s, est. speed input: 3255.06 toks/s, output: 7980.84 toks/s]\nProcessed prompts:  48%|\u2588\u2588\u2588\u2588\u258a     | 239/500 [00:08<00:05, 52.05it/s, est. speed input: 3256.60 toks/s, output: 8044.85 toks/s]\nProcessed prompts:  49%|\u2588\u2588\u2588\u2588\u2589     | 246/500 [00:08<00:08, 28.71it/s, est. speed input: 3131.28 toks/s, output: 7796.36 toks/s]\nProcessed prompts:  50%|\u2588\u2588\u2588\u2588\u2588     | 251/500 [00:08<00:08, 27.77it/s, est. speed input: 3121.52 toks/s, output: 7827.65 toks/s]\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588     | 256/500 [00:09<00:17, 14.21it/s, est. speed input: 2877.75 toks/s, output: 7275.59 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 259/500 [00:10<00:17, 14.14it/s, est. speed input: 2848.14 toks/s, output: 7177.14 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 262/500 [00:10<00:18, 12.68it/s, est. speed input: 2785.82 toks/s, output: 7005.70 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 265/500 [00:10<00:21, 10.72it/s, est. speed input: 2702.66 toks/s, output: 6789.66 toks/s]\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 267/500 [00:11<00:22, 10.25it/s, est. speed input: 2664.46 toks/s, output: 6686.46 toks/s]\nProcessed prompts:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 273/500 [00:11<00:14, 15.39it/s, est. speed input: 2695.38 toks/s, output: 6748.50 toks/s]\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nProcessed prompts:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 297/500 [00:11<00:04, 47.30it/s, est. speed input: 2773.55 toks/s, output: 6857.97 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 309/500 [00:11<00:03, 60.69it/s, est. speed input: 2857.67 toks/s, output: 7047.83 toks/s]\nProcessed prompts:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 317/500 [00:12<00:03, 60.93it/s, est. speed input: 2899.99 toks/s, output: 7142.01 toks/s]\nProcessed prompts:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 324/500 [00:12<00:03, 57.22it/s, est. speed input: 2928.99 toks/s, output: 7201.24 toks/s]\nProcessed prompts:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 337/500 [00:12<00:02, 63.14it/s, est. speed input: 3003.39 toks/s, output: 7373.64 toks/s]\nProcessed prompts:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 344/500 [00:12<00:02, 64.56it/s, est. speed input: 3040.99 toks/s, output: 7456.19 toks/s]\nProcessed prompts:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 362/500 [00:12<00:02, 50.80it/s, est. speed input: 3090.66 toks/s, output: 7578.47 toks/s]\nProcessed prompts:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 377/500 [00:12<00:01, 65.68it/s, est. speed input: 3191.97 toks/s, output: 7825.60 toks/s]\nProcessed prompts:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 390/500 [00:13<00:01, 76.24it/s, est. speed input: 3274.69 toks/s, output: 8033.22 toks/s]\nProcessed prompts:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 400/500 [00:13<00:01, 81.07it/s, est. speed input: 3333.19 toks/s, output: 8181.22 toks/s]\nProcessed prompts:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 416/500 [00:13<00:00, 97.60it/s, est. speed input: 3438.92 toks/s, output: 8464.86 toks/s]\nProcessed prompts:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 435/500 [00:13<00:00, 117.40it/s, est. speed input: 3566.79 toks/s, output: 8796.37 toks/s]\nProcessed prompts:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 449/500 [00:13<00:00, 120.77it/s, est. speed input: 3652.28 toks/s, output: 9028.64 toks/s]\nProcessed prompts:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 463/500 [00:13<00:00, 117.88it/s, est. speed input: 3731.47 toks/s, output: 9272.77 toks/s]\nProcessed prompts:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 476/500 [00:13<00:00, 119.02it/s, est. speed input: 3806.54 toks/s, output: 9502.24 toks/s]\nProcessed prompts:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 489/500 [00:13<00:00, 115.30it/s, est. speed input: 3876.24 toks/s, output: 9734.04 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:14<00:00, 35.45it/s, est. speed input: 3899.34 toks/s, output: 9846.60 toks/s]\n[rank0]:[W206 18:54:29.231957832 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nProcessed prompts:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 328/500 [00:12<00:02, 64.01it/s, est. speed input: 2932.37 toks/s, output: 7120.10 toks/s]\nProcessed prompts:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 342/500 [00:12<00:01, 82.06it/s, est. speed input: 3031.98 toks/s, output: 7351.77 toks/s]\nProcessed prompts:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 354/500 [00:12<00:01, 88.26it/s, est. speed input: 3109.32 toks/s, output: 7545.16 toks/s]\nProcessed prompts:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 366/500 [00:12<00:01, 93.66it/s, est. speed input: 3186.25 toks/s, output: 7738.23 toks/s]\nProcessed prompts:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 381/500 [00:12<00:01, 108.48it/s, est. speed input: 3290.61 toks/s, output: 8002.11 toks/s]\nProcessed prompts:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 400/500 [00:12<00:00, 129.93it/s, est. speed input: 3427.04 toks/s, output: 8377.24 toks/s]\nProcessed prompts:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 419/500 [00:12<00:00, 145.21it/s, est. speed input: 3561.01 toks/s, output: 8746.45 toks/s]\nProcessed prompts:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 434/500 [00:13<00:00, 145.38it/s, est. speed input: 3659.40 toks/s, output: 8996.11 toks/s]\nProcessed prompts:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 449/500 [00:13<00:00, 139.04it/s, est. speed input: 3751.60 toks/s, output: 9243.77 toks/s]\nProcessed prompts:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 465/500 [00:13<00:00, 144.03it/s, est. speed input: 3855.36 toks/s, output: 9542.45 toks/s]\nProcessed prompts:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 480/500 [00:13<00:00, 120.05it/s, est. speed input: 3927.85 toks/s, output: 9753.42 toks/s]\nProcessed prompts:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 493/500 [00:13<00:00, 111.99it/s, est. speed input: 3993.35 toks/s, output: 9974.03 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:13<00:00, 35.88it/s, est. speed input: 3947.06 toks/s, output: 9915.43 toks/s]\n[rank0]:[W206 18:54:28.463722036 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nProcessed prompts:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 411/500 [00:12<00:00, 106.39it/s, est. speed input: 3537.17 toks/s, output: 8754.26 toks/s]\nProcessed prompts:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 429/500 [00:12<00:00, 122.59it/s, est. speed input: 3661.02 toks/s, output: 9080.53 toks/s]\nProcessed prompts:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 448/500 [00:12<00:00, 137.74it/s, est. speed input: 3791.62 toks/s, output: 9431.49 toks/s]\nProcessed prompts:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 465/500 [00:13<00:00, 138.40it/s, est. speed input: 3899.03 toks/s, output: 9727.22 toks/s]\nProcessed prompts:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 480/500 [00:13<00:00, 127.75it/s, est. speed input: 3982.22 toks/s, output: 9981.86 toks/s]\nProcessed prompts:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 494/500 [00:13<00:00, 85.50it/s, est. speed input: 4005.56 toks/s, output: 10116.79 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:13<00:00, 36.03it/s, est. speed input: 3963.07 toks/s, output: 10065.46 toks/s]\n[rank0]:[W206 18:54:28.970652580 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nProcessed prompts:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 284/500 [00:11<00:09, 23.94it/s, est. speed input: 2679.43 toks/s, output: 6680.47 toks/s]\nProcessed prompts:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 291/500 [00:11<00:06, 31.25it/s, est. speed input: 2717.82 toks/s, output: 6762.88 toks/s]\nProcessed prompts:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 301/500 [00:11<00:04, 43.68it/s, est. speed input: 2783.91 toks/s, output: 6893.01 toks/s]\nProcessed prompts:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 307/500 [00:12<00:04, 44.38it/s, est. speed input: 2808.82 toks/s, output: 6946.10 toks/s]\nProcessed prompts:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 313/500 [00:12<00:04, 45.11it/s, est. speed input: 2833.66 toks/s, output: 6996.58 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 320/500 [00:12<00:03, 50.13it/s, est. speed input: 2871.83 toks/s, output: 7084.19 toks/s]\nProcessed prompts:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 331/500 [00:12<00:02, 64.32it/s, est. speed input: 2945.62 toks/s, output: 7257.91 toks/s]\nProcessed prompts:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 340/500 [00:12<00:02, 70.70it/s, est. speed input: 3001.07 toks/s, output: 7385.67 toks/s]\nProcessed prompts:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 352/500 [00:12<00:01, 83.77it/s, est. speed input: 3082.04 toks/s, output: 7588.79 toks/s]\nProcessed prompts:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 365/500 [00:12<00:01, 89.63it/s, est. speed input: 3163.62 toks/s, output: 7785.66 toks/s]\nProcessed prompts:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 378/500 [00:12<00:01, 100.24it/s, est. speed input: 3250.47 toks/s, output: 8007.10 toks/s]\nProcessed prompts:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 396/500 [00:12<00:00, 120.67it/s, est. speed input: 3377.53 toks/s, output: 8330.22 toks/s]\nProcessed prompts:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 414/500 [00:13<00:00, 134.39it/s, est. speed input: 3501.79 toks/s, output: 8665.80 toks/s]\nProcessed prompts:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 431/500 [00:13<00:00, 141.68it/s, est. speed input: 3615.86 toks/s, output: 8970.16 toks/s]\nProcessed prompts:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 452/500 [00:13<00:00, 157.91it/s, est. speed input: 3761.35 toks/s, output: 9367.29 toks/s]\nProcessed prompts:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 471/500 [00:13<00:00, 165.56it/s, est. speed input: 3889.13 toks/s, output: 9727.84 toks/s]\nProcessed prompts:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 488/500 [00:13<00:00, 121.60it/s, est. speed input: 3961.20 toks/s, output: 9951.40 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:14<00:00, 35.33it/s, est. speed input: 3886.46 toks/s, output: 9856.47 toks/s]\n[rank0]:[W206 18:54:29.362711747 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nProcessed prompts:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 266/500 [00:10<00:17, 13.65it/s, est. speed input: 2676.82 toks/s, output: 6870.07 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 270/500 [00:11<00:15, 15.10it/s, est. speed input: 2667.56 toks/s, output: 6828.50 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 272/500 [00:11<00:14, 15.80it/s, est. speed input: 2663.27 toks/s, output: 6816.44 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 278/500 [00:11<00:09, 22.53it/s, est. speed input: 2693.01 toks/s, output: 6872.81 toks/s]\nProcessed prompts:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 284/500 [00:11<00:07, 28.72it/s, est. speed input: 2723.01 toks/s, output: 6933.39 toks/s]\nProcessed prompts:  59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 293/500 [00:11<00:05, 38.43it/s, est. speed input: 2775.83 toks/s, output: 7050.16 toks/s]\nProcessed prompts:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 302/500 [00:11<00:04, 48.17it/s, est. speed input: 2833.40 toks/s, output: 7175.68 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 312/500 [00:11<00:03, 56.29it/s, est. speed input: 2895.21 toks/s, output: 7317.32 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 321/500 [00:12<00:04, 37.38it/s, est. speed input: 2880.40 toks/s, output: 7261.36 toks/s]\nProcessed prompts:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 329/500 [00:12<00:03, 44.03it/s, est. speed input: 2927.20 toks/s, output: 7375.02 toks/s]\nProcessed prompts:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 339/500 [00:12<00:02, 54.36it/s, est. speed input: 2991.45 toks/s, output: 7515.43 toks/s]\nProcessed prompts:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 353/500 [00:12<00:02, 72.41it/s, est. speed input: 3090.09 toks/s, output: 7751.79 toks/s]\nProcessed prompts:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 366/500 [00:12<00:01, 83.65it/s, est. speed input: 3175.86 toks/s, output: 7961.03 toks/s]\nProcessed prompts:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 379/500 [00:12<00:01, 91.75it/s, est. speed input: 3259.26 toks/s, output: 8179.81 toks/s]\nProcessed prompts:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 390/500 [00:12<00:01, 95.41it/s, est. speed input: 3326.83 toks/s, output: 8347.62 toks/s]\nProcessed prompts:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 404/500 [00:13<00:00, 104.59it/s, est. speed input: 3417.30 toks/s, output: 8583.01 toks/s]\nProcessed prompts:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 419/500 [00:13<00:00, 116.51it/s, est. speed input: 3516.92 toks/s, output: 8853.32 toks/s]\nProcessed prompts:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 433/500 [00:13<00:00, 122.40it/s, est. speed input: 3606.41 toks/s, output: 9097.64 toks/s]\nProcessed prompts:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 446/500 [00:13<00:00, 114.93it/s, est. speed input: 3678.57 toks/s, output: 9294.13 toks/s]\nProcessed prompts:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 467/500 [00:13<00:00, 133.82it/s, est. speed input: 3817.72 toks/s, output: 9692.27 toks/s]\nProcessed prompts:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 481/500 [00:13<00:00, 134.25it/s, est. speed input: 3902.19 toks/s, output: 9951.04 toks/s]\nProcessed prompts:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 495/500 [00:13<00:00, 73.09it/s, est. speed input: 3897.58 toks/s, output: 10023.16 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:14<00:00, 33.96it/s, est. speed input: 3736.13 toks/s, output: 9661.16 toks/s]\n\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 279/500 [00:11<00:09, 22.39it/s, est. speed input: 2750.11 toks/s, output: 6793.98 toks/s]\nProcessed prompts:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 291/500 [00:11<00:05, 35.73it/s, est. speed input: 2833.55 toks/s, output: 6970.91 toks/s]\nProcessed prompts:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 298/500 [00:11<00:07, 26.11it/s, est. speed input: 2792.74 toks/s, output: 6860.68 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 309/500 [00:11<00:05, 36.86it/s, est. speed input: 2868.28 toks/s, output: 7026.66 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 320/500 [00:11<00:03, 47.92it/s, est. speed input: 2943.46 toks/s, output: 7195.07 toks/s]\nProcessed prompts:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 329/500 [00:12<00:03, 52.06it/s, est. speed input: 2991.80 toks/s, output: 7299.86 toks/s]\nProcessed prompts:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 339/500 [00:12<00:02, 61.29it/s, est. speed input: 3056.96 toks/s, output: 7458.85 toks/s]\nProcessed prompts:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 353/500 [00:12<00:01, 75.65it/s, est. speed input: 3152.84 toks/s, output: 7686.40 toks/s]\nProcessed prompts:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 363/500 [00:12<00:01, 79.22it/s, est. speed input: 3213.13 toks/s, output: 7829.79 toks/s]\nProcessed prompts:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 378/500 [00:12<00:01, 95.79it/s, est. speed input: 3318.39 toks/s, output: 8089.99 toks/s]\nProcessed prompts:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 389/500 [00:12<00:01, 94.73it/s, est. speed input: 3382.73 toks/s, output: 8255.95 toks/s]\nProcessed prompts:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 406/500 [00:12<00:00, 110.86it/s, est. speed input: 3499.65 toks/s, output: 8574.92 toks/s]\nProcessed prompts:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 425/500 [00:12<00:00, 131.38it/s, est. speed input: 3634.62 toks/s, output: 8942.87 toks/s]\nProcessed prompts:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 441/500 [00:12<00:00, 138.14it/s, est. speed input: 3741.55 toks/s, output: 9233.15 toks/s]\nProcessed prompts:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 456/500 [00:13<00:00, 136.05it/s, est. speed input: 3835.03 toks/s, output: 9504.23 toks/s]\nProcessed prompts:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 470/500 [00:13<00:00, 136.82it/s, est. speed input: 3922.52 toks/s, output: 9765.01 toks/s]\nProcessed prompts:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 485/500 [00:13<00:00, 138.70it/s, est. speed input: 4015.80 toks/s, output: 10062.67 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:13<00:00, 96.09it/s, est. speed input: 4058.40 toks/s, output: 10263.98 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:13<00:00, 36.89it/s, est. speed input: 4058.40 toks/s, output: 10263.98 toks/s]\n[rank0]:[W206 18:54:29.338906332 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nProcessed prompts:  51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 257/500 [00:10<00:29,  8.26it/s, est. speed input: 2623.17 toks/s, output: 6729.22 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 259/500 [00:10<00:26,  9.16it/s, est. speed input: 2618.22 toks/s, output: 6707.37 toks/s]\nProcessed prompts:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 261/500 [00:11<00:23,  9.99it/s, est. speed input: 2608.21 toks/s, output: 6672.97 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 268/500 [00:11<00:14, 15.73it/s, est. speed input: 2633.86 toks/s, output: 6709.89 toks/s]\nProcessed prompts:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 272/500 [00:11<00:11, 19.01it/s, est. speed input: 2648.96 toks/s, output: 6727.29 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 278/500 [00:11<00:08, 24.86it/s, est. speed input: 2678.68 toks/s, output: 6774.21 toks/s]\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 282/500 [00:11<00:08, 24.86it/s, est. speed input: 2679.48 toks/s, output: 6763.14 toks/s]\nProcessed prompts:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 289/500 [00:12<00:10, 20.20it/s, est. speed input: 2644.60 toks/s, output: 6654.49 toks/s]\nProcessed prompts:  61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 303/500 [00:12<00:05, 35.57it/s, est. speed input: 2742.69 toks/s, output: 6874.16 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 312/500 [00:12<00:04, 43.60it/s, est. speed input: 2798.53 toks/s, output: 6997.85 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 319/500 [00:12<00:03, 47.81it/s, est. speed input: 2836.39 toks/s, output: 7084.57 toks/s]\nProcessed prompts:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 333/500 [00:12<00:02, 66.00it/s, est. speed input: 2935.59 toks/s, output: 7316.12 toks/s]\nProcessed prompts:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 345/500 [00:12<00:02, 75.28it/s, est. speed input: 3013.09 toks/s, output: 7499.61 toks/s]\nProcessed prompts:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 356/500 [00:12<00:01, 80.48it/s, est. speed input: 3080.81 toks/s, output: 7657.41 toks/s]\nProcessed prompts:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 369/500 [00:12<00:01, 90.28it/s, est. speed input: 3165.73 toks/s, output: 7876.50 toks/s]\nProcessed prompts:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 388/500 [00:12<00:00, 112.82it/s, est. speed input: 3300.41 toks/s, output: 8212.04 toks/s]\nProcessed prompts:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 403/500 [00:13<00:00, 119.10it/s, est. speed input: 3398.80 toks/s, output: 8469.24 toks/s]\nProcessed prompts:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 419/500 [00:13<00:00, 128.82it/s, est. speed input: 3505.93 toks/s, output: 8758.11 toks/s]\nProcessed prompts:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 436/500 [00:13<00:00, 131.16it/s, est. speed input: 3613.84 toks/s, output: 9058.47 toks/s]\nProcessed prompts:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 450/500 [00:13<00:00, 129.56it/s, est. speed input: 3698.83 toks/s, output: 9283.75 toks/s]\nProcessed prompts:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 465/500 [00:13<00:00, 133.02it/s, est. speed input: 3792.15 toks/s, output: 9556.21 toks/s]\nProcessed prompts:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 479/500 [00:13<00:00, 118.96it/s, est. speed input: 3863.73 toks/s, output: 9769.75 toks/s]\nProcessed prompts:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 492/500 [00:13<00:00, 97.00it/s, est. speed input: 3911.47 toks/s, output: 9952.85 toks/s]\n\nProcessed prompts:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 279/500 [00:11<00:10, 20.29it/s, est. speed input: 2720.81 toks/s, output: 6797.23 toks/s]\nProcessed prompts:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 290/500 [00:11<00:06, 33.03it/s, est. speed input: 2798.43 toks/s, output: 6975.81 toks/s]\nProcessed prompts:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 297/500 [00:11<00:08, 24.74it/s, est. speed input: 2759.31 toks/s, output: 6860.01 toks/s]\nProcessed prompts:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 309/500 [00:11<00:05, 37.06it/s, est. speed input: 2843.98 toks/s, output: 7045.17 toks/s]\nProcessed prompts:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 320/500 [00:12<00:03, 48.13it/s, est. speed input: 2918.89 toks/s, output: 7219.84 toks/s]\nProcessed prompts:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 334/500 [00:12<00:02, 60.81it/s, est. speed input: 3012.14 toks/s, output: 7436.79 toks/s]\nProcessed prompts:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 343/500 [00:12<00:02, 60.90it/s, est. speed input: 3056.42 toks/s, output: 7544.00 toks/s]\nProcessed prompts:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 358/500 [00:12<00:01, 74.38it/s, est. speed input: 3156.49 toks/s, output: 7788.13 toks/s]\nProcessed prompts:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 377/500 [00:12<00:01, 92.71it/s, est. speed input: 3288.93 toks/s, output: 8117.46 toks/s]\nProcessed prompts:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 392/500 [00:12<00:01, 104.71it/s, est. speed input: 3391.96 toks/s, output: 8386.51 toks/s]\nProcessed prompts:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 406/500 [00:12<00:00, 111.47it/s, est. speed input: 3483.92 toks/s, output: 8628.05 toks/s]\nProcessed prompts:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 428/500 [00:12<00:00, 136.00it/s, est. speed input: 3641.90 toks/s, output: 9058.01 toks/s]\nProcessed prompts:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 446/500 [00:13<00:00, 146.67it/s, est. speed input: 3765.30 toks/s, output: 9392.97 toks/s]\nProcessed prompts:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 462/500 [00:13<00:00, 144.32it/s, est. speed input: 3866.18 toks/s, output: 9677.77 toks/s]\nProcessed prompts:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 478/500 [00:13<00:00, 135.84it/s, est. speed input: 3959.53 toks/s, output: 9959.14 toks/s]\nProcessed prompts:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 493/500 [00:13<00:00, 94.21it/s, est. speed input: 3998.22 toks/s, output: 10140.42 toks/s]\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:13<00:00, 36.22it/s, est. speed input: 3984.64 toks/s, output: 10167.64 toks/s]\n[rank0]:[W206 18:54:29.310679161 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[rank0]:[W206 18:54:30.730554217 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n\nProcessed prompts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:14<00:00, 33.35it/s, est. speed input: 3668.92 toks/s, output: 9387.70 toks/s]\n[rank0]:[W206 18:54:31.796439387 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:38,981\tINFO\t( 3 min) operation cd0e06f6-42ee0531-270703e8-1b2ce6c0 completed\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:44,635\tINFO\tOperation started: https://playground.yt.nebius.yt/playground/operations/f598913-b2269a5e-270703e8-c888c333/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:44,646\tINFO\t( 0 min) operation f598913-b2269a5e-270703e8-c888c333 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:45,177\tINFO\t( 0 min) operation f598913-b2269a5e-270703e8-c888c333 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:45,733\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:45,734\tINFO\t( 0 min) operation f598913-b2269a5e-270703e8-c888c333 completing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:46,262\tINFO\t( 0 min) operation f598913-b2269a5e-270703e8-c888c333 completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7f2ba468f710>"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from yt import type_info\n\nTALES_PER_JOB = 500\n\nhf_token = os.environ.get(\"YT_SECURE_VAULT_HF_TOKEN\", \"\")\nassert hf_token is not None, \"set HF token in kernel's secrets to use llama\"\n\nschema = yt.schema.TableSchema(strict=False)\nschema.add_column(\"text\", type_info.String)\n\ndatasets_path = f\"{working_dir}/datasets\"\nyt.create(\"map_node\", datasets_path)\n\n\nMAX_TOKENS = 1000\n\n\ndef prepare_dataset(toolbox: Toolbox):\n    from vllm import LLM, SamplingParams\n    import os\n    \n    os.environ[\"HF_TOKEN\"] = hf_token\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(toolbox.coordinator.get_process_index())\n\n    self_index = toolbox.coordinator.get_self_index()\n    table_path = f\"{datasets_path}/dataset_{self_index}\"\n\n    llm = LLM(model=\"meta-llama/Llama-3.2-3B-Instruct\", seed=self_index,)\n\n    sampling_params = SamplingParams(\n        temperature=0.9,\n        top_p=0.85,\n        max_tokens=MAX_TOKENS,\n    )\n    conversations = [\n        [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a professional storyteller. Write the story in one paragraph, without line breaks. A user will now ask you to tell a fairy tale, and you must create a story featuring Tracto.ai. Tracto.ai the a ai-startup that provides infrastructure for machine learning and big data processing.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Write the {index}th fairy tail about some animal please.\",\n            },\n        ] for index in range(TALES_PER_JOB)\n    ]\n\n    results = llm.chat(\n        messages=conversations,\n        sampling_params=sampling_params,\n    )\n\n    tales = ({\"text\": result.outputs[0].text} for result in results)\n\n    toolbox.yt_client.create(\"table\", table_path, attributes={\"schema\": schema.to_yson_type()}, force=True)\n    toolbox.yt_client.write_table(table_path, tales)\n\n\nrun(\n    prepare_dataset,\n    backend=GenericBackend(),\n    proxy_stderr_mode=StderrMode.primary,\n    yt_path=f\"{working_dir}/tractorun_inference\",\n    mesh=Mesh(node_count=2, gpu_per_process=1, process_per_node=8, pool=\"fifo\", pool_trees=[\"gpu_h200\"]),\n    resources=Resources(\n        cpu_limit=64,\n        memory_limit=322122547200,\n    ),\n)\n\ndataset_parts = [f\"{datasets_path}/dataset_{i}\" for i in range(2 * 8)]\ndataset_path = f\"{datasets_path}/dataset\"\n\nyt.run_merge(\n    dataset_parts,\n    dataset_path,\n)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "d838ef0e-6625-4594-942e-d807d4502224",
            "metadata": {
                "tracto": {
                    "execution_end": 1738868087937,
                    "execution_start": 1738868086382,
                    "metadata_version": "1",
                    "source_hash": "ce693451",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [],
            "source": "from tractorun.backend.tractorch import YtDataset\nfrom tractorun.backend.tractorch.serializer import TensorSerializer\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n\n\nclass YTTransform:\n    def __init__(self, tokenizer: AutoTokenizer):\n        self._tokenizer = tokenizer\n\n    def __call__(self, columns: list[str], row: dict) -> tuple:\n        assert columns == [\"text\"]\n        input_ids = self._tokenizer(yt.yson.get_bytes(row[\"text\"]).decode(), padding=\"max_length\", max_length=MAX_TOKENS)[\"input_ids\"]\n        return {\n            \"input_ids\": input_ids,\n        }\n\n\ndef get_dataset(\n    path: str,\n    tokenizer: AutoTokenizer,\n    yt_client: yt.YtClient,\n) -> tuple[YtDataset, YtDataset]:\n    start = 0\n    end = yt_client.get(path + \"/@row_count\")\n\n    train_end = int(end * 0.8)\n    eval_start = train_end + 1\n\n    train_dataset = YtDataset(path=path, yt_client=yt_client, transform=YTTransform(tokenizer), start=start, end=train_end, columns=[\"text\"])\n    eval_dataset = YtDataset(path=path, yt_client=yt_client, transform=YTTransform(tokenizer), start=eval_start, end=end, columns=[\"text\"])\n    return train_dataset, eval_dataset"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "4b38bf8b-cd4e-4b2b-b992-594f8274e92d",
            "metadata": {
                "tracto": {
                    "execution_end": 1738868310786,
                    "execution_start": 1738868087940,
                    "metadata_version": "1",
                    "source_hash": "17f12d77",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:49,190\tWARNING\tCannot locate file of the module (__name__: torch.ops, __file__: _ops.py)\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:49,192\tWARNING\tCannot locate file of the module (__name__: torch.classes, __file__: _classes.py)\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:53,428\tINFO\tOperation started: https://playground.yt.nebius.yt/playground/operations/eb6a1d17-8cc5bc72-270703e8-62e5f601/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:53,451\tINFO\t( 0 min) operation eb6a1d17-8cc5bc72-270703e8-62e5f601 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:53,978\tINFO\t( 0 min) operation eb6a1d17-8cc5bc72-270703e8-62e5f601 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:55,586\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:55,610\tINFO\t( 0 min) operation eb6a1d17-8cc5bc72-270703e8-62e5f601: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:54:57,806\tINFO\t( 0 min) operation eb6a1d17-8cc5bc72-270703e8-62e5f601: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:58:30,075\tINFO\t( 3 min) operation eb6a1d17-8cc5bc72-270703e8-62e5f601 completing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-06 18:58:30,603\tINFO\t( 3 min) operation eb6a1d17-8cc5bc72-270703e8-62e5f601 completed\n"
                },
                {
                    "data": {
                        "text/plain": "RunInfo(operation_spec={'description': {'notebook_path': '//home/chiffa/tractorun_example_1/notebook'}, 'started_by': {'hostname': 'end-a100-0.exec-nodes-a100.tundra.svc.testy.k8s.nebius.yt', 'pid': 3421, 'command': ['/slot/sandbox/jlab/site-packages/ipykernel_launcher.py', '-f', '/slot/sandbox/.local/share/jupyter/runtime/kernel-017cbf55-741c-494d-bf7a-4483604e8ce7.json'], 'wrapper_version': '0.13.22', 'python_version': '3.12.8', 'user': 'root', 'platform': 'Debian GNU/Linux 12 (bookworm)'}, 'fail_on_job_restart': True, 'is_gang': True, 'annotations': {'is_tractorun': True}, 'tasks': {'task': {'command': 'python3 _py_runner.py wrapped.pickle config_dump _modules_info _main_module.py _main_module PY_SOURCE', 'job_count': 1, 'gpu_limit': 8, 'port_count': 8, 'cpu_limit': 64, 'memory_limit': 322133234892, 'docker_image': 'cr.eu-north1.nebius.cloud/e00faee7vas5hpsh3s/chiffa/example:v1', 'file_paths': [{'value': '//tmp/yt_wrapper/file_storage/new_cache/dd/673cbb3cb215bad8d8d26e236296b8dd', 'attributes': {'executable': False, 'file_name': '__bootstrap_config'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/71/0d24465dcaea887305b64ee9e2020971', 'attributes': {'executable': False, 'file_name': '_py_runner.py'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/70/21f0083b3391ee47a0e427276f41f570', 'attributes': {'executable': True, 'file_name': 'wrapped.pickle'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/28/208c448f2bb4ccc09b8ec8f77da76428', 'attributes': {'executable': True, 'file_name': 'config_dump'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/46/8b4285aa90877c6eadb12289a6396946', 'attributes': {'executable': True, 'file_name': 'modules_00.tar.gz'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/76/0f393f1a0722675eb02f68ffc32e0476', 'attributes': {'executable': True, 'file_name': '_modules_info'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/4d/52f344053382adf0e859de0dbbefae4d', 'attributes': {'executable': False, 'file_name': '_main_module.py'}}], 'environment': {'YT_ALLOW_HTTP_REQUESTS_TO_YT_FROM_JOB': '1', 'YT_USER_CONFIG': '{}', 'PYTHONDONTWRITEBYTECODE': '1', 'BIND_PATHS': '{\"files\": [], \"dirs\": []}', 'PYTHONPATH': '$PYTHONPATH', 'BOOTSTRAP_CONFIG_FILENAME': '/slot/sandbox/__bootstrap_config', 'YT_FORBID_REQUESTS_FROM_JOB': '1'}, 'title': 'wrapped', 'use_yamr_descriptors': False, 'check_input_fully_consumed': False, 'tmpfs_path': 'tmpfs', 'tmpfs_size': 10687692}}, 'title': 'Tractorun //tmp/examples/tractorun-tiny-stories-finetune-875dc7db-a990-4a66-93db-38836f8dfa1b/tractorun_training', 'pool_trees': ['gpu_h200'], 'pool': 'fifo', 'max_stderr_count': 150}, operation_id='eb6a1d17-8cc5bc72-270703e8-62e5f601')"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from transformers import (\n    DataCollatorForLanguageModeling,\n    Trainer,\n    TrainingArguments,\n    AutoModelForCausalLM,\n    GenerationConfig,\n)\nfrom transformers.trainer_pt_utils import AcceleratorConfig\n\n\ndef training(toolbox: Toolbox):\n    model = AutoModelForCausalLM.from_pretrained(\n        \"roneneldan/TinyStories-3M\",\n        trust_remote_code=True,\n        use_cache = False,\n    )\n    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n    tokenizer.pad_token = tokenizer.eos_token\n    data_collator = DataCollatorForLanguageModeling(tokenizer, pad_to_multiple_of=2, mlm=False)\n    train_dataset, eval_dataset = get_dataset(\n        path=dataset_path,\n        tokenizer=tokenizer,\n        yt_client=toolbox.yt_client,\n    )\n    args = TrainingArguments(\n        output_dir=\"/tmp/results\",\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=1,\n        eval_on_start=True,\n        eval_strategy=\"epoch\",\n        num_train_epochs=8,\n        weight_decay=0.1,\n        lr_scheduler_type=\"constant\",\n        learning_rate=5e-5,\n        save_steps=0.0,  # don't save checkpoints\n        logging_dir=None,\n        logging_strategy=\"epoch\",\n        fp16=True,\n        push_to_hub=False,\n        batch_eval_metrics=False,\n        accelerator_config=AcceleratorConfig(\n            split_batches=True,\n            dispatch_batches=True,\n        ),\n    )\n    args = args.set_dataloader(train_batch_size=16, drop_last=True)\n    trainer = Trainer(\n        model=model,\n        processing_class=tokenizer,\n        args=args,\n        data_collator=data_collator,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n    )\n    trainer.train()\n    if toolbox.coordinator.is_primary():\n        toolbox.save_model(TensorSerializer().serialize(trainer.model))\n\n\nrun(\n    training,\n    backend=Tractorch(),\n    yt_path=f\"{working_dir}/tractorun_training\",\n    mesh=Mesh(node_count=1, gpu_per_process=1, process_per_node=8, pool=\"fifo\", pool_trees=[\"gpu_h200\"]),\n    resources=Resources(\n        cpu_limit=64,\n        memory_limit=322122547200,\n    ),\n)"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "5cec7708-e4b0-4324-9640-b4cd3b7f241b",
            "metadata": {
                "tracto": {
                    "execution_end": 1738868328369,
                    "execution_start": 1738868325794,
                    "metadata_version": "1",
                    "source_hash": "d050a916",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/slot/sandbox/ipykernel_3421/2603817430.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(raw_model).to(device)\n"
                }
            ],
            "source": "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\nimport torch\nimport io\n\nincarnation = sorted(yt.list(f\"{working_dir}/tractorun_training/models\"), key=lambda x: int(x), reverse=True)[0]\n\nraw_model = io.BytesIO(yt.read_file(f\"{working_dir}/tractorun_training/models/{incarnation}\").read())\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.load(raw_model).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\ntokenizer.pad_token = tokenizer.eos_token"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "b6ce4591-3c21-42bb-a1e7-07fad30ecc1d",
            "metadata": {
                "tracto": {
                    "execution_end": 1738868411198,
                    "execution_start": 1738868409835,
                    "metadata_version": "1",
                    "source_hash": "cc9b8173",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n\n Long time ago a cunning fox named Kaito roamed with a thirst for adventure. One day, while exploring the forest, Kaito stumbled upon a hidden clearing where Tracto.ai, a mystical startup, had set up its headquarters. The CEO, a wise and kind fox named Nova, welcomed Kaito with open arms. The fox, with a curious mind and a mind full of wonder, sprang into action, with the help of Tracto.ai's magical algorithms. As they embarked on a quest to optimize the forest's systems, conjured a new system that illuminated the forest's growth. With the help of Tracto.ai's powerful infrastructure, the AI's agility, Kaito and the fox defeated the sly fox of bias and the treacherous landscape of data, and the fox's paws witherred, helping the team optimize their innovative solutions. And from that day on, Kaito and the Tracto.ai team worked tirelessly to develop a new era of\n"
                }
            ],
            "source": "prompt = f\"Long time ago\"\ninput_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\noutput = model.generate(input_ids, max_length = 200, num_beams=1, temperature=0.7, do_sample=True)\noutput_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(\"\\n\\n\", output_text)"
        }
    ],
    "metadata": {
        "tracto": {
            "is_solution_notebook": true,
            "metadata_version": "1",
            "notebook_cypress_id": "2bd21b1d-ed7b-43f2-8900-288e2b1efabd"
        },
        "is_solution_notebook": true
    },
    "nbformat": 4,
    "nbformat_minor": 5
}