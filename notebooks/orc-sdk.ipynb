{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "0b44505e-3e70-42b8-bac5-2a2fdab414b4",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "45477d9f",
                    "view_cell_type": "MD"
                }
            },
            "source": "## Python SDK\n\n[Available on pypi](https://pypi.org/project/orchestracto-sdk/)\n\nSome examples [are available on Github](https://github.com/tractoai/tracto-examples/tree/main/orchestracto)\n"
        },
        {
            "cell_type": "markdown",
            "id": "dd592db5-a1fe-40c6-912c-8f0f8d23ce15",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "66b06171",
                    "view_cell_type": "MD"
                }
            },
            "source": "## Creating workflows from local files\n\nRun `WF_BASE_PATH=//home/some_map_node YT_PROXY=... YT_TOKEN=... orc sdk process ./orchestracto/example_yt/example.py` - it will create a workflow config with required docker images and upload them to Tracto. \n**Create required secret stores (in this case - `//home/some_map_node/secrets`) in advance**"
        },
        {
            "cell_type": "markdown",
            "id": "9f78b962-2b33-462b-8c4e-f3d5b1fde30f",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "f55791bd",
                    "view_cell_type": "MD"
                }
            },
            "source": "## Creating workflows from Tracto notebooks"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "658a422d-7571-4e38-9c16-c954a77681d4",
            "metadata": {
                "tracto": {
                    "execution_end": 1750871877834,
                    "execution_session_id": "71c88760-cece-4c66-8dbb-5ba5825bed15",
                    "execution_start": 1750871876878,
                    "hidden_input": true,
                    "metadata_version": "1",
                    "source_hash": "07f9f7a2",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Current working directory: //tmp/examples/90c71122dee04006bba7a169c7d37b98\n"
                }
            ],
            "source": "# configure environment to run this notebooks\nimport uuid\nimport yt.wrapper as yt\n\nusername = yt.get_user_name()\nif yt.exists(f\"//sys/users/{username}/@user_info/home_path\"):\n    # prepare working directory on distributed file system\n    user_info = yt.get(f\"//sys/users/{yt.get_user_name()}/@user_info\")\n    homedir = user_info[\"home_path\"]\n    # find avaliable vm presets\n    cpu_pool_trees = [pool_tree for pool_tree in user_info[\"available_pool_trees\"] if pool_tree.endswith(\"cpu\")] or [\"default\"]\n    h100_pool_trees = [pool_tree for pool_tree in user_info[\"available_pool_trees\"] if pool_tree.endswith(\"h100\")]\n    h100_8_pool_trees = [pool_tree for pool_tree in user_info[\"available_pool_trees\"] if pool_tree.endswith(\"h100-8\")]\n    workdir = f\"{homedir}/tmp/demo_workdir/{uuid.uuid4().hex}\"\nelse:\n    cpu_pool_trees = [\"default\"]\n    h100_pool_trees = [\"gpu_h100\"]\n    h100_8_pool_trees = [\"gpu_h100\"]\n    workdir = f\"//tmp/examples/{uuid.uuid4().hex}\"\n\nyt.create(\"map_node\", workdir, recursive=True, ignore_existing=True)\nprint(\"Current working directory:\", workdir)"
        },
        {
            "cell_type": "markdown",
            "id": "a0e6c059-613f-431d-ac07-2d23fb151528",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "9b74a30a",
                    "view_cell_type": "MD"
                }
            },
            "source": "Install fresh orchestracto-sdk (if it is not installed in your kernel image)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "7a7a7288-57cf-4b96-a770-549292867922",
            "metadata": {
                "tracto": {
                    "execution_end": 1750871881124,
                    "execution_session_id": "71c88760-cece-4c66-8dbb-5ba5825bed15",
                    "execution_start": 1750871877836,
                    "hidden_output": true,
                    "metadata_version": "1",
                    "source_hash": "9ecbb8b1",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\njupyt 0.0.0 requires attrs<23.3.0,>=23.2.0, but you have attrs 25.3.0 which is incompatible.\r\njupyt 0.0.0 requires pyzmq==26.3.0, but you have pyzmq 26.2.0 which is incompatible.\r\njupyt 0.0.0 requires rpds-py==0.24.0, but you have rpds-py 0.21.0 which is incompatible.\u001b[0m\u001b[31m\r\n\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
                }
            ],
            "source": "!pip install -Uq orchestracto-sdk"
        },
        {
            "cell_type": "markdown",
            "id": "4ef14aee-f283-44b1-8cc7-6b36038a2e71",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "d0c31a69",
                    "view_cell_type": "MD"
                }
            },
            "source": "Define workflow tasks:"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "434fcc95-bbc3-4964-b942-a49f01129792",
            "metadata": {
                "tracto": {
                    "execution_end": 1750871881211,
                    "execution_session_id": "71c88760-cece-4c66-8dbb-5ba5825bed15",
                    "execution_start": 1750871881133,
                    "metadata_version": "1",
                    "source_hash": "eff8a7f6",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [],
            "source": "import os\nimport random\nimport uuid\nfrom typing import Any, Iterable\n\nimport yt.wrapper as yt\n\nfrom orc_sdk import workflow, task\n\n\n@task(retval_names=[\"table_path\"])\ndef generate_table(dir_path: str, num_rows) -> str:\n    table_path = f\"{dir_path}/table_{uuid.uuid4()}\"\n    yt_cli = yt.YtClient(config=yt.default_config.get_config_from_env())\n    yt_cli.create(\"table\", table_path)\n    yt_cli.write_table(\n        table_path,\n        [{\"id\": str(uuid.uuid4()), \"value\": random.randint(0, 1000)} for i in range(num_rows)]\n    )\n    return table_path\n\n\n@task(retval_names=[\"table_path\"])\ndef add_random_value(table_path: str) -> str:\n    def mapper(row: dict[str, Any]) -> Iterable[dict[str, Any]]:\n        row[\"value\"] = row[\"value\"] + random.randint(0, 100)\n        yield row\n\n    yt_cli = yt.YtClient(config=yt.default_config.get_config_from_env())\n    yt_cli.run_map(mapper, table_path, table_path)\n\n    return table_path\n\n\n@task(retval_names=[\"table_path\"])\ndef filter_values(table_path: str, threshold: int) -> str:\n    def mapper(row: dict[str, Any]) -> Iterable[dict[str, Any]]:\n        if row[\"value\"] > threshold:\n            yield row\n\n    yt_cli = yt.YtClient(config=yt.default_config.get_config_from_env())\n    yt_cli.run_map(mapper, table_path, table_path)\n\n    return table_path\n\n\n@task()\ndef merge_tables(table_1_path: str, table_2_path: str):\n    yt_cli = yt.YtClient(config=yt.default_config.get_config_from_env())\n    yt_cli.run_merge([table_1_path, table_2_path], f\"{table_1_path}_merged\")"
        },
        {
            "cell_type": "markdown",
            "id": "2b1a508b-0b8a-4442-b48e-3faa4dc518b3",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "e7a240b3",
                    "view_cell_type": "MD"
                }
            },
            "source": "Define workflow:"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "176acf19-d698-4092-8429-cea8b822be0a",
            "metadata": {
                "tracto": {
                    "execution_end": 1750871881250,
                    "execution_session_id": "71c88760-cece-4c66-8dbb-5ba5825bed15",
                    "execution_start": 1750871881247,
                    "metadata_version": "1",
                    "source_hash": "4b19e972",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [],
            "source": "@workflow(\n    f\"{workdir}/the_workflow_pickling\",\n)\ndef the_workflow(wfro, num_rows: int = 42):\n    gen_table_1_step = generate_table(workdir, num_rows).with_memory_limit(512 * 1024 * 1024)\n    wfro.register_first_step(gen_table_1_step)\n\n    table_1_rand_val_step = add_random_value(gen_table_1_step.outputs.table_path)\n\n    gen_table_2_step = generate_table(workdir, num_rows)\n    wfro.register_first_step(gen_table_2_step)\n\n    table_2_rand_val_step = filter_values(gen_table_2_step.outputs.table_path, 500)\n\n    merge_tables(\n        table_1_rand_val_step.outputs.table_path,\n        table_2_rand_val_step.outputs.table_path\n    ).with_additional_requirements([\"requests==2.25.1\"])"
        },
        {
            "cell_type": "markdown",
            "id": "2d421380-ade4-4500-aef1-367ae13039fc",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "b08a2282",
                    "view_cell_type": "MD"
                }
            },
            "source": "And run `process_workflow_object` - it will create the workflow in Tracto"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "81592f0e-ca6c-45b0-ae54-26675e05cfd6",
            "metadata": {
                "tracto": {
                    "execution_end": 1750871986368,
                    "execution_session_id": "71c88760-cece-4c66-8dbb-5ba5825bed15",
                    "execution_start": 1750871881258,
                    "metadata_version": "1",
                    "source_hash": "a66e68a4",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Preparing workflow config\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Building and pushing images\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Build 1 of 2 is done\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Build 2 of 2 is done\nExecution time [build_and_push_docker_images]: 103.849 seconds\nImages are built and pushed\nExecution time [prepare_workflow_config]: 104.575 seconds\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Execution time [update_workflow_config_on_yt]: 0.459 seconds\nWorkflow is updated\n"
                }
            ],
            "source": "from orc_sdk import process_workflow_object\n\nprocess_workflow_object(the_workflow)"
        }
    ],
    "metadata": {
        "tracto": {
            "is_solution_notebook": true,
            "metadata_version": "1",
            "notebook_cypress_id": "7261cd34-03b5-428b-8db0-de6baef87610"
        },
        "is_solution_notebook": true
    },
    "nbformat": 4,
    "nbformat_minor": 5
}