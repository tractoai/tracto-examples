{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "9b35c90f-e91f-42c5-99ef-adac98e9a103",
            "metadata": {
                "tracto": {
                    "metadata_version": "1",
                    "source_hash": "8a0a37ab",
                    "view_cell_type": "MD"
                }
            },
            "source": "# Run verl by tractorun\n\nIn this notebook we run [Verl](https://github.com/volcengine/verl/) on the [Tracto.ai](https://tracto.ai) platform. As an example, we will use [this notebook](https://github.com/volcengine/verl/blob/main/examples/ppo_trainer/verl_getting_started.ipynb), but instead of using 1 GPU, we will utilize all 8.\n\nTo run this notebook, use the following Docker image.\n\n```docker\nROM ubuntu:22.04\n\nUSER root\n\nRUN apt-get update && apt-get install -y \\\n    software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa \\\n    && apt-get update && apt-get install -y \\\n    python3.10 \\\n    python3.10-venv \\\n    python3.10-dev\n\nRUN apt-get install wget --yes\nRUN wget https://bootstrap.pypa.io/get-pip.py && python3.10 get-pip.py\n\nRUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n\nRUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb\nRUN dpkg -i cuda-keyring_1.1-1_all.deb\nRUN apt-get update\nRUN apt-get -y install cuda-toolkit-12-4\n\nENV PATH /usr/local/cuda-12.4/bin:$PATH\nENV CUDA_HOME /usr/local/cuda-12.4\n\nRUN pip3 install --upgrade pip setuptools wheel\nRUN pip3 install torchvision==0.19.0\nRUN pip install --pre torch==2.4.0 --index-url https://download.pytorch.org/whl/nightly/cu121\nRUN pip install vllm==0.6.3\n\nRUN pip install -U \"huggingface_hub[cli]\"\n\nRUN pip install tractorun\n\nRUN apt-get install git --yes\nRUN mkdir /verl_repo && git clone https://github.com/volcengine/verl /verl_repo && cd /verl_repo && pip3 install -e . -U\n\nRUN pip3 install flash-attn --no-build-isolation\n\n\nRUN mkdir /models && huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /models/Qwen2.5-0.5B-Instruct\nRUN mkdir /data && mkdir /gsm8k && python3 /verl_repo/examples/data_preprocess/gsm8k.py --local_dir /data/gsm8k\n```"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c9a5505d-f80b-420e-952c-8563d5dfdc4e",
            "metadata": {
                "tracto": {
                    "execution_end": 1739569822791,
                    "execution_start": 1739568819355,
                    "metadata_version": "1",
                    "source_hash": "1450c5b3",
                    "view_cell_type": "CODE"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:33:42,346\tINFO\tOperation started: https://playground.yt.nebius.yt/playground/operations/520620f6-3ce90f29-270703e8-f36e1657/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:33:42,380\tINFO\t( 0 min) operation 520620f6-3ce90f29-270703e8-f36e1657 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:33:42,932\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:33:44,616\tINFO\t( 0 min) operation 520620f6-3ce90f29-270703e8-f36e1657: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:33:47,709\tINFO\t( 0 min) operation 520620f6-3ce90f29-270703e8-f36e1657: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:50:22,575\tINFO\t(16 min) operation 520620f6-3ce90f29-270703e8-f36e1657 completed\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-02-14 21:50:22,604\tINFO\t(16 min) Alerts: {'low_cpu_usage': {'code': 1, 'message': \"Average CPU usage of some of your job types is significantly lower than requested 'cpu_limit'. Consider decreasing cpu_limit in spec of your operation\", 'attributes': {'pid': 1, 'tid': 4583944030924008135, 'thread': 'Controller:13', 'fid': 18446123350071491836, 'host': 'man0-0460.hw.nebius.yt', 'datetime': '2025-02-14T21:50:20.670172Z', 'trace_id': 'ad092a59-a0dcb7aa-4a232913-32edd2b8', 'span_id': 5365977716875535721}, 'inner_errors': [{'code': 1, 'message': 'Jobs of task \"task\" use 6.80% of requested cpu limit', 'attributes': {'pid': 1, 'tid': 4583944030924008135, 'thread': 'Controller:13', 'fid': 18446123350071491836, 'host': 'man0-0460.hw.nebius.yt', 'datetime': '2025-02-14T21:50:20.670153Z', 'trace_id': 'ad092a59-a0dcb7aa-4a232913-32edd2b8', 'span_id': 5365977716875535721, 'cpu_time': 8102394, 'cpu_limit': 120.0, 'exec_time': 992364}}]}}\n"
                },
                {
                    "data": {
                        "text/plain": "RunInfo(operation_spec={'description': {'notebook_path': '//home/chiffa/verl/notebook_multiple_gpu.ipynb'}, 'started_by': {'hostname': 'end-h100-1.exec-nodes-h100.tundra.svc.testy.k8s.nebius.yt', 'pid': 249, 'wrapper_version': '0.13.23', 'python_version': '3.10.12', 'binary_name': 'ipykernel_launcher.py', 'command': ['/slot/sandbox/jlab/site-packages/ipykernel_launcher.py', '-f', '/slot/sandbox/.local/share/jupyter/runtime/kernel-8ed19f55-5722-4b41-95d6-f516c69e13c6.json'], 'user': 'root', 'platform': 'Ubuntu 22.04 (jammy)'}, 'fail_on_job_restart': True, 'is_gang': True, 'annotations': {'is_tractorun': True}, 'tasks': {'task': {'command': 'python3 _py_runner.py wrapped.pickle config_dump _modules_info modules/_main_module.py _main_module PY_SOURCE', 'job_count': 1, 'gpu_limit': 8, 'port_count': 1, 'cpu_limit': 120, 'memory_limit': 644253684654, 'docker_image': 'cr.eu-north1.nebius.cloud/e00faee7vas5hpsh3s/chiffa/verl:v6', 'file_paths': [{'value': '//tmp/yt_wrapper/file_storage/new_cache/71/b303204be3f04a4339b8663e9a5bdf71', 'attributes': {'executable': False, 'file_name': '__bootstrap_config'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/67/80157d229db480c648bd68b804d6ed67', 'attributes': {'executable': False, 'file_name': '_py_runner.py'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/01/48dacbf1419c38cd38dc0823675bdf01', 'attributes': {'executable': True, 'file_name': 'wrapped.pickle'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/77/948c88991370c2bd91a152f6cbe36c77', 'attributes': {'executable': True, 'file_name': 'config_dump'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/34/9ba4276c0e5bac05b2355303b566ea34', 'attributes': {'executable': True, 'file_name': 'modules_00.tar.gz'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/97/416a7fbba94ac9fccc909731d4034797', 'attributes': {'executable': True, 'file_name': '_modules_info'}}, {'value': '//tmp/yt_wrapper/file_storage/new_cache/4d/52f344053382adf0e859de0dbbefae4d', 'attributes': {'executable': False, 'file_name': 'modules/_main_module.py'}}], 'environment': {'YT_ALLOW_HTTP_REQUESTS_TO_YT_FROM_JOB': '1', 'YT_USER_CONFIG': '{}', 'PYTHONDONTWRITEBYTECODE': '1', 'BIND_PATHS': '{\"files\": [], \"dirs\": []}', 'PYTHONPATH': '$PYTHONPATH', 'BOOTSTRAP_CONFIG_FILENAME': '/slot/sandbox/__bootstrap_config', 'YT_FORBID_REQUESTS_FROM_JOB': '1'}, 'title': 'wrapped', 'use_yamr_descriptors': False, 'check_input_fully_consumed': False, 'tmpfs_path': 'tmpfs', 'tmpfs_size': 8590254}}, 'title': 'Tractorun //tmp/verl', 'pool_trees': ['gpu_h200'], 'max_stderr_count': 150}, operation_id='520620f6-3ce90f29-270703e8-f36e1657')"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from tractorun.run import prepare_and_get_toolbox\nfrom tractorun.backend.generic import GenericBackend\nfrom tractorun.run import run\nfrom tractorun.resources import Resources\nfrom tractorun.mesh import Mesh\nfrom tractorun.stderr_reader import StderrMode\n\nimport subprocess\nimport sys\nimport os\n\ndef controller(toolbox):\n    command = [\n        r\"PYTHONUNBUFFERED=1 python3 -m verl.trainer.main_ppo data.train_files=/data/gsm8k/train.parquet \"\n        r\"data.val_files=/data/gsm8k/test.parquet data.train_batch_size=128 data.val_batch_size=656 \"\n        r\"data.max_prompt_length=512 data.max_response_length=256 actor_rollout_ref.model.path=/models/Qwen2.5-0.5B-Instruct \"\n        r\"actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.actor.ppo_mini_batch_size=64 \"\n        r\"actor_rollout_ref.actor.ppo_micro_batch_size=8 actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1 \"\n        r\"actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.gpu_memory_utilization=0.4 \"\n        r\"actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 critic.optim.lr=1e-5 \"\n        r\"critic.model.path=/models/Qwen2.5-0.5B-Instruct critic.ppo_micro_batch_size=8 \"\n        r\"algorithm.kl_ctrl.kl_coef=0.001 +trainer.val_before_train=False trainer.default_hdfs_dir=null \"\n        r\"trainer.n_gpus_per_node=8 trainer.nnodes=1 trainer.save_freq=10 trainer.test_freq=10 \"\n        r\"trainer.total_epochs=1 trainer.logger=[console]\"\n    ]\n\n    os.environ[\"VLLM_ATTENTION_BACKEND\"] = \"XFORMERS\"\n    process = subprocess.run(command, shell=True, stdout=sys.stdout, stderr=sys.stderr, env=os.environ)\n    assert process.returncode == 0\n\nrun(\n    controller,\n    yt_path=\"//tmp/verl\",\n    resources=Resources(\n        memory_limit=644245094400, # 600 GiB\n        cpu_limit=120,\n    ),\n    mesh=Mesh(\n        node_count=1,\n        process_per_node=1,\n        gpu_per_process=8,\n        pool_trees=[\"gpu_h200\"],\n    ),\n    proxy_stderr_mode=StderrMode.primary,\n    backend=GenericBackend(),\n    docker_image=\"cr.eu-north1.nebius.cloud/e00faee7vas5hpsh3s/chiffa/verl:v6\",\n)"
        }
    ],
    "metadata": {
        "tracto": {
            "is_solution_notebook": true,
            "metadata_version": "1",
            "notebook_cypress_id": "89f96d7b-51bb-4f12-a374-a8c42e69d6c1"
        },
        "is_solution_notebook": true
    },
    "nbformat": 4,
    "nbformat_minor": 5
}