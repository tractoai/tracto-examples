{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "c54c9923-2ede-4ccc-853a-0625fa0954c4",
            "metadata": {
                "cell_id": "c54c9923-2ede-4ccc-853a-0625fa0954c4",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "When is it more likely to see a running squirrel in Central Park, New York? Let's find out, along with an example of data preparation on YTsaurus.\n\nThis notebook demonstrates:\n\n* How to use `map`, `reduce`, `sort`, and `mapreduce` operations on schematized and non-schematized tables\n* How to use YTsaurus to transform unstructured data into structured data\n* How to process Date type on YT\n\nAt the end of this example, we will find out when it is more likely to encounter a running squirrel in Central Park, New York."
                }
            },
            "source": "When is it more likely to see a running squirrel in Central Park, New York? Let's find out, along with an example of data preparation on YTsaurus.\n\nThis notebook demonstrates:\n\n* How to use `map`, `reduce`, `sort`, and `mapreduce` operations on schematized and non-schematized tables\n* How to use YTsaurus to transform unstructured data into structured data\n* How to process Date type on YT\n\nAt the end of this example, we will find out when it is more likely to encounter a running squirrel in Central Park, New York."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "5181bc2b-d877-4648-9801-0e19c7ba1362",
            "metadata": {
                "cell_id": "5181bc2b-d877-4648-9801-0e19c7ba1362",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "from yt import wrapper as yt\nfrom yt import type_info\n\nimport uuid\nimport re\nimport datetime\nimport time\n\nfrom typing import Iterable\nfrom collections import defaultdict"
                }
            },
            "outputs": [],
            "source": "from yt import wrapper as yt\nfrom yt import type_info\n\nimport uuid\nimport re\nimport datetime\nimport time\n\nfrom typing import Iterable\nfrom collections import defaultdict"
        },
        {
            "cell_type": "markdown",
            "id": "2db47098-db83-4b89-8bc7-6e6139a1ec41",
            "metadata": {
                "cell_id": "2db47098-db83-4b89-8bc7-6e6139a1ec41",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Create a base directory for examples"
                }
            },
            "source": "## Create a base directory for examples"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "42e9ceac-e055-4408-b005-c2373a197653",
            "metadata": {
                "cell_id": "42e9ceac-e055-4408-b005-c2373a197653",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "working_dir = f\"//tmp/examples/process-squirrels-data_{uuid.uuid4()}\"\nyt.create(\"map_node\", working_dir, recursive=True)\nprint(working_dir)"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "//tmp/examples/process-squirrels-data_32335170-1236-4633-942e-086b0af41222\n"
                }
            ],
            "source": "working_dir = f\"//tmp/examples/process-squirrels-data_{uuid.uuid4()}\"\nyt.create(\"map_node\", working_dir, recursive=True)\nprint(working_dir)"
        },
        {
            "cell_type": "markdown",
            "id": "cd2f273b-97bc-4971-97a3-8c676a3b12b6",
            "metadata": {
                "cell_id": "cd2f273b-97bc-4971-97a3-8c676a3b12b6",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "# Dataset preparation"
                }
            },
            "source": "# Dataset preparation"
        },
        {
            "cell_type": "markdown",
            "id": "bc4ced9a-f9ab-447b-b374-eb2f7c92d83a",
            "metadata": {
                "cell_id": "bc4ced9a-f9ab-447b-b374-eb2f7c92d83a",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Let use `//home/samples/squirrels-hectare-data`. This dataset contains environmental data related to each of the 350 \u201ccountable\u201d hectares of Central Park. Examples include weather, litter, animals sighted, and human density.\n\nThis dataset has several problems:\n1. Date has a non-standard format.\n2. Columns `other_animals_sightings` is unstructured.\n3. Weather data is also unstructed. Let's extract the temperature and structure weather description."
                }
            },
            "source": "Let use `//home/samples/squirrels-hectare-data`. This dataset contains environmental data related to each of the 350 \u201ccountable\u201d hectares of Central Park. Examples include weather, litter, animals sighted, and human density.\n\nThis dataset has several problems:\n1. Date has a non-standard format.\n2. Columns `other_animals_sightings` is unstructured.\n3. Weather data is also unstructed. Let's extract the temperature and structure weather description."
        },
        {
            "cell_type": "markdown",
            "id": "56d2ed70-d2eb-4be1-8f41-3c55d2675a2d",
            "metadata": {
                "cell_id": "56d2ed70-d2eb-4be1-8f41-3c55d2675a2d",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Extract weather data"
                }
            },
            "source": "## Extract weather data"
        },
        {
            "cell_type": "markdown",
            "id": "ae3832c5-4b19-4b6c-bd50-d9694b625ae0",
            "metadata": {
                "cell_id": "ae3832c5-4b19-4b6c-bd50-d9694b625ae0",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Request for original dataset size. We are going to use this data to estimate the proportion of parsed values."
                }
            },
            "source": "Request for original dataset size. We are going to use this data to estimate the proportion of parsed values."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "ca5eb7d8-b153-4007-b8d1-50c8114daef6",
            "metadata": {
                "cell_id": "ca5eb7d8-b153-4007-b8d1-50c8114daef6",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "dataset_size = yt.get(\"//home/samples/squirrels-hectare-data/@row_count\")\nprint(dataset_size)"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "700\n"
                }
            ],
            "source": "dataset_size = yt.get(\"//home/samples/squirrels-hectare-data/@row_count\")\nprint(dataset_size)"
        },
        {
            "cell_type": "markdown",
            "id": "7d72b7e1-14b7-42a9-9706-b7229d784271",
            "metadata": {
                "cell_id": "7d72b7e1-14b7-42a9-9706-b7229d784271",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Looking at the dataset, we can notice some facts:\n1. Temperature data is at the beginning of the record\n2. Temperature can be indicated in either Fahrenheit or Celsius\n3. Typically the data is separated by a comma\n\nThis way we can iteratively apply our parsing function in the map operation and evaluate the records that could not be parsed. Since there are few records in the dataset, we can read them and watch them in this notebook."
                }
            },
            "source": "Looking at the dataset, we can notice some facts:\n1. Temperature data is at the beginning of the record\n2. Temperature can be indicated in either Fahrenheit or Celsius\n3. Typically the data is separated by a comma\n\nThis way we can iteratively apply our parsing function in the map operation and evaluate the records that could not be parsed. Since there are few records in the dataset, we can read them and watch them in this notebook."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "1b8c3c66-365d-4b1e-8b1d-57b82a14ccd0",
            "metadata": {
                "cell_id": "1b8c3c66-365d-4b1e-8b1d-57b82a14ccd0",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "F_TEMP_REGEXP = re.compile(r\"^~?(\\d+\\.?\\d*)(-\\d+)?\\s*[\u00b0\u00ba]?\\s*[fF]\")\nC_TEMP_REGEXP = re.compile(r\"^~?(\\d+\\.?\\d*)\\s*[\u00b0\u00ba]?\\s*[cC]\")\nF2_TEMP_REGEXP = re.compile(r\"(\\d+\\.?\\d*)[s|ish]\")\n\ndef f_to_c(temp: int) -> int:\n    return round((5 / 9) * (temp - 32))\n\ndef str_to_int(value: str) -> int:\n    return round(float(value))\n\ndef parse_weather_data(raw_weather_data: str | None) -> tuple[int, list[str]]:\n    if raw_weather_data is None:\n        return None, []\n\n    weather_data_parts = [part.strip(\" \").lower() for part in raw_weather_data.split(\",\")]\n\n    if len(weather_data_parts) == 0:\n        None, []\n    maybe_temp = weather_data_parts[0]\n\n    f_match = F_TEMP_REGEXP.search(maybe_temp)\n    if f_match:\n        return f_to_c(str_to_int(f_match.group(1))), weather_data_parts[1:]\n    \n    f2_match = F2_TEMP_REGEXP.search(maybe_temp) \n    if f2_match:\n        return f_to_c(str_to_int(f2_match.group(1))), weather_data_parts[1:]\n\n    c_match = C_TEMP_REGEXP.search(maybe_temp)\n    if c_match:\n        return str_to_int(c_match.group(1)), weather_data_parts[1:]\n    \n    return None, weather_data_parts"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
                }
            ],
            "source": "F_TEMP_REGEXP = re.compile(r\"^~?(\\d+\\.?\\d*)(-\\d+)?\\s*[\u00b0\u00ba]?\\s*[fF]\")\nC_TEMP_REGEXP = re.compile(r\"^~?(\\d+\\.?\\d*)\\s*[\u00b0\u00ba]?\\s*[cC]\")\nF2_TEMP_REGEXP = re.compile(r\"(\\d+\\.?\\d*)[s|ish]\")\n\ndef f_to_c(temp: int) -> int:\n    return round((5 / 9) * (temp - 32))\n\ndef str_to_int(value: str) -> int:\n    return round(float(value))\n\ndef parse_weather_data(raw_weather_data: str | None) -> tuple[int, list[str]]:\n    if raw_weather_data is None:\n        return None, []\n\n    weather_data_parts = [part.strip(\" \").lower() for part in raw_weather_data.split(\",\")]\n\n    if len(weather_data_parts) == 0:\n        None, []\n    maybe_temp = weather_data_parts[0]\n\n    f_match = F_TEMP_REGEXP.search(maybe_temp)\n    if f_match:\n        return f_to_c(str_to_int(f_match.group(1))), weather_data_parts[1:]\n    \n    f2_match = F2_TEMP_REGEXP.search(maybe_temp) \n    if f2_match:\n        return f_to_c(str_to_int(f2_match.group(1))), weather_data_parts[1:]\n\n    c_match = C_TEMP_REGEXP.search(maybe_temp)\n    if c_match:\n        return str_to_int(c_match.group(1)), weather_data_parts[1:]\n    \n    return None, weather_data_parts"
        },
        {
            "cell_type": "markdown",
            "id": "ae5d7a2b-a6fc-4096-a089-b1118eb944da",
            "metadata": {
                "cell_id": "ae5d7a2b-a6fc-4096-a089-b1118eb944da",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Map operation for testing parsiong function"
                }
            },
            "source": "## Map operation for testing parsiong function"
        },
        {
            "cell_type": "markdown",
            "id": "bf839c80-0ed4-4e99-a903-50ac30ab8eb5",
            "metadata": {
                "cell_id": "bf839c80-0ed4-4e99-a903-50ac30ab8eb5",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Let's run [map operation](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/map)"
                }
            },
            "source": "Let's run [map operation](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/map)"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "5e597bd5-a8b5-4c22-8891-5953a573624e",
            "metadata": {
                "cell_id": "5e597bd5-a8b5-4c22-8891-5953a573624e",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "def filter_records_without_temperature(record: dict) -> Iterable[dict]:\n    temp, weather_data = parse_weather_data(record[\"sighter_observed_weather_data\"])\n    if not temp:\n        yield {\"sighter_observed_weather_data\": record[\"sighter_observed_weather_data\"]}\n\nyt.run_map(\n    filter_records_without_temperature,\n    source_table=\"//home/samples/squirrels-hectare-data\",\n    destination_table=f\"{working_dir}/records_without_temperature\",\n)\n\nrecords = [record for record in yt.read_table(f\"{working_dir}/records_without_temperature\")]\nfiltered_count = yt.get(f\"{working_dir}/records_without_temperature/@row_count\")\nprint(f\"{filtered_count / dataset_size * 100}%\")\n\nfor record in records:\n    print(record)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:19,970\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/e4a31444-46a78637-134403e8-8adec6c/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:19,990\tINFO\t( 0 min) operation e4a31444-46a78637-134403e8-8adec6c starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:20,541\tINFO\t( 0 min) operation e4a31444-46a78637-134403e8-8adec6c initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:21,612\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false, 'mapper': {'title': 'filter_records_without_tempera'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:23,930\tINFO\t( 0 min) operation e4a31444-46a78637-134403e8-8adec6c: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:35,413\tINFO\t( 0 min) operation e4a31444-46a78637-134403e8-8adec6c: running=0     completed=1     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:38,013\tINFO\t( 0 min) operation e4a31444-46a78637-134403e8-8adec6c completed\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "10.857142857142858%\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'cloudy, slight drizzle'}\n{'sighter_observed_weather_data': 'sunny, chilly'}\n{'sighter_observed_weather_data': 'Misty'}\n{'sighter_observed_weather_data': 'Muggy, cloudy, slightly damp'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'chilly, sunny'}\n{'sighter_observed_weather_data': 'cloudy, drizzling'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'drizzling'}\n{'sighter_observed_weather_data': 'overcast, damp'}\n{'sighter_observed_weather_data': 'Partly cloudy, dewy'}\n{'sighter_observed_weather_data': 'Cool, Cloudy'}\n{'sighter_observed_weather_data': 'partly cloudy, pleasant'}\n{'sighter_observed_weather_data': 'rainy'}\n{'sighter_observed_weather_data': 'cool, cloudy'}\n{'sighter_observed_weather_data': 'cool, windy'}\n{'sighter_observed_weather_data': 'got dark very suddenly'}\n{'sighter_observed_weather_data': 'damp, misty, cloudy'}\n{'sighter_observed_weather_data': 'damp, humid, cloudy, dreary, misty, not raining, moist'}\n{'sighter_observed_weather_data': 'rainy'}\n{'sighter_observed_weather_data': 'cool, windy'}\n{'sighter_observed_weather_data': 'Sunny, Windy, Cool'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'Sunny, Blue Sky'}\n{'sighter_observed_weather_data': 'Sunny'}\n{'sighter_observed_weather_data': 'drizzling, cloudy'}\n{'sighter_observed_weather_data': 'Partly cloudy'}\n{'sighter_observed_weather_data': 'Humid'}\n{'sighter_observed_weather_data': 'drizzling cloudy'}\n{'sighter_observed_weather_data': 'Cool'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'Cool, cloudy & light drizzle'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'Misty, Rain, Cool'}\n{'sighter_observed_weather_data': 'Muggy, but cool. Sprinkling.'}\n{'sighter_observed_weather_data': 'Humid'}\n{'sighter_observed_weather_data': 'drizzling'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'Clear Skies, Breezy'}\n{'sighter_observed_weather_data': 'Calm'}\n{'sighter_observed_weather_data': 'clear blue sky, breezy, getting cold'}\n{'sighter_observed_weather_data': 'drizzling'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'sprinkling'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'Overcast & humid but cool'}\n{'sighter_observed_weather_data': 'Overcast & humid but cool'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'overcast, dusk'}\n{'sighter_observed_weather_data': 'cool, overcast'}\n{'sighter_observed_weather_data': 'cloudy'}\n{'sighter_observed_weather_data': 'cool, sunny'}\n{'sighter_observed_weather_data': 'cold, sunny'}\n{'sighter_observed_weather_data': 'sunny, cool'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'cool, dusk'}\n{'sighter_observed_weather_data': 'cool, dusk'}\n{'sighter_observed_weather_data': 'cloudy, misting rain'}\n{'sighter_observed_weather_data': 'Clear, Calm, No wind'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'artsy lighting, breezy'}\n{'sighter_observed_weather_data': 'Humid. Overcast.'}\n{'sighter_observed_weather_data': 'Misty, rain, cool'}\n{'sighter_observed_weather_data': 'Raining'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'Sunny, cloudy, chilly, damp, slightly warm'}\n{'sighter_observed_weather_data': 'Overcast lite rain'}\n{'sighter_observed_weather_data': 'Humid'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': 'overcast'}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': None}\n{'sighter_observed_weather_data': None}\n"
                }
            ],
            "source": "def filter_records_without_temperature(record: dict) -> Iterable[dict]:\n    temp, weather_data = parse_weather_data(record[\"sighter_observed_weather_data\"])\n    if not temp:\n        yield {\"sighter_observed_weather_data\": record[\"sighter_observed_weather_data\"]}\n\nyt.run_map(\n    filter_records_without_temperature,\n    source_table=\"//home/samples/squirrels-hectare-data\",\n    destination_table=f\"{working_dir}/records_without_temperature\",\n)\n\nrecords = [record for record in yt.read_table(f\"{working_dir}/records_without_temperature\")]\nfiltered_count = yt.get(f\"{working_dir}/records_without_temperature/@row_count\")\nprint(f\"{filtered_count / dataset_size * 100}%\")\n\nfor record in records:\n    print(record)"
        },
        {
            "cell_type": "markdown",
            "id": "7fc911a5-0884-4f76-a590-234107323945",
            "metadata": {
                "cell_id": "7fc911a5-0884-4f76-a590-234107323945",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "We can verify that there is no more unparsed temperature data. The proportion of undefined temperature is 10%, let's consider it acceptable for demonstration."
                }
            },
            "source": "We can verify that there is no more unparsed temperature data. The proportion of undefined temperature is 10%, let's consider it acceptable for demonstration."
        },
        {
            "cell_type": "markdown",
            "id": "16b2cbe5-522e-4c4f-b5ec-d77a3ca9beba",
            "metadata": {
                "cell_id": "16b2cbe5-522e-4c4f-b5ec-d77a3ca9beba",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Prepare dataset"
                }
            },
            "source": "## Prepare dataset"
        },
        {
            "cell_type": "markdown",
            "id": "d48ac3f9-9591-497a-818e-129a4ace6be2",
            "metadata": {
                "cell_id": "d48ac3f9-9591-497a-818e-129a4ace6be2",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Dates on YTsaurus are presented as days from `01-01-1970` (like unittime, but days) -> Dates have Int type. For simplicity, we will not use data schematization at this stage, except for some important columns.\n\nIn the next step we plan to join this data with another dataset, so to avoid problems with implicit type casting, we create an explicit non-strict schema only for three columns:\n* date\n* hectare\n* shift"
                }
            },
            "source": "Dates on YTsaurus are presented as days from `01-01-1970` (like unittime, but days) -> Dates have Int type. For simplicity, we will not use data schematization at this stage, except for some important columns.\n\nIn the next step we plan to join this data with another dataset, so to avoid problems with implicit type casting, we create an explicit non-strict schema only for three columns:\n* date\n* hectare\n* shift"
        },
        {
            "cell_type": "markdown",
            "id": "4fabfec5-4103-4d6f-b123-eb09f8c48693",
            "metadata": {
                "cell_id": "4fabfec5-4103-4d6f-b123-eb09f8c48693",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "YTsaurus operation also can be implemented as python classes."
                }
            },
            "source": "YTsaurus operation also can be implemented as python classes."
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "32710b7a-654a-40f3-aa70-5ed4fab38f36",
            "metadata": {
                "cell_id": "32710b7a-654a-40f3-aa70-5ed4fab38f36",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "REMOVE_BRACKETS_REGEXP = re.compile(r\"\\(.*?\\)\")\n\nclass HectareDataCanonizer:\n    def _canonize_date(self, date: str) -> int:\n        day, month, year = date[2:4], date[:2], date[4:8]\n        date_str = f\"{year}-{month}-{day}\"\n        date_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n        unix_days = int((date_obj.date() - datetime.date.fromtimestamp(0)).days)\n        return unix_days\n\n    def _canonize_other_animals(self, other_animals_sightings: str | None) -> list[str]:\n        if not other_animals_sightings:\n            return []\n\n        return [REMOVE_BRACKETS_REGEXP.sub(\"\", r).strip(\" \").lower() for r in other_animals_sightings.split(\",\")]\n\n    def __call__(self, record: dict) -> Iterable[dict]:\n        record[\"date\"] = self._canonize_date(record[\"date\"])\n        temperature, weather_data = parse_weather_data(record[\"sighter_observed_weather_data\"])\n        record[\"temperature_celsius\"] = temperature\n        record[\"weather_data\"] = weather_data\n        record[\"other_animals_sightings\"] = self._canonize_other_animals(record[\"other_animals_sightings\"])\n        yield record\n\ncanonized_squirrels_hectare_data = f\"{working_dir}/hectare_data\"\nschema = yt.schema.TableSchema(strict=False)\nschema.add_column(\"date\", type_info.Date)\nschema.add_column(\"hectare\", type_info.String)\nschema.add_column(\"shift\", type_info.String)\n\nyt.create(\"table\", canonized_squirrels_hectare_data, force=True, attributes={\"schema\": schema.to_yson_type()})\n\nyt.run_map(\n    HectareDataCanonizer(),\n    source_table=\"//home/samples/squirrels-hectare-data\",\n    destination_table=canonized_squirrels_hectare_data,\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:48,978\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/80abcaf5-61bd8e50-134403e8-d29aa2e0/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:48,999\tINFO\t( 0 min) operation 80abcaf5-61bd8e50-134403e8-d29aa2e0 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:51,630\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false, 'mapper': {'title': 'HectareDataCanonizer'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:51,659\tINFO\t( 0 min) operation 80abcaf5-61bd8e50-134403e8-d29aa2e0: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:29:53,853\tINFO\t( 0 min) operation 80abcaf5-61bd8e50-134403e8-d29aa2e0: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:35:52,776\tINFO\t( 6 min) operation 80abcaf5-61bd8e50-134403e8-d29aa2e0 completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e8515750>"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "REMOVE_BRACKETS_REGEXP = re.compile(r\"\\(.*?\\)\")\n\nclass HectareDataCanonizer:\n    def _canonize_date(self, date: str) -> int:\n        day, month, year = date[2:4], date[:2], date[4:8]\n        date_str = f\"{year}-{month}-{day}\"\n        date_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n        unix_days = int((date_obj.date() - datetime.date.fromtimestamp(0)).days)\n        return unix_days\n\n    def _canonize_other_animals(self, other_animals_sightings: str | None) -> list[str]:\n        if not other_animals_sightings:\n            return []\n\n        return [REMOVE_BRACKETS_REGEXP.sub(\"\", r).strip(\" \").lower() for r in other_animals_sightings.split(\",\")]\n\n    def __call__(self, record: dict) -> Iterable[dict]:\n        record[\"date\"] = self._canonize_date(record[\"date\"])\n        temperature, weather_data = parse_weather_data(record[\"sighter_observed_weather_data\"])\n        record[\"temperature_celsius\"] = temperature\n        record[\"weather_data\"] = weather_data\n        record[\"other_animals_sightings\"] = self._canonize_other_animals(record[\"other_animals_sightings\"])\n        yield record\n\ncanonized_squirrels_hectare_data = f\"{working_dir}/hectare_data\"\nschema = yt.schema.TableSchema(strict=False)\nschema.add_column(\"date\", type_info.Date)\nschema.add_column(\"hectare\", type_info.String)\nschema.add_column(\"shift\", type_info.String)\n\nyt.create(\"table\", canonized_squirrels_hectare_data, force=True, attributes={\"schema\": schema.to_yson_type()})\n\nyt.run_map(\n    HectareDataCanonizer(),\n    source_table=\"//home/samples/squirrels-hectare-data\",\n    destination_table=canonized_squirrels_hectare_data,\n)"
        },
        {
            "cell_type": "markdown",
            "id": "149202f1-8ece-40ba-9553-dca8ff745c99",
            "metadata": {
                "cell_id": "149202f1-8ece-40ba-9553-dca8ff745c99",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "# Verify dataset"
                }
            },
            "source": "# Verify dataset"
        },
        {
            "cell_type": "markdown",
            "id": "f45926de-6b76-4dda-a9bd-014165b2edac",
            "metadata": {
                "cell_id": "f45926de-6b76-4dda-a9bd-014165b2edac",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "We have a dataset from the same authors, that contains squirrel data for each of the 3,023 sightings, including location coordinates, age, primary and secondary fur color, elevation, activities, communications, and interactions between squirrels and humans.\n\nWe can use this data for:\n1. Verifying our current dataset\n2. Creating a new dataset that includes data from both of them"
                }
            },
            "source": "We have a dataset from the same authors, that contains squirrel data for each of the 3,023 sightings, including location coordinates, age, primary and secondary fur color, elevation, activities, communications, and interactions between squirrels and humans.\n\nWe can use this data for:\n1. Verifying our current dataset\n2. Creating a new dataset that includes data from both of them"
        },
        {
            "cell_type": "markdown",
            "id": "6790171d-3283-4b77-9971-76dc65599ed4",
            "metadata": {
                "cell_id": "6790171d-3283-4b77-9971-76dc65599ed4",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Since we will be using the reduce operation, we have to [sort](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/sort) the table by the keys."
                }
            },
            "source": "Since we will be using the reduce operation, we have to [sort](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/sort) the table by the keys."
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "fc211609-5dc5-46c7-bdec-cd1a57c2f496",
            "metadata": {
                "cell_id": "fc211609-5dc5-46c7-bdec-cd1a57c2f496",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "yt.run_sort(\n    source_table=canonized_squirrels_hectare_data,\n    destination_table=canonized_squirrels_hectare_data,\n    sort_by=[\"date\", \"hectare\", \"shift\"],\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:35:53,175\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/8f9fe338-19a84995-134403e8-ff867333/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:35:53,197\tINFO\t( 0 min) operation 8f9fe338-19a84995-134403e8-ff867333 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:35:53,721\tINFO\t( 0 min) operation 8f9fe338-19a84995-134403e8-ff867333 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:35:55,423\tINFO\t( 0 min) operation 8f9fe338-19a84995-134403e8-ff867333: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:35:59,217\tINFO\t( 0 min) operation 8f9fe338-19a84995-134403e8-ff867333 completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e85728d0>"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "yt.run_sort(\n    source_table=canonized_squirrels_hectare_data,\n    destination_table=canonized_squirrels_hectare_data,\n    sort_by=[\"date\", \"hectare\", \"shift\"],\n)"
        },
        {
            "cell_type": "markdown",
            "id": "443a949d-c865-4386-a5ed-f54cb97ebcb9",
            "metadata": {
                "cell_id": "443a949d-c865-4386-a5ed-f54cb97ebcb9",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Let's count how many squirrels were seen every day in the first dataset. Let's use [reduce operation](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/reduce)"
                }
            },
            "source": "Let's count how many squirrels were seen every day in the first dataset. Let's use [reduce operation](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/reduce)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "25926dab-0b41-4c0c-86cc-b28e5afff251",
            "metadata": {
                "cell_id": "25926dab-0b41-4c0c-86cc-b28e5afff251",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "def sum_squirrels_by_date_hectare(key: dict[str, int], records: Iterable[dict]):\n    squirrels = 0\n    for record in records:\n        squirrels += record[\"number_of_squirrels\"]\n    yield {\"date\": int(key[\"date\"]), \"squirrels\": squirrels}\n\nsquirrels_by_date_hectare = f\"{working_dir}/squirrels_by_date_hectare\"\n\nyt.run_reduce(\n    sum_squirrels_by_date_hectare,\n    source_table=canonized_squirrels_hectare_data,\n    destination_table=squirrels_by_date_hectare,\n    reduce_by=[\"date\"],\n)\nyt.run_sort(\n    source_table=squirrels_by_date_hectare,\n    destination_table=squirrels_by_date_hectare,\n    sort_by=[\"date\"],\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:36:06,106\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/bbac56ad-12c2673a-134403e8-b3ce3e42/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:36:06,130\tINFO\t( 0 min) operation bbac56ad-12c2673a-134403e8-b3ce3e42 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:36:06,646\tINFO\t( 0 min) operation bbac56ad-12c2673a-134403e8-b3ce3e42 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:36:09,292\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false, 'reducer': {'title': 'sum_squirrels_by_date_hectare'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:36:09,312\tINFO\t( 0 min) operation bbac56ad-12c2673a-134403e8-b3ce3e42: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:36:10,935\tINFO\t( 0 min) operation bbac56ad-12c2673a-134403e8-b3ce3e42: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:44,548\tINFO\t( 3 min) operation bbac56ad-12c2673a-134403e8-b3ce3e42 completed\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:44,980\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/5102a997-94566239-134403e8-55d0933f/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:45,001\tINFO\t( 0 min) operation 5102a997-94566239-134403e8-55d0933f starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:45,520\tINFO\t( 0 min) operation 5102a997-94566239-134403e8-55d0933f initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:46,654\tINFO\t( 0 min) operation 5102a997-94566239-134403e8-55d0933f: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:49,878\tINFO\t( 0 min) operation 5102a997-94566239-134403e8-55d0933f: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:57,897\tINFO\t( 0 min) operation 5102a997-94566239-134403e8-55d0933f completing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:58,415\tINFO\t( 0 min) operation 5102a997-94566239-134403e8-55d0933f completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e9e3ccd0>"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "def sum_squirrels_by_date_hectare(key: dict[str, int], records: Iterable[dict]):\n    squirrels = 0\n    for record in records:\n        squirrels += record[\"number_of_squirrels\"]\n    yield {\"date\": int(key[\"date\"]), \"squirrels\": squirrels}\n\nsquirrels_by_date_hectare = f\"{working_dir}/squirrels_by_date_hectare\"\n\nyt.run_reduce(\n    sum_squirrels_by_date_hectare,\n    source_table=canonized_squirrels_hectare_data,\n    destination_table=squirrels_by_date_hectare,\n    reduce_by=[\"date\"],\n)\nyt.run_sort(\n    source_table=squirrels_by_date_hectare,\n    destination_table=squirrels_by_date_hectare,\n    sort_by=[\"date\"],\n)"
        },
        {
            "cell_type": "markdown",
            "id": "926b4179-fe12-4f5c-89ea-a621c1fc2649",
            "metadata": {
                "cell_id": "926b4179-fe12-4f5c-89ea-a621c1fc2649",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Let's count how many squirrels were seen every day in the second dataset."
                }
            },
            "source": "Let's count how many squirrels were seen every day in the second dataset."
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "e51a6070-bca1-4a6d-938b-7d5817039145",
            "metadata": {
                "cell_id": "e51a6070-bca1-4a6d-938b-7d5817039145",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "sorted_squirrels_data = f\"{working_dir}/sorted_squirrels_data\"\n\nyt.run_sort(\n    source_table=\"//home/samples/squirrels\",\n    destination_table=sorted_squirrels_data,\n    sort_by=[\"date\", \"hectare\", \"shift\"],\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:59,680\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/586d4921-cd22b52f-134403e8-169ebdcc/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:39:59,694\tINFO\t( 0 min) operation 586d4921-cd22b52f-134403e8-169ebdcc starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:00,216\tINFO\t( 0 min) operation 586d4921-cd22b52f-134403e8-169ebdcc initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:03,447\tINFO\t( 0 min) operation 586d4921-cd22b52f-134403e8-169ebdcc: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:17,344\tINFO\t( 0 min) operation 586d4921-cd22b52f-134403e8-169ebdcc: running=0     completed=1     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:20,454\tINFO\t( 0 min) operation 586d4921-cd22b52f-134403e8-169ebdcc completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e847fd10>"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "sorted_squirrels_data = f\"{working_dir}/sorted_squirrels_data\"\n\nyt.run_sort(\n    source_table=\"//home/samples/squirrels\",\n    destination_table=sorted_squirrels_data,\n    sort_by=[\"date\", \"hectare\", \"shift\"],\n)"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "aa922e78-9223-4da2-b129-bc82d09d98a3",
            "metadata": {
                "cell_id": "aa922e78-9223-4da2-b129-bc82d09d98a3",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "def sum_squirrels_by_date_squirrels(key: dict[str, int], records: Iterable[dict]):\n    squirrels = []\n    for record in records:\n        squirrels.append(record[\"squirrel_id\"])\n    squirrels_count = len(squirrels)\n    yield {\"date\": int(key[\"date\"]), \"squirrels\": squirrels_count}\n\nsquirrels_by_date_squirrels = f\"{working_dir}/squirrels_by_date_squirrels\"\n\nyt.run_reduce(\n    sum_squirrels_by_date_squirrels,\n    source_table=sorted_squirrels_data,\n    destination_table=squirrels_by_date_squirrels,\n    reduce_by=[\"date\"],\n)\nyt.run_sort(\n    source_table=squirrels_by_date_squirrels,\n    destination_table=squirrels_by_date_squirrels,\n    sort_by=[\"date\", \"hectare\", \"shift\"],\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:27,440\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/38798a85-54287e4b-134403e8-b03b2314/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:27,466\tINFO\t( 0 min) operation 38798a85-54287e4b-134403e8-b03b2314 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:27,991\tINFO\t( 0 min) operation 38798a85-54287e4b-134403e8-b03b2314 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:28,531\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false, 'reducer': {'title': 'sum_squirrels_by_date_squirrel'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:29,123\tINFO\t( 0 min) operation 38798a85-54287e4b-134403e8-b03b2314: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:40:32,467\tINFO\t( 0 min) operation 38798a85-54287e4b-134403e8-b03b2314: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:37,534\tINFO\t( 3 min) operation 38798a85-54287e4b-134403e8-b03b2314 completed\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:38,228\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/e6700343-652fa9ff-134403e8-b9a7a44e/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:38,250\tINFO\t( 0 min) operation e6700343-652fa9ff-134403e8-b9a7a44e initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:41,296\tINFO\t( 0 min) operation e6700343-652fa9ff-134403e8-b9a7a44e: running=0     completed=1     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:41,820\tINFO\t( 0 min) operation e6700343-652fa9ff-134403e8-b9a7a44e completing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:42,345\tINFO\t( 0 min) operation e6700343-652fa9ff-134403e8-b9a7a44e completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e816b090>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "def sum_squirrels_by_date_squirrels(key: dict[str, int], records: Iterable[dict]):\n    squirrels = []\n    for record in records:\n        squirrels.append(record[\"squirrel_id\"])\n    squirrels_count = len(squirrels)\n    yield {\"date\": int(key[\"date\"]), \"squirrels\": squirrels_count}\n\nsquirrels_by_date_squirrels = f\"{working_dir}/squirrels_by_date_squirrels\"\n\nyt.run_reduce(\n    sum_squirrels_by_date_squirrels,\n    source_table=sorted_squirrels_data,\n    destination_table=squirrels_by_date_squirrels,\n    reduce_by=[\"date\"],\n)\nyt.run_sort(\n    source_table=squirrels_by_date_squirrels,\n    destination_table=squirrels_by_date_squirrels,\n    sort_by=[\"date\", \"hectare\", \"shift\"],\n)"
        },
        {
            "cell_type": "markdown",
            "id": "23c1a830-de46-44eb-b63d-db239947efb2",
            "metadata": {
                "cell_id": "23c1a830-de46-44eb-b63d-db239947efb2",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Join tables"
                }
            },
            "source": "## Join tables"
        },
        {
            "cell_type": "markdown",
            "id": "3e83310c-b745-441f-a2dd-f9650e15ddd7",
            "metadata": {
                "cell_id": "3e83310c-b745-441f-a2dd-f9650e15ddd7",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "Now we can compare the data."
                }
            },
            "source": "Now we can compare the data."
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "98b94d3b-13f8-4fe9-b50a-b462be5d77ed",
            "metadata": {
                "cell_id": "98b94d3b-13f8-4fe9-b50a-b462be5d77ed",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "@yt.with_context\ndef reduce_compare_squirrels_count(key: dict[str, str], records: Iterable[dict], context: yt.schema.Context):\n    count_by_table = {}\n    for record in records:\n        table_index = context.table_index\n        assert table_index not in count_by_table \n        count_by_table[table_index] = record[\"squirrels\"]\n    if count_by_table.get(0) != count_by_table.get(1):\n        yield {\"date\": key[\"date\"], \"squirrels_data\": count_by_table.get(0), \"hectare_data\": count_by_table.get(1)}\n\nsquirrels_count_diff = f\"{working_dir}/squirrels_count_diff\"\n\nyt.run_reduce(\n    reduce_compare_squirrels_count,\n    source_table=[squirrels_by_date_squirrels, squirrels_by_date_hectare],\n    destination_table=squirrels_count_diff,\n    reduce_by=[\"date\"],\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:48,746\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/661600b1-9d03b2a2-134403e8-77e968b3/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:48,765\tINFO\t( 0 min) operation 661600b1-9d03b2a2-134403e8-77e968b3 starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:49,284\tINFO\t( 0 min) operation 661600b1-9d03b2a2-134403e8-77e968b3 initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:50,878\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false, 'reducer': {'title': 'reduce_compare_squirrels_count'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:50,897\tINFO\t( 0 min) operation 661600b1-9d03b2a2-134403e8-77e968b3: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:43:54,205\tINFO\t( 0 min) operation 661600b1-9d03b2a2-134403e8-77e968b3: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:45,171\tINFO\t( 2 min) operation 661600b1-9d03b2a2-134403e8-77e968b3 completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e9e87710>"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "@yt.with_context\ndef reduce_compare_squirrels_count(key: dict[str, str], records: Iterable[dict], context: yt.schema.Context):\n    count_by_table = {}\n    for record in records:\n        table_index = context.table_index\n        assert table_index not in count_by_table \n        count_by_table[table_index] = record[\"squirrels\"]\n    if count_by_table.get(0) != count_by_table.get(1):\n        yield {\"date\": key[\"date\"], \"squirrels_data\": count_by_table.get(0), \"hectare_data\": count_by_table.get(1)}\n\nsquirrels_count_diff = f\"{working_dir}/squirrels_count_diff\"\n\nyt.run_reduce(\n    reduce_compare_squirrels_count,\n    source_table=[squirrels_by_date_squirrels, squirrels_by_date_hectare],\n    destination_table=squirrels_count_diff,\n    reduce_by=[\"date\"],\n)"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "27d32e8b-a9aa-4636-98d1-033077cac205",
            "metadata": {
                "cell_id": "27d32e8b-a9aa-4636-98d1-033077cac205",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "for record in yt.read_table(squirrels_count_diff):\n    print(record)"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'date': 17814, 'squirrels_data': 335, 'hectare_data': 334}\n"
                }
            ],
            "source": "for record in yt.read_table(squirrels_count_diff):\n    print(record)"
        },
        {
            "cell_type": "markdown",
            "id": "0a14d44e-a32f-4488-8b70-d5443aef7993",
            "metadata": {
                "cell_id": "0a14d44e-a32f-4488-8b70-d5443aef7993",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "We can see that the data is not the same on only one day and differs by 1. For the demo example, we consider this result acceptable."
                }
            },
            "source": "We can see that the data is not the same on only one day and differs by 1. For the demo example, we consider this result acceptable."
        },
        {
            "cell_type": "markdown",
            "id": "579da997-9fc5-41e2-ba82-2143e606716f",
            "metadata": {
                "cell_id": "579da997-9fc5-41e2-ba82-2143e606716f",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "# Make new dataset"
                }
            },
            "source": "# Make new dataset"
        },
        {
            "cell_type": "markdown",
            "id": "1010431d-b18e-42c9-b3ea-a6184ba1f463",
            "metadata": {
                "cell_id": "1010431d-b18e-42c9-b3ea-a6184ba1f463",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "## Use destination table with schema\n\nWe can secribe table's schema as yt_dataclass and reuse this object in next steps."
                }
            },
            "source": "## Use destination table with schema\n\nWe can secribe table's schema as yt_dataclass and reuse this object in next steps."
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "5daec413-ab60-49f4-abed-d6b90a3ea397",
            "metadata": {
                "cell_id": "5daec413-ab60-49f4-abed-d6b90a3ea397",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "from typing import Optional, Any\n\n@yt.yt_dataclass\nclass JoinedDatasetRow:\n    date: yt.schema.Date\n    hectare: str\n    shift: str\n    other_animals_sightings: list[str]\n    temperature_celsius: Optional[int]\n    weather_data: list[str]\n    age: str\n    squirrel_id: str\n    running: bool\n    chasing: bool\n    climbing: bool\n    eating: bool\n    foraging: bool\n    kuks: bool\n    quaas: bool\n    moans: bool\n    tail_flags: bool\n    tail_twitches: bool\n    approaches: bool\n    indifferent: bool\n    runs_from: bool\n\n\njoined_dataset = f\"{working_dir}/joined_dataset\"\nyt.create(\"table\", joined_dataset, force=True, attributes={\"schema\": yt.schema.TableSchema.from_row_type(JoinedDatasetRow)})\n\n\n@yt.with_context\ndef reduce_join(key: dict[str, str], records: Iterable[dict[str, Any]], context: yt.schema.Context) -> Iterable:\n    squirrels: list[SquirrelsRow] = []\n    other_animals_sightings = set()\n    temperature_celsius = None\n    weather_data = set()\n    for record in records:\n        if context.table_index == 0:\n            squirrels.append(record)\n        elif context.table_index == 1:\n            other_animals_sightings.update(set(record[\"other_animals_sightings\"]))\n            temperature_celsius = record[\"temperature_celsius\"] if temperature_celsius is None else (temperature_celsius + record[\"temperature_celsius\"]) / 2\n            weather_data.update(set(record[\"weather_data\"]))\n    temperature_celsius = round(temperature_celsius) if temperature_celsius is not None else None\n    weather_data = list(weather_data)\n    other_animals_sightings = list(other_animals_sightings)\n    for squirrel in squirrels:\n        yield dict(\n            date=key[\"date\"],\n            hectare=key[\"hectare\"],\n            shift=key[\"shift\"],\n            other_animals_sightings=other_animals_sightings,\n            temperature_celsius=temperature_celsius,\n            weather_data=weather_data,\n            age=squirrel[\"age\"],\n            squirrel_id=squirrel[\"squirrel_id\"],\n            running=squirrel[\"running\"],\n            chasing=squirrel[\"chasing\"],\n            climbing=squirrel[\"climbing\"],\n            eating=squirrel[\"eating\"],\n            foraging=squirrel[\"foraging\"],\n            kuks=squirrel[\"kuks\"],\n            quaas=squirrel[\"quaas\"],\n            moans=squirrel[\"moans\"],\n            tail_flags=squirrel[\"tail_flags\"],\n            tail_twitches=squirrel[\"tail_twitches\"],\n            approaches=squirrel[\"approaches\"],\n            indifferent=squirrel[\"indifferent\"],\n            runs_from=squirrel[\"runs_from\"],\n        )\n\n\nyt.run_reduce(\n    reduce_join,\n    source_table=[sorted_squirrels_data, canonized_squirrels_hectare_data],\n    destination_table=joined_dataset,\n    reduce_by=[\"date\", \"hectare\", \"shift\"],\n)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:51,444\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/5a8606e7-ae10c92d-134403e8-377ace7e/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:51,461\tINFO\t( 0 min) operation 5a8606e7-ae10c92d-134403e8-377ace7e starting\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:51,980\tINFO\t( 0 min) operation 5a8606e7-ae10c92d-134403e8-377ace7e initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:52,522\tINFO\t( 0 min) Unrecognized spec: {'enable_partitioned_data_balancing': false, 'reducer': {'title': 'reduce_join'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:53,613\tINFO\t( 0 min) operation 5a8606e7-ae10c92d-134403e8-377ace7e: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:57,176\tINFO\t( 0 min) operation 5a8606e7-ae10c92d-134403e8-377ace7e: running=1     completed=0     pending=0     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:58,063\tINFO\t( 0 min) operation 5a8606e7-ae10c92d-134403e8-377ace7e completing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:46:59,096\tINFO\t( 0 min) operation 5a8606e7-ae10c92d-134403e8-377ace7e completed\n"
                },
                {
                    "data": {
                        "text/plain": "<yt.wrapper.operation_commands.Operation at 0x7fa3e8561490>"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from typing import Optional, Any\n\n@yt.yt_dataclass\nclass JoinedDatasetRow:\n    date: yt.schema.Date\n    hectare: str\n    shift: str\n    other_animals_sightings: list[str]\n    temperature_celsius: Optional[int]\n    weather_data: list[str]\n    age: str\n    squirrel_id: str\n    running: bool\n    chasing: bool\n    climbing: bool\n    eating: bool\n    foraging: bool\n    kuks: bool\n    quaas: bool\n    moans: bool\n    tail_flags: bool\n    tail_twitches: bool\n    approaches: bool\n    indifferent: bool\n    runs_from: bool\n\n\njoined_dataset = f\"{working_dir}/joined_dataset\"\nyt.create(\"table\", joined_dataset, force=True, attributes={\"schema\": yt.schema.TableSchema.from_row_type(JoinedDatasetRow)})\n\n\n@yt.with_context\ndef reduce_join(key: dict[str, str], records: Iterable[dict[str, Any]], context: yt.schema.Context) -> Iterable:\n    squirrels: list[SquirrelsRow] = []\n    other_animals_sightings = set()\n    temperature_celsius = None\n    weather_data = set()\n    for record in records:\n        if context.table_index == 0:\n            squirrels.append(record)\n        elif context.table_index == 1:\n            other_animals_sightings.update(set(record[\"other_animals_sightings\"]))\n            temperature_celsius = record[\"temperature_celsius\"] if temperature_celsius is None else (temperature_celsius + record[\"temperature_celsius\"]) / 2\n            weather_data.update(set(record[\"weather_data\"]))\n    temperature_celsius = round(temperature_celsius) if temperature_celsius is not None else None\n    weather_data = list(weather_data)\n    other_animals_sightings = list(other_animals_sightings)\n    for squirrel in squirrels:\n        yield dict(\n            date=key[\"date\"],\n            hectare=key[\"hectare\"],\n            shift=key[\"shift\"],\n            other_animals_sightings=other_animals_sightings,\n            temperature_celsius=temperature_celsius,\n            weather_data=weather_data,\n            age=squirrel[\"age\"],\n            squirrel_id=squirrel[\"squirrel_id\"],\n            running=squirrel[\"running\"],\n            chasing=squirrel[\"chasing\"],\n            climbing=squirrel[\"climbing\"],\n            eating=squirrel[\"eating\"],\n            foraging=squirrel[\"foraging\"],\n            kuks=squirrel[\"kuks\"],\n            quaas=squirrel[\"quaas\"],\n            moans=squirrel[\"moans\"],\n            tail_flags=squirrel[\"tail_flags\"],\n            tail_twitches=squirrel[\"tail_twitches\"],\n            approaches=squirrel[\"approaches\"],\n            indifferent=squirrel[\"indifferent\"],\n            runs_from=squirrel[\"runs_from\"],\n        )\n\n\nyt.run_reduce(\n    reduce_join,\n    source_table=[sorted_squirrels_data, canonized_squirrels_hectare_data],\n    destination_table=joined_dataset,\n    reduce_by=[\"date\", \"hectare\", \"shift\"],\n)"
        },
        {
            "cell_type": "markdown",
            "id": "1a9761ee-7f9f-476f-bdf0-2f55454fe414",
            "metadata": {
                "cell_id": "1a9761ee-7f9f-476f-bdf0-2f55454fe414",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "# Running squirrels\n\nNow we can find out when it was more likely to see a running squirrel in Central Park, New York, in October 2018 - on cold or warm days using our new dataset. Let's do this using [mapreduce operation](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/mapreduce). We will consider days with temperatures >= 15 as warm days and temperatures < 15 as cold days."
                }
            },
            "source": "# Running squirrels\n\nNow we can find out when it was more likely to see a running squirrel in Central Park, New York, in October 2018 - on cold or warm days using our new dataset. Let's do this using [mapreduce operation](https://ytsaurus.tech/docs/en/user-guide/data-processing/operations/mapreduce). We will consider days with temperatures >= 15 as warm days and temperatures < 15 as cold days."
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "b3806db8-c8e4-4a80-9e49-0ec7c9d6c5af",
            "metadata": {
                "cell_id": "b3806db8-c8e4-4a80-9e49-0ec7c9d6c5af",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "@yt.yt_dataclass\nclass RunningIsColdRow:\n    temperature: str\n    is_running: bool\n\n\n@yt.yt_dataclass\nclass RunningIsColdResultRow:\n    temperature: str\n    is_running: int\n    not_running: int\n\n\nclass RunningIsColdMapper(yt.TypedJob):\n    def __call__(self, record: JoinedDatasetRow) -> Iterable[RunningIsColdRow]:\n        if record.temperature_celsius is None:\n            return \n        yield RunningIsColdRow(\n            is_running=record.running,\n            temperature=\"total\",\n        )\n        yield RunningIsColdRow(\n            is_running=record.running,\n            temperature=\"cold\" if (record.temperature_celsius < 15) else \"not_cold\",\n        )\n\n\nclass RunningIsColdReducer(yt.TypedJob):\n    def __call__(self, records: yt.schema.RowIterator[RunningIsColdRow]) -> Iterable[RunningIsColdResultRow]:\n        is_running = 0\n        not_running = 0\n        for record in records:\n            if record.is_running:\n                is_running += 1\n            else:\n                not_running += 1\n        yield RunningIsColdResultRow(\n            is_running=is_running,\n            not_running=not_running,\n            temperature=record.temperature,\n        )\n\n\nrunning_squirrels = f\"{working_dir}/running_squirrels\"\n\nyt.run_map_reduce(\n    mapper=RunningIsColdMapper(),\n    reducer=RunningIsColdReducer(),\n    source_table=joined_dataset,\n    destination_table=running_squirrels,\n    reduce_by=[\"temperature\"],\n)\n\nfor line in yt.read_table(running_squirrels):\n    print(line)"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:47:11,571\tINFO\tOperation started: https://planck.yt.nebius.yt/playground/operations/63a15d58-67d774a2-134403e8-863f1c8a/details\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:47:11,634\tINFO\t( 0 min) operation 63a15d58-67d774a2-134403e8-863f1c8a initializing\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:47:13,354\tINFO\t( 0 min) Unrecognized spec: {'mapper': {'title': 'RunningIsColdMapper'}, 'reducer': {'title': 'RunningIsColdReducer'}}\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:47:15,836\tINFO\t( 0 min) operation 63a15d58-67d774a2-134403e8-863f1c8a: running=0     completed=0     pending=1     failed=0     aborted=0     lost=0     total=1     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:47:19,535\tINFO\t( 0 min) operation 63a15d58-67d774a2-134403e8-863f1c8a: running=1     completed=1     pending=0     failed=0     aborted=0     lost=0     total=2     blocked=0    \n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-01-21 19:50:05,035\tINFO\t( 2 min) operation 63a15d58-67d774a2-134403e8-863f1c8a completed\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'temperature': 'cold', 'is_running': 296, 'not_running': 799}\n{'temperature': 'not_cold', 'is_running': 368, 'not_running': 1264}\n{'temperature': 'total', 'is_running': 664, 'not_running': 2063}\n"
                }
            ],
            "source": "@yt.yt_dataclass\nclass RunningIsColdRow:\n    temperature: str\n    is_running: bool\n\n\n@yt.yt_dataclass\nclass RunningIsColdResultRow:\n    temperature: str\n    is_running: int\n    not_running: int\n\n\nclass RunningIsColdMapper(yt.TypedJob):\n    def __call__(self, record: JoinedDatasetRow) -> Iterable[RunningIsColdRow]:\n        if record.temperature_celsius is None:\n            return \n        yield RunningIsColdRow(\n            is_running=record.running,\n            temperature=\"total\",\n        )\n        yield RunningIsColdRow(\n            is_running=record.running,\n            temperature=\"cold\" if (record.temperature_celsius < 15) else \"not_cold\",\n        )\n\n\nclass RunningIsColdReducer(yt.TypedJob):\n    def __call__(self, records: yt.schema.RowIterator[RunningIsColdRow]) -> Iterable[RunningIsColdResultRow]:\n        is_running = 0\n        not_running = 0\n        for record in records:\n            if record.is_running:\n                is_running += 1\n            else:\n                not_running += 1\n        yield RunningIsColdResultRow(\n            is_running=is_running,\n            not_running=not_running,\n            temperature=record.temperature,\n        )\n\n\nrunning_squirrels = f\"{working_dir}/running_squirrels\"\n\nyt.run_map_reduce(\n    mapper=RunningIsColdMapper(),\n    reducer=RunningIsColdReducer(),\n    source_table=joined_dataset,\n    destination_table=running_squirrels,\n    reduce_by=[\"temperature\"],\n)\n\nfor line in yt.read_table(running_squirrels):\n    print(line)"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "id": "29a22318-d2c3-4e61-8af3-8e9cfce18930",
            "metadata": {
                "cell_id": "29a22318-d2c3-4e61-8af3-8e9cfce18930",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "print(\"Cold: \", 296 / (296 + 799))\nprint(\"Warm: \", 368 / (368 + 1264))"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Cold:  0.27031963470319637\nWarm:  0.22549019607843138\n"
                }
            ],
            "source": "print(\"Cold: \", 296 / (296 + 799))\nprint(\"Warm: \", 368 / (368 + 1264))"
        },
        {
            "cell_type": "markdown",
            "id": "c28c9bc8-90f4-426c-9b38-ee451b24bdc4",
            "metadata": {
                "cell_id": "c28c9bc8-90f4-426c-9b38-ee451b24bdc4",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "We can see that the proportion of contacts with running squirrels was higher on cold days. Let's use [Chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test) to verify it."
                }
            },
            "source": "We can see that the proportion of contacts with running squirrels was higher on cold days. Let's use [Chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test) to verify it."
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "id": "9856bb98-d322-49ee-bcc6-d7e286678859",
            "metadata": {
                "cell_id": "9856bb98-d322-49ee-bcc6-d7e286678859",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "!pip install scipy"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting scipy\r\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "  Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m178.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hRequirement already satisfied: numpy<2.5,>=1.23.5 in /slot/sandbox/jlab/site-packages (from scipy) (2.2.0)\r\nDownloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\r\n\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/40.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.3/40.6 MB\u001b[0m \u001b[31m159.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.4/40.6 MB\u001b[0m \u001b[31m233.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.5/40.6 MB\u001b[0m \u001b[31m234.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m28.3/40.6 MB\u001b[0m \u001b[31m230.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m28.4/40.6 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m28.7/40.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m28.9/40.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m29.4/40.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u001b[0m \u001b[32m36.9/40.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.2/40.6 MB\u001b[0m \u001b[31m163.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25h"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Installing collected packages: scipy\r\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Successfully installed scipy-1.15.1\r\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n\u001b[0m"
                }
            ],
            "source": "!pip install scipy"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "id": "217c912d-7926-4b45-b0ef-ef71cef6f3e8",
            "metadata": {
                "cell_id": "217c912d-7926-4b45-b0ef-ef71cef6f3e8",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "CODE",
                    "view_source": "from scipy.stats import chi2_contingency\n\nobserved = [\n    [296, 799],\n    [368, 1264],\n]\n\nchi2, p, dof, expected = chi2_contingency(observed)\n\np < 0.05"
                }
            },
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/_core/__init__.py:23\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/_core/multiarray.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/_core/overrides.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[1;32m     11\u001b[0m ARRAY_FUNCTIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core._multiarray_umath'",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/__init__.py:114\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__config__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_config\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/__config__.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     __cpu_features__,\n\u001b[1;32m      6\u001b[0m     __cpu_baseline__,\n\u001b[1;32m      7\u001b[0m     __cpu_dispatch__,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_config\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/_core/__init__.py:49\u001b[0m\n\u001b[1;32m     26\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m], sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[1;32m     48\u001b[0m         __version__, exc)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
                        "\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"/opt/conda/bin/python\"\n  * The NumPy version is: \"2.2.0\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy._core._multiarray_umath'\n",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[1;32m      3\u001b[0m observed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m296\u001b[39m, \u001b[38;5;241m799\u001b[39m],\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;241m368\u001b[39m, \u001b[38;5;241m1264\u001b[39m],\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m chi2, p, dof, expected \u001b[38;5;241m=\u001b[39m chi2_contingency(observed)\n",
                        "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/scipy/__init__.py:47\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSciPy: A scientific computing package for Python\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_importlib\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m __numpy_version__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__config__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show \u001b[38;5;28;01mas\u001b[39;00m show_config\n",
                        "File \u001b[0;32m~/jlab/site-packages/numpy/__init__.py:119\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    116\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError importing numpy: you should not try to import numpy from\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124m    its source directory; please exit the numpy source tree, and relaunch\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124m    your python interpreter from there.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _core\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m     False_, ScalarType, True_,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mabs\u001b[39m, absolute, acos, acosh, add, \u001b[38;5;28mall\u001b[39m, allclose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     vecmat, void, vstack, where, zeros, zeros_like\n\u001b[1;32m    170\u001b[0m )\n",
                        "\u001b[0;31mImportError\u001b[0m: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there."
                    ]
                }
            ],
            "source": "from scipy.stats import chi2_contingency\n\nobserved = [\n    [296, 799],\n    [368, 1264],\n]\n\nchi2, p, dof, expected = chi2_contingency(observed)\n\np < 0.05"
        },
        {
            "cell_type": "markdown",
            "id": "f285677d-3d08-43dc-8e3a-3547825434b7",
            "metadata": {
                "cell_id": "f285677d-3d08-43dc-8e3a-3547825434b7",
                "tracto": {
                    "metadata_version": "1",
                    "view_cell_type": "MD",
                    "view_source": "~~Therefore, in cold days squirrels run more.~~\n\nTherefore, we see that in cold days of October 2018, it was more likely to see a running squirrel in Central Park, New York, than on warm days."
                }
            },
            "source": "~~Therefore, in cold days squirrels run more.~~\n\nTherefore, we see that in cold days of October 2018, it was more likely to see a running squirrel in Central Park, New York, than on warm days."
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "faucct",
            "name": "faucct"
        },
        "tracto": {
            "is_solution_notebook": true,
            "metadata_version": "1",
            "notebook_cypress_id": "d4a9ec0e-c576-4167-ab24-01e8e4f442b9"
        },
        "is_solution_notebook": true
    },
    "nbformat": 4,
    "nbformat_minor": 5
}